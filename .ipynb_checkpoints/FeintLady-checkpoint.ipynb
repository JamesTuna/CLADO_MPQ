{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2109f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /homes/zdeng/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch,torchvision,os,time\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from utils.util import get_loader,evaluate\n",
    "from utils.layer import qConv2d,qLinear\n",
    "from utils.train import QAVAT_train\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models             \n",
    "\n",
    "              # for example model\n",
    "from mqbench.prepare_by_platform import prepare_by_platform   # add quant nodes for specific Backend\n",
    "from mqbench.prepare_by_platform import BackendType           # contain various Backend, like TensorRT, NNIE, etc.\n",
    "from mqbench.utils.state import enable_calibration            # turn on calibration algorithm, determine scale, zero_point, etc.\n",
    "from mqbench.utils.state import enable_quantization           # turn on actually quantization, like FP32 -> INT8\n",
    "from mqbench.utils.state import disable_all           # turn on actually quantization, like FP32 -> INT8\n",
    "from copy import deepcopy\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet56\", pretrained=True).cuda()\n",
    "# model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_mobilenetv2_x0_5\", pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53657ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train,test = get_loader('cifar10'.upper(),batch_size=128,test_batch_size=128)\n",
    "train.num_workers = 2\n",
    "test.num_workers = 2\n",
    "train.pin_in_memory = True\n",
    "test.pin_in_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f67af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration data used to calibrate PTQ and MPQ\n",
    "calib_data = []\n",
    "i = 0\n",
    "for img,label in train:\n",
    "    i += 1\n",
    "    calib_data.append((img,label))\n",
    "    if i == 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d31b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPQ_scheme = (2,4,8)\n",
    "\n",
    "model.eval()\n",
    "torch_fp_model = deepcopy(model)\n",
    "torch_mix_model = deepcopy(model)\n",
    "for b in MPQ_scheme:\n",
    "    exec(f'torch_{b}bits_model=deepcopy(model)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b007f436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare 2bits model using MQBench\n",
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 2 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Set layer conv1 to 8 bit.\n",
      "[MQBENCH] INFO: Set layer fc to 8 bit.\n",
      "dbg node_to_quantize_output\n",
      " odict_keys([x, relu, layer1_0_relu, layer1_0_relu_1, layer1_1_relu, layer1_1_relu_1, layer1_2_relu, layer1_2_relu_1, layer1_3_relu, layer1_3_relu_1, layer1_4_relu, layer1_4_relu_1, layer1_5_relu, layer1_5_relu_1, layer1_6_relu, layer1_6_relu_1, layer1_7_relu, layer1_7_relu_1, layer1_8_relu, layer1_8_relu_1, layer2_0_relu, layer2_0_relu_1, layer2_1_relu, layer2_1_relu_1, layer2_2_relu, layer2_2_relu_1, layer2_3_relu, layer2_3_relu_1, layer2_4_relu, layer2_4_relu_1, layer2_5_relu, layer2_5_relu_1, layer2_6_relu, layer2_6_relu_1, layer2_7_relu, layer2_7_relu_1, layer2_8_relu, layer2_8_relu_1, layer3_0_relu, layer3_0_relu_1, layer3_1_relu, layer3_1_relu_1, layer3_2_relu, layer3_2_relu_1, layer3_3_relu, layer3_3_relu_1, layer3_4_relu, layer3_4_relu_1, layer3_5_relu, layer3_5_relu_1, layer3_6_relu, layer3_6_relu_1, layer3_7_relu, layer3_7_relu_1, layer3_8_relu, view])\n",
      "[MQBENCH] INFO: Set x post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set view post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant view_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n",
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n",
      "evaluate mqb quantized model\n",
      "Prepare 4bits model using MQBench\n",
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 4 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Set layer conv1 to 8 bit.\n",
      "[MQBENCH] INFO: Set layer fc to 8 bit.\n",
      "dbg node_to_quantize_output\n",
      " odict_keys([x, relu, layer1_0_relu, layer1_0_relu_1, layer1_1_relu, layer1_1_relu_1, layer1_2_relu, layer1_2_relu_1, layer1_3_relu, layer1_3_relu_1, layer1_4_relu, layer1_4_relu_1, layer1_5_relu, layer1_5_relu_1, layer1_6_relu, layer1_6_relu_1, layer1_7_relu, layer1_7_relu_1, layer1_8_relu, layer1_8_relu_1, layer2_0_relu, layer2_0_relu_1, layer2_1_relu, layer2_1_relu_1, layer2_2_relu, layer2_2_relu_1, layer2_3_relu, layer2_3_relu_1, layer2_4_relu, layer2_4_relu_1, layer2_5_relu, layer2_5_relu_1, layer2_6_relu, layer2_6_relu_1, layer2_7_relu, layer2_7_relu_1, layer2_8_relu, layer2_8_relu_1, layer3_0_relu, layer3_0_relu_1, layer3_1_relu, layer3_1_relu_1, layer3_2_relu, layer3_2_relu_1, layer3_3_relu, layer3_3_relu_1, layer3_4_relu, layer3_4_relu_1, layer3_5_relu, layer3_5_relu_1, layer3_6_relu, layer3_6_relu_1, layer3_7_relu, layer3_7_relu_1, layer3_8_relu, view])\n",
      "[MQBENCH] INFO: Set x post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_1_post_act_fake_quantizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set view post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant view_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n",
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n",
      "evaluate mqb quantized model\n",
      "Prepare 8bits model using MQBench\n",
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Set layer conv1 to 8 bit.\n",
      "[MQBENCH] INFO: Set layer fc to 8 bit.\n",
      "dbg node_to_quantize_output\n",
      " odict_keys([x, relu, layer1_0_relu, layer1_0_relu_1, layer1_1_relu, layer1_1_relu_1, layer1_2_relu, layer1_2_relu_1, layer1_3_relu, layer1_3_relu_1, layer1_4_relu, layer1_4_relu_1, layer1_5_relu, layer1_5_relu_1, layer1_6_relu, layer1_6_relu_1, layer1_7_relu, layer1_7_relu_1, layer1_8_relu, layer1_8_relu_1, layer2_0_relu, layer2_0_relu_1, layer2_1_relu, layer2_1_relu_1, layer2_2_relu, layer2_2_relu_1, layer2_3_relu, layer2_3_relu_1, layer2_4_relu, layer2_4_relu_1, layer2_5_relu, layer2_5_relu_1, layer2_6_relu, layer2_6_relu_1, layer2_7_relu, layer2_7_relu_1, layer2_8_relu, layer2_8_relu_1, layer3_0_relu, layer3_0_relu_1, layer3_1_relu, layer3_1_relu_1, layer3_2_relu, layer3_2_relu_1, layer3_3_relu, layer3_3_relu_1, layer3_4_relu, layer3_4_relu_1, layer3_5_relu, layer3_5_relu_1, layer3_6_relu, layer3_6_relu_1, layer3_7_relu, layer3_7_relu_1, layer3_8_relu, view])\n",
      "[MQBENCH] INFO: Set x post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set view post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant view_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n",
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n",
      "evaluate mqb quantized model\n"
     ]
    }
   ],
   "source": [
    "def getModuleByName(modelName,moduleName):\n",
    "    '''\n",
    "        replace module with name modelName.moduleName with newModule\n",
    "    '''\n",
    "    tokens = moduleName.split('.')\n",
    "    eval_str = modelName\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            eval_str += f'[{int(token)}]'\n",
    "        except:\n",
    "            eval_str += f'.{token}'\n",
    "\n",
    "    return eval(eval_str)\n",
    "\n",
    "for b in MPQ_scheme:\n",
    "    \n",
    "    mqb_model = deepcopy(model)\n",
    "    # MSE calibration on model parameters\n",
    "    backend = BackendType.Academic\n",
    "    extra_config = {\n",
    "        'extra_qconfig_dict': {\n",
    "            'w_observer': 'MSEObserver',                              # custom weight observer\n",
    "            'a_observer': 'EMAMSEObserver',                              # custom activation observer\n",
    "            'w_fakequantize': 'FixedFakeQuantize',                    # custom weight fake quantize function\n",
    "            'a_fakequantize': 'FixedFakeQuantize',                    # custom activation fake quantize function\n",
    "            'w_qscheme': {\n",
    "                'bit': b,                                             # custom bitwidth for weight,\n",
    "                'symmetry': True,                                    # custom whether quant is symmetric for weight,\n",
    "                'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for weight,\n",
    "                'pot_scale': False,                                   # custom whether scale is power of two for weight.\n",
    "            },\n",
    "            'a_qscheme': {\n",
    "                'bit': 8,                                             # custom bitwidth for activation,\n",
    "                'symmetry': False,                                    # custom whether quant is symmetric for activation,\n",
    "                'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for activation,\n",
    "                'pot_scale': False,                                   # custom whether scale is power of two for activation.\n",
    "            }\n",
    "        }                                                         # custom tracer behavior, checkout https://github.com/pytorch/pytorch/blob/efcbbb177eacdacda80b94ad4ce34b9ed6cf687a/torch/fx/_symbolic_trace.py#L836\n",
    "    }\n",
    "    print(f'Prepare {b}bits model using MQBench')\n",
    "\n",
    "    mqb_model = prepare_by_platform(mqb_model, backend,extra_config).cuda()\n",
    "    \n",
    "    # calibration loop\n",
    "    enable_calibration(mqb_model)\n",
    "    for img,label in calib_data:\n",
    "        mqb_model(img.cuda())  \n",
    "\n",
    "    # evaluation loop\n",
    "    enable_quantization(mqb_model)\n",
    "    print('evaluate mqb quantized model')\n",
    "    evaluate(test,mqb_model)\n",
    "\n",
    "    # pass quantized weight to torch_quantized_model\n",
    "    for n,m in mqb_model.named_modules():\n",
    "        if isinstance(m,torch.nn.Linear) or isinstance(m,torch.nn.Conv2d):\n",
    "            # print('loading quantized weight for layer',n)\n",
    "            torch_module = getModuleByName(f'torch_{b}bits_model',n)\n",
    "            torch_module.weight.data = m.weight_fake_quant(m.weight).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c08c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 0.8784,\n",
       " 'qtl_acc': 0.8784,\n",
       " 'mean_loss': 0.5174500063250337,\n",
       " 'qtl_loss': 0.5174500063250337,\n",
       " 'test time': 2.7054293155670166,\n",
       " 'acc_list': array([0.8784]),\n",
       " 'loss_list': array([0.51745001])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test,torch_4bits_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5773766",
   "metadata": {},
   "outputs": [],
   "source": [
    "mqb_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846ea48",
   "metadata": {},
   "source": [
    "## FeintLady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f9cd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# 1. record all modules we want to consider\n",
    "layers_to_quant = OrderedDict() # layer_name:[torch_fp_module,torch_q_module,torch_p_module]\n",
    "types_to_quant = (torch.nn.Conv2d,torch.nn.Linear)\n",
    "\n",
    "for n,m in torch_fp_model.named_modules():\n",
    "    if isinstance(m,types_to_quant):\n",
    "        layers_to_quant[n] = {'fp':m}\n",
    "\n",
    "for b in MPQ_scheme:\n",
    "    for n,m in eval(f'torch_{b}bits_model').named_modules():\n",
    "        if isinstance(m,types_to_quant):\n",
    "            layers_to_quant[n][f'{b}bits'] = m\n",
    "\n",
    "for n,m in torch_mix_model.named_modules():\n",
    "    if isinstance(m,types_to_quant):\n",
    "        layers_to_quant[n]['mix'] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c80e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate(calib_data,torch_fp_model)\n",
    "ref_metric = ('mean_loss',res['mean_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772d2eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 1.0,\n",
       " 'qtl_acc': 1.0,\n",
       " 'mean_loss': 0.0007052061591821257,\n",
       " 'qtl_loss': 0.0007052061591821257,\n",
       " 'test time': 0.251004695892334,\n",
       " 'acc_list': array([1.]),\n",
       " 'loss_list': array([0.00070521])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6716b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_loss(perturb_scheme,ref_metric,eval_data,mix_perturb=False,printInfo=False):\n",
    "    # perturb_schemes: dictionary of {layer_name: bitwidth}\n",
    "    # mix_perturb: if true, perturb_schemes {layer_name:(bitwidth1,bitwidth2)}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        if not mix_perturb:\n",
    "            for n in perturb_scheme:\n",
    "                b = perturb_scheme[n]\n",
    "                layers_to_quant[n]['mix'].weight.data = layers_to_quant[n][f'{b}bits'].weight.data\n",
    "        else:\n",
    "            # mix perturbation\n",
    "            for n in perturb_scheme:\n",
    "                b1,b2 = perturb_scheme[n]\n",
    "                d1 = layers_to_quant[n][f'{b1}bits'].weight.data - layers_to_quant[n]['fp'].weight.data\n",
    "                d2 = layers_to_quant[n][f'{b2}bits'].weight.data - layers_to_quant[n]['fp'].weight.data\n",
    "                layers_to_quant[n]['mix'].weight.data = layers_to_quant[n]['fp'].weight.data + 0.5*d1 + 0.5*d2\n",
    "            \n",
    "        # do evaluation\n",
    "        res = evaluate(eval_data,torch_mix_model)\n",
    "        perturbed_loss = res[ref_metric[0]] - ref_metric[1]\n",
    "        \n",
    "        if printInfo:\n",
    "            print(res)\n",
    "        # recover layers\n",
    "        for n in perturb_scheme:\n",
    "            layers_to_quant[n]['mix'].weight.data = layers_to_quant[n]['fp'].weight.data\n",
    "    return perturbed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4162ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1',\n",
       "              {'fp': Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.0.conv1',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.0.conv2',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.1.conv1',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.1.conv2',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.2.conv1',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.2.conv2',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.3.conv1',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.3.conv2',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.4.conv1',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.4.conv2',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.5.conv1',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.5.conv2',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.6.conv1',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.6.conv2',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.7.conv1',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.7.conv2',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.8.conv1',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer1.8.conv2',\n",
       "              {'fp': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.0.conv1',\n",
       "              {'fp': Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.0.conv2',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.0.downsample.0',\n",
       "              {'fp': Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "               '2bits': Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "               '4bits': Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "               '8bits': Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "               'mix': Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)}),\n",
       "             ('layer2.1.conv1',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.1.conv2',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.2.conv1',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.2.conv2',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.3.conv1',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.3.conv2',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.4.conv1',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.4.conv2',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.5.conv1',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.5.conv2',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.6.conv1',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.6.conv2',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.7.conv1',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.7.conv2',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.8.conv1',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer2.8.conv2',\n",
       "              {'fp': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.0.conv1',\n",
       "              {'fp': Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.0.conv2',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.0.downsample.0',\n",
       "              {'fp': Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "               '2bits': Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "               '4bits': Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "               '8bits': Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "               'mix': Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)}),\n",
       "             ('layer3.1.conv1',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.1.conv2',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.2.conv1',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.2.conv2',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.3.conv1',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.3.conv2',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.4.conv1',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.4.conv2',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.5.conv1',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.5.conv2',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.6.conv1',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.6.conv2',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.7.conv1',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.7.conv2',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.8.conv1',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('layer3.8.conv2',\n",
       "              {'fp': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '2bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '4bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               '8bits': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "               'mix': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}),\n",
       "             ('fc',\n",
       "              {'fp': Linear(in_features=64, out_features=10, bias=True),\n",
       "               '2bits': Linear(in_features=64, out_features=10, bias=True),\n",
       "               '4bits': Linear(in_features=64, out_features=10, bias=True),\n",
       "               '8bits': Linear(in_features=64, out_features=10, bias=True),\n",
       "               'mix': Linear(in_features=64, out_features=10, bias=True)})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_to_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47dd85f",
   "metadata": {},
   "source": [
    "## Build Cached Grad if not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f370df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "s_time = time.time()\n",
    "cached = {}\n",
    "for n in layers_to_quant:\n",
    "    for m in layers_to_quant:\n",
    "        for s1 in MPQ_scheme:\n",
    "            for s2 in MPQ_scheme:\n",
    "                if (n,m,s1,s2) not in cached:\n",
    "                    if n == m:\n",
    "                        print(f'mix perturb layer {n} to {s1}bits and {s2}bits')\n",
    "                        p = perturb_loss({n:(s1,s2)},ref_metric,calib_data,mix_perturb=True)\n",
    "                    else:\n",
    "                        print(f'perturb layer {n} to {s1}bits and layer {m} to {s2}bits')\n",
    "                        p = perturb_loss({n:s1,m:s2},ref_metric,calib_data,mix_perturb=False)\n",
    "                    \n",
    "                    cached[(n,m,s1,s2)] = cached[(m,n,s2,s1)] = p\n",
    "                    \n",
    "print(f'{time.time()-s_time:.2f} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239967a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index = {}\n",
    "cnt = 0\n",
    "for layer in layers_to_quant:\n",
    "    for s in MPQ_scheme:\n",
    "        layer_index[layer+f'{s}bits'] = cnt\n",
    "        cnt += 1\n",
    "L = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hm = np.zeros(shape=(L,L))\n",
    "for n in layers_to_quant:\n",
    "    for m in layers_to_quant:\n",
    "        for s1 in MPQ_scheme:\n",
    "            for s2 in MPQ_scheme:\n",
    "                hm[layer_index[n+f'{s1}bits'],layer_index[m+f'{s2}bits']] = cached[(n,m,s1,s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad = np.zeros_like(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99559c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generalw248_c10resnet56_calib','wb') as f:\n",
    "    pickle.dump({'Ltilde':hm,'layer_index':layer_index},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_loss(['conv1',],ref_metric,eval_data=calib_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc001d",
   "metadata": {},
   "source": [
    "## Load Cached Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "498e1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generalw248_c10resnet56_calib','rb') as f:\n",
    "    hm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf87d3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 layer conv1 scheme 2bits\n",
      "index 1 layer conv1 scheme 4bits\n",
      "index 2 layer conv1 scheme 8bits\n",
      "index 3 layer layer1.0.conv1 scheme 2bits\n",
      "index 4 layer layer1.0.conv1 scheme 4bits\n",
      "index 5 layer layer1.0.conv1 scheme 8bits\n",
      "index 6 layer layer1.0.conv2 scheme 2bits\n",
      "index 7 layer layer1.0.conv2 scheme 4bits\n",
      "index 8 layer layer1.0.conv2 scheme 8bits\n",
      "index 9 layer layer1.1.conv1 scheme 2bits\n",
      "index 10 layer layer1.1.conv1 scheme 4bits\n",
      "index 11 layer layer1.1.conv1 scheme 8bits\n",
      "index 12 layer layer1.1.conv2 scheme 2bits\n",
      "index 13 layer layer1.1.conv2 scheme 4bits\n",
      "index 14 layer layer1.1.conv2 scheme 8bits\n",
      "index 15 layer layer1.2.conv1 scheme 2bits\n",
      "index 16 layer layer1.2.conv1 scheme 4bits\n",
      "index 17 layer layer1.2.conv1 scheme 8bits\n",
      "index 18 layer layer1.2.conv2 scheme 2bits\n",
      "index 19 layer layer1.2.conv2 scheme 4bits\n",
      "index 20 layer layer1.2.conv2 scheme 8bits\n",
      "index 21 layer layer1.3.conv1 scheme 2bits\n",
      "index 22 layer layer1.3.conv1 scheme 4bits\n",
      "index 23 layer layer1.3.conv1 scheme 8bits\n",
      "index 24 layer layer1.3.conv2 scheme 2bits\n",
      "index 25 layer layer1.3.conv2 scheme 4bits\n",
      "index 26 layer layer1.3.conv2 scheme 8bits\n",
      "index 27 layer layer1.4.conv1 scheme 2bits\n",
      "index 28 layer layer1.4.conv1 scheme 4bits\n",
      "index 29 layer layer1.4.conv1 scheme 8bits\n",
      "index 30 layer layer1.4.conv2 scheme 2bits\n",
      "index 31 layer layer1.4.conv2 scheme 4bits\n",
      "index 32 layer layer1.4.conv2 scheme 8bits\n",
      "index 33 layer layer1.5.conv1 scheme 2bits\n",
      "index 34 layer layer1.5.conv1 scheme 4bits\n",
      "index 35 layer layer1.5.conv1 scheme 8bits\n",
      "index 36 layer layer1.5.conv2 scheme 2bits\n",
      "index 37 layer layer1.5.conv2 scheme 4bits\n",
      "index 38 layer layer1.5.conv2 scheme 8bits\n",
      "index 39 layer layer1.6.conv1 scheme 2bits\n",
      "index 40 layer layer1.6.conv1 scheme 4bits\n",
      "index 41 layer layer1.6.conv1 scheme 8bits\n",
      "index 42 layer layer1.6.conv2 scheme 2bits\n",
      "index 43 layer layer1.6.conv2 scheme 4bits\n",
      "index 44 layer layer1.6.conv2 scheme 8bits\n",
      "index 45 layer layer1.7.conv1 scheme 2bits\n",
      "index 46 layer layer1.7.conv1 scheme 4bits\n",
      "index 47 layer layer1.7.conv1 scheme 8bits\n",
      "index 48 layer layer1.7.conv2 scheme 2bits\n",
      "index 49 layer layer1.7.conv2 scheme 4bits\n",
      "index 50 layer layer1.7.conv2 scheme 8bits\n",
      "index 51 layer layer1.8.conv1 scheme 2bits\n",
      "index 52 layer layer1.8.conv1 scheme 4bits\n",
      "index 53 layer layer1.8.conv1 scheme 8bits\n",
      "index 54 layer layer1.8.conv2 scheme 2bits\n",
      "index 55 layer layer1.8.conv2 scheme 4bits\n",
      "index 56 layer layer1.8.conv2 scheme 8bits\n",
      "index 57 layer layer2.0.conv1 scheme 2bits\n",
      "index 58 layer layer2.0.conv1 scheme 4bits\n",
      "index 59 layer layer2.0.conv1 scheme 8bits\n",
      "index 60 layer layer2.0.conv2 scheme 2bits\n",
      "index 61 layer layer2.0.conv2 scheme 4bits\n",
      "index 62 layer layer2.0.conv2 scheme 8bits\n",
      "index 63 layer layer2.0.downsample.0 scheme 2bits\n",
      "index 64 layer layer2.0.downsample.0 scheme 4bits\n",
      "index 65 layer layer2.0.downsample.0 scheme 8bits\n",
      "index 66 layer layer2.1.conv1 scheme 2bits\n",
      "index 67 layer layer2.1.conv1 scheme 4bits\n",
      "index 68 layer layer2.1.conv1 scheme 8bits\n",
      "index 69 layer layer2.1.conv2 scheme 2bits\n",
      "index 70 layer layer2.1.conv2 scheme 4bits\n",
      "index 71 layer layer2.1.conv2 scheme 8bits\n",
      "index 72 layer layer2.2.conv1 scheme 2bits\n",
      "index 73 layer layer2.2.conv1 scheme 4bits\n",
      "index 74 layer layer2.2.conv1 scheme 8bits\n",
      "index 75 layer layer2.2.conv2 scheme 2bits\n",
      "index 76 layer layer2.2.conv2 scheme 4bits\n",
      "index 77 layer layer2.2.conv2 scheme 8bits\n",
      "index 78 layer layer2.3.conv1 scheme 2bits\n",
      "index 79 layer layer2.3.conv1 scheme 4bits\n",
      "index 80 layer layer2.3.conv1 scheme 8bits\n",
      "index 81 layer layer2.3.conv2 scheme 2bits\n",
      "index 82 layer layer2.3.conv2 scheme 4bits\n",
      "index 83 layer layer2.3.conv2 scheme 8bits\n",
      "index 84 layer layer2.4.conv1 scheme 2bits\n",
      "index 85 layer layer2.4.conv1 scheme 4bits\n",
      "index 86 layer layer2.4.conv1 scheme 8bits\n",
      "index 87 layer layer2.4.conv2 scheme 2bits\n",
      "index 88 layer layer2.4.conv2 scheme 4bits\n",
      "index 89 layer layer2.4.conv2 scheme 8bits\n",
      "index 90 layer layer2.5.conv1 scheme 2bits\n",
      "index 91 layer layer2.5.conv1 scheme 4bits\n",
      "index 92 layer layer2.5.conv1 scheme 8bits\n",
      "index 93 layer layer2.5.conv2 scheme 2bits\n",
      "index 94 layer layer2.5.conv2 scheme 4bits\n",
      "index 95 layer layer2.5.conv2 scheme 8bits\n",
      "index 96 layer layer2.6.conv1 scheme 2bits\n",
      "index 97 layer layer2.6.conv1 scheme 4bits\n",
      "index 98 layer layer2.6.conv1 scheme 8bits\n",
      "index 99 layer layer2.6.conv2 scheme 2bits\n",
      "index 100 layer layer2.6.conv2 scheme 4bits\n",
      "index 101 layer layer2.6.conv2 scheme 8bits\n",
      "index 102 layer layer2.7.conv1 scheme 2bits\n",
      "index 103 layer layer2.7.conv1 scheme 4bits\n",
      "index 104 layer layer2.7.conv1 scheme 8bits\n",
      "index 105 layer layer2.7.conv2 scheme 2bits\n",
      "index 106 layer layer2.7.conv2 scheme 4bits\n",
      "index 107 layer layer2.7.conv2 scheme 8bits\n",
      "index 108 layer layer2.8.conv1 scheme 2bits\n",
      "index 109 layer layer2.8.conv1 scheme 4bits\n",
      "index 110 layer layer2.8.conv1 scheme 8bits\n",
      "index 111 layer layer2.8.conv2 scheme 2bits\n",
      "index 112 layer layer2.8.conv2 scheme 4bits\n",
      "index 113 layer layer2.8.conv2 scheme 8bits\n",
      "index 114 layer layer3.0.conv1 scheme 2bits\n",
      "index 115 layer layer3.0.conv1 scheme 4bits\n",
      "index 116 layer layer3.0.conv1 scheme 8bits\n",
      "index 117 layer layer3.0.conv2 scheme 2bits\n",
      "index 118 layer layer3.0.conv2 scheme 4bits\n",
      "index 119 layer layer3.0.conv2 scheme 8bits\n",
      "index 120 layer layer3.0.downsample.0 scheme 2bits\n",
      "index 121 layer layer3.0.downsample.0 scheme 4bits\n",
      "index 122 layer layer3.0.downsample.0 scheme 8bits\n",
      "index 123 layer layer3.1.conv1 scheme 2bits\n",
      "index 124 layer layer3.1.conv1 scheme 4bits\n",
      "index 125 layer layer3.1.conv1 scheme 8bits\n",
      "index 126 layer layer3.1.conv2 scheme 2bits\n",
      "index 127 layer layer3.1.conv2 scheme 4bits\n",
      "index 128 layer layer3.1.conv2 scheme 8bits\n",
      "index 129 layer layer3.2.conv1 scheme 2bits\n",
      "index 130 layer layer3.2.conv1 scheme 4bits\n",
      "index 131 layer layer3.2.conv1 scheme 8bits\n",
      "index 132 layer layer3.2.conv2 scheme 2bits\n",
      "index 133 layer layer3.2.conv2 scheme 4bits\n",
      "index 134 layer layer3.2.conv2 scheme 8bits\n",
      "index 135 layer layer3.3.conv1 scheme 2bits\n",
      "index 136 layer layer3.3.conv1 scheme 4bits\n",
      "index 137 layer layer3.3.conv1 scheme 8bits\n",
      "index 138 layer layer3.3.conv2 scheme 2bits\n",
      "index 139 layer layer3.3.conv2 scheme 4bits\n",
      "index 140 layer layer3.3.conv2 scheme 8bits\n",
      "index 141 layer layer3.4.conv1 scheme 2bits\n",
      "index 142 layer layer3.4.conv1 scheme 4bits\n",
      "index 143 layer layer3.4.conv1 scheme 8bits\n",
      "index 144 layer layer3.4.conv2 scheme 2bits\n",
      "index 145 layer layer3.4.conv2 scheme 4bits\n",
      "index 146 layer layer3.4.conv2 scheme 8bits\n",
      "index 147 layer layer3.5.conv1 scheme 2bits\n",
      "index 148 layer layer3.5.conv1 scheme 4bits\n",
      "index 149 layer layer3.5.conv1 scheme 8bits\n",
      "index 150 layer layer3.5.conv2 scheme 2bits\n",
      "index 151 layer layer3.5.conv2 scheme 4bits\n",
      "index 152 layer layer3.5.conv2 scheme 8bits\n",
      "index 153 layer layer3.6.conv1 scheme 2bits\n",
      "index 154 layer layer3.6.conv1 scheme 4bits\n",
      "index 155 layer layer3.6.conv1 scheme 8bits\n",
      "index 156 layer layer3.6.conv2 scheme 2bits\n",
      "index 157 layer layer3.6.conv2 scheme 4bits\n",
      "index 158 layer layer3.6.conv2 scheme 8bits\n",
      "index 159 layer layer3.7.conv1 scheme 2bits\n",
      "index 160 layer layer3.7.conv1 scheme 4bits\n",
      "index 161 layer layer3.7.conv1 scheme 8bits\n",
      "index 162 layer layer3.7.conv2 scheme 2bits\n",
      "index 163 layer layer3.7.conv2 scheme 4bits\n",
      "index 164 layer layer3.7.conv2 scheme 8bits\n",
      "index 165 layer layer3.8.conv1 scheme 2bits\n",
      "index 166 layer layer3.8.conv1 scheme 4bits\n",
      "index 167 layer layer3.8.conv1 scheme 8bits\n",
      "index 168 layer layer3.8.conv2 scheme 2bits\n",
      "index 169 layer layer3.8.conv2 scheme 4bits\n",
      "index 170 layer layer3.8.conv2 scheme 8bits\n",
      "index 171 layer fc scheme 2bits\n",
      "index 172 layer fc scheme 4bits\n",
      "index 173 layer fc scheme 8bits\n"
     ]
    }
   ],
   "source": [
    "index2layerscheme = [None for i in range(hm['Ltilde'].shape[0])]\n",
    "\n",
    "for name in hm['layer_index']:\n",
    "    index = hm['layer_index'][name]\n",
    "    layer_name = name[:-5]\n",
    "    scheme = name[-5:]\n",
    "    print(f'index {index} layer {layer_name} scheme {scheme}')\n",
    "    \n",
    "    index2layerscheme[index] = (layer_name,scheme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65ecf015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fc', '8bits')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2layerscheme[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17bd25f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7c00cf8430>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(hm['Ltilde'],cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "beb3fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = hm['Ltilde'].shape[0]\n",
    "cached_grad = np.zeros_like(hm['Ltilde'])\n",
    "for i in range(L):\n",
    "    for j in range(L):\n",
    "        layer_i,scheme_i = index2layerscheme[i]\n",
    "        layer_j,scheme_j = index2layerscheme[j]\n",
    "        if layer_i == layer_j:\n",
    "            if scheme_i == scheme_j:\n",
    "                cached_grad[i,j] = cached_grad[j,i] = 2*hm['Ltilde'][i,j]\n",
    "            else:\n",
    "                cached_grad[i,j] = cached_grad[j,i] = 4 * hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "        else:\n",
    "            cached_grad[i,j] = cached_grad[j,i] = hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "        '''\n",
    "        print(index2layerscheme[i])\n",
    "        print(index2layerscheme[j])\n",
    "        '''\n",
    "        '''\n",
    "        if i == j:\n",
    "            cached_grad[i,j] = 0.5 * hm['Ltilde'][i,j]\n",
    "        else:\n",
    "            cached_grad[i,j] = 0.25 * (hm['Ltilde'][i,j]-hm['Ltilde'][i,i]-hm['Ltilde'][j,j])\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a23b27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00010728585039032623,\n",
       " 0.0006407861656043679,\n",
       " 8.602364687249064e-07,\n",
       " ('layer1.2.conv2', '2bits'),\n",
       " ('layer1.2.conv2', '4bits'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm['Ltilde'][18,19],hm['Ltilde'][18,18],hm['Ltilde'][19,19],index2layerscheme[18],index2layerscheme[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccbde6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00021250300051178783"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_grad[18][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e34a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7c00e6acd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cached_grad[cached_grad<0]=0\n",
    "plt.imshow(cached_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4555d2",
   "metadata": {},
   "source": [
    "### Define a naive cost function: model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5886f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = np.array([0 for i in range(L)])\n",
    "for l in hm['layer_index']:\n",
    "    index = hm['layer_index'][l]\n",
    "    layer_name, scheme = index2layerscheme[index]\n",
    "    layer_size[index] = torch.numel(layers_to_quant[layer_name]['fp'].weight) * int(scheme[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6abd2edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   864,   1728,   3456,   4608,   9216,  18432,   4608,   9216,\n",
       "        18432,   4608,   9216,  18432,   4608,   9216,  18432,   4608,\n",
       "         9216,  18432,   4608,   9216,  18432,   4608,   9216,  18432,\n",
       "         4608,   9216,  18432,   4608,   9216,  18432,   4608,   9216,\n",
       "        18432,   4608,   9216,  18432,   4608,   9216,  18432,   4608,\n",
       "         9216,  18432,   4608,   9216,  18432,   4608,   9216,  18432,\n",
       "         4608,   9216,  18432,   4608,   9216,  18432,   4608,   9216,\n",
       "        18432,   9216,  18432,  36864,  18432,  36864,  73728,   1024,\n",
       "         2048,   4096,  18432,  36864,  73728,  18432,  36864,  73728,\n",
       "        18432,  36864,  73728,  18432,  36864,  73728,  18432,  36864,\n",
       "        73728,  18432,  36864,  73728,  18432,  36864,  73728,  18432,\n",
       "        36864,  73728,  18432,  36864,  73728,  18432,  36864,  73728,\n",
       "        18432,  36864,  73728,  18432,  36864,  73728,  18432,  36864,\n",
       "        73728,  18432,  36864,  73728,  18432,  36864,  73728,  18432,\n",
       "        36864,  73728,  36864,  73728, 147456,  73728, 147456, 294912,\n",
       "         4096,   8192,  16384,  73728, 147456, 294912,  73728, 147456,\n",
       "       294912,  73728, 147456, 294912,  73728, 147456, 294912,  73728,\n",
       "       147456, 294912,  73728, 147456, 294912,  73728, 147456, 294912,\n",
       "        73728, 147456, 294912,  73728, 147456, 294912,  73728, 147456,\n",
       "       294912,  73728, 147456, 294912,  73728, 147456, 294912,  73728,\n",
       "       147456, 294912,  73728, 147456, 294912,  73728, 147456, 294912,\n",
       "        73728, 147456, 294912,   1280,   2560,   5120])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "367cb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.nn.Parameter(torch.randn(L))\n",
    "alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(MPQ_scheme)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2aa5e446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([58, 3]),\n",
       " tensor([1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 0, 2, 2, 1, 2, 2, 0, 1, 1, 2, 1, 1, 1, 0,\n",
       "         1, 0, 0, 0, 0, 0, 2, 0, 1, 1, 2, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 2, 1,\n",
       "         0, 0, 1, 2, 2, 2, 0, 1, 2, 0]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.shape,alpha.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e11b34a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = torch.ones(int(L/len(MPQ_scheme)),dtype=int) * len(MPQ_scheme)\n",
    "offset = offset.cumsum(dim=-1) - len(MPQ_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7dc9cf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   3,   6,   9,  12,  15,  18,  21,  24,  27,  30,  33,  36,  39,\n",
       "         42,  45,  48,  51,  54,  57,  60,  63,  66,  69,  72,  75,  78,  81,\n",
       "         84,  87,  90,  93,  96,  99, 102, 105, 108, 111, 114, 117, 120, 123,\n",
       "        126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165,\n",
       "        168, 171])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7defd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = v.reshape(-1,len(MPQ_scheme)).argmax(dim=1) + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "50be6404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   4,   7,  10,  13,  17,  19,  21,  26,  28,  30,  35,  38,\n",
       "        40,  44,  47,  48,  52,  55,  59,  61,  64,  67,  69,  73,  75,\n",
       "        78,  81,  84,  87,  92,  93,  97, 100, 104, 105, 108, 111, 115,\n",
       "       119, 121, 123, 127, 130, 132, 136, 140, 142, 144, 147, 151, 155,\n",
       "       158, 161, 162, 166, 170, 171])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "00068f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv1', '4bits')\n",
      "('layer1.0.conv1', '4bits')\n",
      "('layer1.0.conv2', '4bits')\n",
      "('layer1.1.conv1', '4bits')\n",
      "('layer1.1.conv2', '4bits')\n",
      "('layer1.2.conv1', '8bits')\n",
      "('layer1.2.conv2', '4bits')\n",
      "('layer1.3.conv1', '2bits')\n",
      "('layer1.3.conv2', '8bits')\n",
      "('layer1.4.conv1', '4bits')\n",
      "('layer1.4.conv2', '2bits')\n",
      "('layer1.5.conv1', '8bits')\n",
      "('layer1.5.conv2', '8bits')\n",
      "('layer1.6.conv1', '4bits')\n",
      "('layer1.6.conv2', '8bits')\n",
      "('layer1.7.conv1', '8bits')\n",
      "('layer1.7.conv2', '2bits')\n",
      "('layer1.8.conv1', '4bits')\n",
      "('layer1.8.conv2', '4bits')\n",
      "('layer2.0.conv1', '8bits')\n",
      "('layer2.0.conv2', '4bits')\n",
      "('layer2.0.downsample.0', '4bits')\n",
      "('layer2.1.conv1', '4bits')\n",
      "('layer2.1.conv2', '2bits')\n",
      "('layer2.2.conv1', '4bits')\n",
      "('layer2.2.conv2', '2bits')\n",
      "('layer2.3.conv1', '2bits')\n",
      "('layer2.3.conv2', '2bits')\n",
      "('layer2.4.conv1', '2bits')\n",
      "('layer2.4.conv2', '2bits')\n",
      "('layer2.5.conv1', '8bits')\n",
      "('layer2.5.conv2', '2bits')\n",
      "('layer2.6.conv1', '4bits')\n",
      "('layer2.6.conv2', '4bits')\n",
      "('layer2.7.conv1', '8bits')\n",
      "('layer2.7.conv2', '2bits')\n",
      "('layer2.8.conv1', '2bits')\n",
      "('layer2.8.conv2', '2bits')\n",
      "('layer3.0.conv1', '4bits')\n",
      "('layer3.0.conv2', '8bits')\n",
      "('layer3.0.downsample.0', '4bits')\n",
      "('layer3.1.conv1', '2bits')\n",
      "('layer3.1.conv2', '4bits')\n",
      "('layer3.2.conv1', '4bits')\n",
      "('layer3.2.conv2', '2bits')\n",
      "('layer3.3.conv1', '4bits')\n",
      "('layer3.3.conv2', '8bits')\n",
      "('layer3.4.conv1', '4bits')\n",
      "('layer3.4.conv2', '2bits')\n",
      "('layer3.5.conv1', '2bits')\n",
      "('layer3.5.conv2', '4bits')\n",
      "('layer3.6.conv1', '8bits')\n",
      "('layer3.6.conv2', '8bits')\n",
      "('layer3.7.conv1', '8bits')\n",
      "('layer3.7.conv2', '2bits')\n",
      "('layer3.8.conv1', '4bits')\n",
      "('layer3.8.conv2', '8bits')\n",
      "('fc', '2bits')\n"
     ]
    }
   ],
   "source": [
    "for scheme_id in select.numpy():\n",
    "    print(index2layerscheme[scheme_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37a9b5c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check of equality constraint (probability simplex)\n",
    "layer_ids = {}\n",
    "for i in range(len(index2layerscheme)):\n",
    "    n,s = index2layerscheme[i]\n",
    "    if n not in layer_ids:\n",
    "        layer_ids[n] = []\n",
    "    layer_ids[n].append(i)\n",
    "for layer in layer_ids:\n",
    "    ids = layer_ids[layer]\n",
    "    print(alpha[ids].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4bcd5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random variable v\n",
    "# use recitfied sigmoid h(v) to represent alpha\n",
    "# freg is 1-(1-2h(v))**beta, annealing beta to \n",
    "\n",
    "if not isinstance(cached_grad,torch.Tensor):\n",
    "    cached_grad = torch.Tensor(cached_grad)\n",
    "\n",
    "layer_size_tensor = torch.Tensor(layer_size)\n",
    "\n",
    "def lossfunc(v,beta,lambda1,lambda2,printInfo=False,naive=False,b=None):\n",
    "    \n",
    "    alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(MPQ_scheme))).reshape(-1,)\n",
    "    \n",
    "    if not naive:\n",
    "        outer_alpha = torch.outer(alpha,alpha)\n",
    "        netloss = torch.sum(outer_alpha * cached_grad)\n",
    "    else:\n",
    "        netloss = torch.sum(torch.diagonal(cached_grad) * alpha)\n",
    "        \n",
    "    model_size = torch.sum(layer_size_tensor * alpha)/8/1024/1024 # model size in MB\n",
    "            \n",
    "    regloss = torch.sum(1-(torch.abs(1-2*alpha))**beta)\n",
    "    regloss *= lambda1\n",
    "\n",
    "    if b is None:\n",
    "        closs = lambda2 * model_size\n",
    "    else:\n",
    "        closs = lambda2 * torch.clamp(model_size-b,0)\n",
    "    \n",
    "    totloss = netloss + regloss + closs\n",
    "    \n",
    "    if printInfo:\n",
    "        print(f'netloss {netloss.item():.4f} regloss {regloss.item():.4f}(beta={beta:.4f}) closs{closs.item():.4f}(model size: {model_size.item():.4f}MB constraint:{b})')\n",
    "        print('alpha:\\n',alpha)\n",
    "        \n",
    "    return totloss    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "04760381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(n_iteration,lr,beta,lambda1,lambda2,b=None,naive=False):\n",
    "    \n",
    "    v = torch.nn.Parameter(torch.randn(L))\n",
    "    optim = torch.optim.Adam([v,],lr=lr)\n",
    "    bs = np.linspace(beta[0],beta[1],n_iteration)\n",
    "    \n",
    "    for i in range(n_iteration):\n",
    "        if i==0 or (i+1) % 1000 == 0:\n",
    "            printInfo = True\n",
    "            print(f'Iter {i+1}')\n",
    "        else:\n",
    "            printInfo = False\n",
    "            \n",
    "        optim.zero_grad()\n",
    "        loss = lossfunc(v,bs[i],lambda1,lambda2,printInfo=printInfo,b=b,naive=naive)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    return v\n",
    "\n",
    "def evaluate_decision(v,printInfo=False):\n",
    "    v = v.detach()\n",
    "    # alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(MPQ_scheme)))\n",
    "    offset = torch.ones(int(L/len(MPQ_scheme)),dtype=int) * len(MPQ_scheme)\n",
    "    offset = offset.cumsum(dim=-1) - len(MPQ_scheme)\n",
    "    select = v.reshape(-1,len(MPQ_scheme)).argmax(dim=1) + offset\n",
    "    \n",
    "    decisions = {}\n",
    "    for scheme_id in select.numpy():\n",
    "        layer,scheme = index2layerscheme[scheme_id]\n",
    "        decisions[layer] = scheme\n",
    "    \n",
    "    print(\"evaluate_decision\\n\",decisions)\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        for n in decisions:\n",
    "            layers_to_quant[n]['mix'].weight.data = layers_to_quant[n][decisions[n]].weight.data\n",
    "        # do evaluation\n",
    "        res = evaluate(test,torch_mix_model)\n",
    "        # recover layers\n",
    "        for n in decisions:\n",
    "            layers_to_quant[n]['mix'].weight.data = layers_to_quant[n]['fp'].weight.data\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cf97384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_decision\n",
      " {'conv1': '8bits', 'layer1.0.conv1': '8bits', 'layer1.0.conv2': '8bits', 'layer1.1.conv1': '8bits', 'layer1.1.conv2': '8bits', 'layer1.2.conv1': '8bits', 'layer1.2.conv2': '8bits', 'layer1.3.conv1': '4bits', 'layer1.3.conv2': '4bits', 'layer1.4.conv1': '8bits', 'layer1.4.conv2': '2bits', 'layer1.5.conv1': '8bits', 'layer1.5.conv2': '4bits', 'layer1.6.conv1': '4bits', 'layer1.6.conv2': '8bits', 'layer1.7.conv1': '4bits', 'layer1.7.conv2': '8bits', 'layer1.8.conv1': '8bits', 'layer1.8.conv2': '8bits', 'layer2.0.conv1': '2bits', 'layer2.0.conv2': '8bits', 'layer2.0.downsample.0': '8bits', 'layer2.1.conv1': '8bits', 'layer2.1.conv2': '8bits', 'layer2.2.conv1': '8bits', 'layer2.2.conv2': '8bits', 'layer2.3.conv1': '8bits', 'layer2.3.conv2': '4bits', 'layer2.4.conv1': '8bits', 'layer2.4.conv2': '8bits', 'layer2.5.conv1': '8bits', 'layer2.5.conv2': '8bits', 'layer2.6.conv1': '8bits', 'layer2.6.conv2': '8bits', 'layer2.7.conv1': '8bits', 'layer2.7.conv2': '8bits', 'layer2.8.conv1': '8bits', 'layer2.8.conv2': '8bits', 'layer3.0.conv1': '8bits', 'layer3.0.conv2': '8bits', 'layer3.0.downsample.0': '4bits', 'layer3.1.conv1': '8bits', 'layer3.1.conv2': '8bits', 'layer3.2.conv1': '8bits', 'layer3.2.conv2': '8bits', 'layer3.3.conv1': '4bits', 'layer3.3.conv2': '8bits', 'layer3.4.conv1': '4bits', 'layer3.4.conv2': '4bits', 'layer3.5.conv1': '4bits', 'layer3.5.conv2': '4bits', 'layer3.6.conv1': '8bits', 'layer3.6.conv2': '4bits', 'layer3.7.conv1': '4bits', 'layer3.7.conv2': '4bits', 'layer3.8.conv1': '2bits', 'layer3.8.conv2': '2bits', 'fc': '8bits'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 0.8677,\n",
       " 'qtl_acc': 0.8677,\n",
       " 'mean_loss': 0.43237017547782464,\n",
       " 'qtl_loss': 0.43237017547782464,\n",
       " 'test time': 2.66797137260437,\n",
       " 'acc_list': array([0.8677]),\n",
       " 'loss_list': array([0.43237018])}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fa2f91e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1\n",
      "netloss 4.4601 regloss 0.0000(beta=20.0000) closs0.0000(model size: 0.4936MB constraint:None)\n",
      "alpha:\n",
      " tensor([0.1996, 0.4421, 0.3583, 0.6186, 0.2132, 0.1682, 0.2233, 0.5423, 0.2344,\n",
      "        0.3015, 0.2781, 0.4204, 0.2396, 0.6582, 0.1023, 0.8121, 0.1740, 0.0139,\n",
      "        0.0141, 0.9384, 0.0475, 0.3281, 0.0725, 0.5994, 0.1982, 0.2676, 0.5342,\n",
      "        0.2715, 0.2630, 0.4656, 0.1482, 0.5748, 0.2769, 0.3595, 0.1730, 0.4675,\n",
      "        0.0736, 0.0925, 0.8338, 0.0177, 0.4065, 0.5758, 0.4592, 0.1216, 0.4192,\n",
      "        0.3151, 0.1831, 0.5018, 0.0099, 0.9237, 0.0664, 0.2100, 0.5100, 0.2799,\n",
      "        0.2170, 0.3191, 0.4639, 0.0278, 0.0475, 0.9246, 0.1462, 0.3787, 0.4750,\n",
      "        0.0470, 0.7012, 0.2518, 0.1850, 0.3359, 0.4791, 0.1831, 0.6710, 0.1460,\n",
      "        0.5250, 0.0673, 0.4078, 0.1395, 0.2700, 0.5905, 0.0552, 0.7896, 0.1552,\n",
      "        0.2765, 0.1691, 0.5544, 0.2029, 0.0596, 0.7376, 0.4536, 0.3896, 0.1568,\n",
      "        0.6994, 0.2048, 0.0958, 0.2893, 0.2519, 0.4588, 0.1579, 0.0963, 0.7459,\n",
      "        0.0520, 0.6014, 0.3466, 0.2768, 0.6554, 0.0678, 0.0637, 0.8230, 0.1133,\n",
      "        0.8604, 0.0132, 0.1263, 0.1250, 0.8219, 0.0531, 0.2810, 0.1967, 0.5223,\n",
      "        0.8213, 0.1141, 0.0646, 0.4621, 0.0248, 0.5131, 0.2484, 0.5914, 0.1603,\n",
      "        0.2741, 0.4598, 0.2661, 0.1102, 0.0121, 0.8776, 0.2366, 0.1740, 0.5894,\n",
      "        0.3620, 0.3333, 0.3047, 0.3517, 0.2949, 0.3534, 0.1833, 0.6450, 0.1717,\n",
      "        0.4855, 0.3796, 0.1348, 0.0971, 0.6653, 0.2376, 0.2045, 0.7319, 0.0637,\n",
      "        0.1740, 0.6186, 0.2074, 0.2189, 0.0692, 0.7119, 0.0921, 0.2204, 0.6874,\n",
      "        0.1862, 0.5632, 0.2507, 0.5446, 0.0876, 0.3678, 0.2497, 0.2270, 0.5232,\n",
      "        0.2032, 0.2583, 0.5384], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 1000\n",
      "netloss 0.2364 regloss 0.0000(beta=18.2016) closs0.0000(model size: 0.6033MB constraint:None)\n",
      "alpha:\n",
      " tensor([0.1996, 0.4421, 0.3583, 0.1384, 0.4612, 0.4004, 0.0467, 0.5656, 0.3878,\n",
      "        0.0678, 0.3018, 0.6303, 0.0527, 0.7299, 0.2173, 0.1904, 0.7487, 0.0609,\n",
      "        0.0028, 0.9885, 0.0087, 0.0676, 0.0714, 0.8610, 0.0440, 0.0828, 0.8732,\n",
      "        0.0556, 0.3130, 0.6313, 0.0320, 0.8521, 0.1159, 0.0745, 0.2027, 0.7228,\n",
      "        0.0149, 0.0161, 0.9689, 0.0034, 0.3828, 0.6138, 0.0987, 0.1797, 0.7216,\n",
      "        0.0640, 0.2283, 0.7076, 0.0020, 0.9315, 0.0665, 0.0429, 0.5387, 0.4184,\n",
      "        0.0461, 0.2369, 0.7170, 0.0060, 0.0169, 0.9771, 0.0296, 0.3447, 0.6257,\n",
      "        0.0132, 0.2294, 0.7573, 0.0374, 0.3495, 0.6130, 0.0372, 0.7433, 0.2195,\n",
      "        0.1140, 0.1057, 0.7803, 0.0285, 0.1839, 0.7876, 0.0119, 0.6941, 0.2940,\n",
      "        0.0563, 0.2016, 0.7421, 0.0413, 0.0312, 0.9275, 0.0973, 0.5986, 0.3041,\n",
      "        0.1575, 0.5578, 0.2847, 0.0623, 0.1785, 0.7592, 0.0334, 0.0127, 0.9539,\n",
      "        0.0120, 0.3655, 0.6225, 0.0572, 0.8219, 0.1209, 0.0196, 0.4836, 0.4968,\n",
      "        0.2054, 0.0737, 0.7209, 0.0333, 0.7734, 0.1933, 0.0599, 0.2356, 0.7044,\n",
      "        0.1919, 0.5115, 0.2966, 0.0993, 0.0298, 0.8708, 0.0505, 0.7272, 0.2223,\n",
      "        0.0556, 0.5467, 0.3978, 0.0218, 0.0054, 0.9727, 0.0482, 0.1509, 0.8009,\n",
      "        0.0742, 0.4410, 0.4848, 0.0738, 0.3324, 0.5938, 0.0367, 0.7055, 0.2578,\n",
      "        0.1017, 0.6063, 0.2920, 0.0192, 0.6910, 0.2899, 0.0411, 0.8582, 0.1007,\n",
      "        0.0368, 0.7065, 0.2567, 0.0434, 0.0690, 0.8876, 0.0186, 0.1995, 0.7820,\n",
      "        0.0381, 0.5845, 0.3774, 0.1180, 0.1621, 0.7199, 0.0490, 0.2452, 0.7058,\n",
      "        0.2032, 0.2583, 0.5384], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 2000\n",
      "netloss 0.0532 regloss 0.0000(beta=16.4014) closs0.0000(model size: 0.6490MB constraint:None)\n",
      "alpha:\n",
      " tensor([1.9959e-01, 4.4208e-01, 3.5834e-01, 6.8635e-02, 4.4725e-01, 4.8412e-01,\n",
      "        2.4942e-02, 3.6716e-01, 6.0790e-01, 3.6803e-02, 1.6167e-01, 8.0153e-01,\n",
      "        2.6142e-02, 3.7802e-01, 5.9584e-01, 7.8543e-02, 8.4777e-01, 7.3688e-02,\n",
      "        1.5631e-03, 9.9301e-01, 5.4272e-03, 3.5569e-02, 4.6020e-02, 9.1841e-01,\n",
      "        2.3154e-02, 3.4323e-02, 9.4252e-01, 3.0591e-02, 2.8622e-01, 6.8319e-01,\n",
      "        1.7319e-02, 9.1367e-01, 6.9009e-02, 3.9205e-02, 1.4272e-01, 8.1808e-01,\n",
      "        8.2911e-03, 8.6305e-03, 9.8308e-01, 2.0229e-03, 2.6209e-01, 7.3589e-01,\n",
      "        5.2621e-02, 1.5586e-01, 7.9152e-01, 3.3892e-02, 1.9498e-01, 7.7113e-01,\n",
      "        5.8361e-04, 1.7361e-01, 8.2581e-01, 2.3540e-02, 3.9836e-01, 5.7810e-01,\n",
      "        2.5250e-02, 1.1848e-01, 8.5627e-01, 4.5469e-03, 8.9499e-03, 9.8650e-01,\n",
      "        1.8161e-02, 2.4583e-01, 7.3601e-01, 6.7906e-03, 7.1810e-02, 9.2140e-01,\n",
      "        2.0572e-02, 2.8368e-01, 6.9575e-01, 2.1254e-02, 6.4852e-01, 3.3023e-01,\n",
      "        5.7135e-02, 8.1465e-02, 8.6140e-01, 1.6035e-02, 9.9336e-02, 8.8463e-01,\n",
      "        6.1437e-03, 3.0995e-01, 6.8391e-01, 3.1187e-02, 1.8252e-01, 7.8629e-01,\n",
      "        2.2919e-02, 1.5599e-02, 9.6148e-01, 5.0853e-02, 5.2433e-01, 4.2482e-01,\n",
      "        7.2279e-02, 5.7122e-01, 3.5650e-01, 3.4042e-02, 8.5017e-02, 8.8094e-01,\n",
      "        1.8859e-02, 6.2382e-03, 9.7490e-01, 6.6953e-03, 1.6862e-01, 8.2469e-01,\n",
      "        3.1890e-02, 7.3910e-01, 2.2901e-01, 8.1786e-03, 9.6630e-02, 8.9519e-01,\n",
      "        8.1610e-02, 7.9008e-02, 8.3938e-01, 1.4861e-02, 1.3649e-01, 8.4865e-01,\n",
      "        3.7017e-02, 2.0963e-01, 7.5335e-01, 8.2287e-02, 5.6452e-01, 3.5319e-01,\n",
      "        5.5996e-02, 2.0134e-02, 9.2387e-01, 2.7135e-02, 7.0198e-01, 2.7089e-01,\n",
      "        3.1168e-02, 4.6531e-01, 5.0353e-01, 1.2256e-02, 2.7161e-03, 9.8503e-01,\n",
      "        2.6966e-02, 9.5924e-02, 8.7711e-01, 3.9265e-02, 3.8082e-01, 5.7991e-01,\n",
      "        3.9346e-02, 2.1402e-01, 7.4664e-01, 2.0466e-02, 5.9591e-01, 3.8362e-01,\n",
      "        5.1001e-02, 4.8845e-01, 4.6055e-01, 1.0972e-02, 6.3435e-01, 3.5467e-01,\n",
      "        2.3678e-02, 7.9880e-01, 1.7753e-01, 2.2238e-02, 6.9147e-01, 2.8630e-01,\n",
      "        2.4881e-02, 5.0613e-02, 9.2451e-01, 1.1381e-02, 1.5727e-01, 8.3135e-01,\n",
      "        2.1421e-02, 4.3500e-01, 5.4358e-01, 6.3767e-02, 1.6239e-01, 7.7384e-01,\n",
      "        2.7387e-02, 1.9074e-01, 7.8187e-01, 2.0323e-01, 2.5834e-01, 5.3844e-01],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 3000\n",
      "netloss 0.0127 regloss 0.0000(beta=14.6013) closs0.0000(model size: 0.6883MB constraint:None)\n",
      "alpha:\n",
      " tensor([1.9959e-01, 4.4207e-01, 3.5834e-01, 4.3472e-02, 3.8741e-01, 5.6912e-01,\n",
      "        1.3988e-02, 1.8986e-01, 7.9615e-01, 2.2508e-02, 7.8593e-02, 8.9890e-01,\n",
      "        1.1117e-02, 1.2348e-01, 8.6541e-01, 4.5143e-02, 8.6955e-01, 8.5303e-02,\n",
      "        1.0498e-03, 9.9500e-01, 3.9521e-03, 2.2648e-02, 3.0129e-02, 9.4722e-01,\n",
      "        1.4724e-02, 1.9256e-02, 9.6602e-01, 2.0082e-02, 2.5200e-01, 7.2792e-01,\n",
      "        1.1601e-02, 9.4484e-01, 4.3558e-02, 2.4420e-02, 9.5367e-02, 8.8021e-01,\n",
      "        5.4870e-03, 5.5666e-03, 9.8895e-01, 1.3414e-03, 1.9108e-01, 8.0758e-01,\n",
      "        3.3499e-02, 1.2671e-01, 8.3979e-01, 2.1649e-02, 1.6084e-01, 8.1751e-01,\n",
      "        2.3606e-04, 4.6358e-02, 9.5341e-01, 1.4081e-02, 2.4813e-01, 7.3779e-01,\n",
      "        1.6003e-02, 6.6884e-02, 9.1711e-01, 5.5124e-03, 6.4494e-03, 9.8804e-01,\n",
      "        1.3496e-02, 1.6974e-01, 8.1676e-01, 4.7206e-03, 3.7815e-02, 9.5746e-01,\n",
      "        1.2836e-02, 2.0086e-01, 7.8630e-01, 1.2717e-02, 4.5082e-01, 5.3646e-01,\n",
      "        3.4724e-02, 5.7269e-02, 9.0801e-01, 1.0408e-02, 5.8827e-02, 9.3076e-01,\n",
      "        2.9054e-03, 1.0936e-01, 8.8774e-01, 2.0398e-02, 1.5605e-01, 8.2355e-01,\n",
      "        1.4991e-02, 9.2225e-03, 9.7579e-01, 2.9900e-02, 3.7860e-01, 5.9150e-01,\n",
      "        4.2217e-02, 5.2017e-01, 4.3762e-01, 2.1578e-02, 4.6414e-02, 9.3201e-01,\n",
      "        1.2459e-02, 3.7845e-03, 9.8376e-01, 4.1060e-03, 8.6813e-02, 9.0908e-01,\n",
      "        1.6829e-02, 4.4179e-01, 5.4138e-01, 4.4549e-03, 4.0747e-02, 9.5480e-01,\n",
      "        4.6263e-02, 7.4206e-02, 8.7953e-01, 6.8245e-03, 4.4427e-02, 9.4875e-01,\n",
      "        3.0115e-02, 1.8079e-01, 7.8909e-01, 5.1697e-02, 5.5679e-01, 3.9151e-01,\n",
      "        3.7935e-02, 1.3895e-02, 9.4817e-01, 1.7092e-02, 6.2589e-01, 3.5702e-01,\n",
      "        1.9925e-02, 3.5174e-01, 6.2833e-01, 8.1152e-03, 1.6114e-03, 9.9027e-01,\n",
      "        1.7727e-02, 6.2431e-02, 9.1984e-01, 2.4518e-02, 2.9949e-01, 6.7599e-01,\n",
      "        2.4161e-02, 1.2925e-01, 8.4659e-01, 1.2386e-02, 4.1066e-01, 5.7695e-01,\n",
      "        2.8054e-02, 2.9840e-01, 6.7355e-01, 7.2350e-03, 5.4349e-01, 4.4927e-01,\n",
      "        1.4221e-02, 5.8182e-01, 4.0395e-01, 1.5999e-02, 6.4821e-01, 3.3579e-01,\n",
      "        1.6729e-02, 3.5509e-02, 9.4776e-01, 8.8151e-03, 1.2419e-01, 8.6699e-01,\n",
      "        1.3025e-02, 2.6844e-01, 7.1853e-01, 4.4164e-02, 1.5368e-01, 8.0216e-01,\n",
      "        1.8230e-02, 1.4073e-01, 8.4104e-01, 2.0323e-01, 2.5834e-01, 5.3844e-01],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4000\n",
      "netloss -0.0111 regloss 0.0000(beta=12.8011) closs0.0000(model size: 0.7244MB constraint:None)\n",
      "alpha:\n",
      " tensor([1.9959e-01, 4.4207e-01, 3.5834e-01, 2.9138e-02, 3.0209e-01, 6.6877e-01,\n",
      "        7.9349e-03, 9.5053e-02, 8.9701e-01, 1.4050e-02, 3.7999e-02, 9.4795e-01,\n",
      "        5.6754e-03, 5.3153e-02, 9.4117e-01, 2.8545e-02, 8.5611e-01, 1.1535e-01,\n",
      "        7.2908e-04, 9.9627e-01, 3.0039e-03, 1.5265e-02, 2.0338e-02, 9.6440e-01,\n",
      "        9.9507e-03, 1.2083e-02, 9.7797e-01, 1.3814e-02, 2.0663e-01, 7.7956e-01,\n",
      "        8.9895e-03, 9.6820e-01, 2.2816e-02, 1.5719e-02, 6.0767e-02, 9.2351e-01,\n",
      "        3.8533e-03, 3.7956e-03, 9.9235e-01, 9.4960e-04, 2.0453e-01, 7.9452e-01,\n",
      "        2.1976e-02, 9.2194e-02, 8.8583e-01, 1.4657e-02, 1.3259e-01, 8.5276e-01,\n",
      "        1.2352e-04, 1.7819e-02, 9.8206e-01, 8.4225e-03, 1.4275e-01, 8.4883e-01,\n",
      "        1.0595e-02, 3.9913e-02, 9.4949e-01, 3.0502e-02, 7.3856e-03, 9.6211e-01,\n",
      "        1.0723e-02, 1.1002e-01, 8.7926e-01, 3.8189e-03, 2.3294e-02, 9.7289e-01,\n",
      "        7.1842e-03, 1.0503e-01, 8.8778e-01, 5.6474e-03, 1.8527e-01, 8.0908e-01,\n",
      "        2.0712e-02, 3.4551e-02, 9.4474e-01, 6.8593e-03, 3.4528e-02, 9.5861e-01,\n",
      "        1.5145e-03, 4.6766e-02, 9.5172e-01, 1.3505e-02, 1.2380e-01, 8.6270e-01,\n",
      "        9.7951e-03, 5.3841e-03, 9.8482e-01, 1.5498e-02, 2.0378e-01, 7.8072e-01,\n",
      "        2.4597e-02, 4.1038e-01, 5.6502e-01, 1.3772e-02, 2.5531e-02, 9.6070e-01,\n",
      "        8.0293e-03, 2.2609e-03, 9.8971e-01, 2.3834e-03, 3.8020e-02, 9.5960e-01,\n",
      "        6.3466e-03, 1.4968e-01, 8.4398e-01, 2.6780e-03, 2.0911e-02, 9.7641e-01,\n",
      "        2.8228e-02, 6.3486e-02, 9.0829e-01, 3.7952e-03, 2.0476e-02, 9.7573e-01,\n",
      "        3.1644e-02, 1.5539e-01, 8.1296e-01, 3.8817e-02, 5.2088e-01, 4.4030e-01,\n",
      "        2.6930e-02, 9.9500e-03, 9.6312e-01, 1.0032e-02, 4.3574e-01, 5.5423e-01,\n",
      "        1.2426e-02, 2.2925e-01, 7.5832e-01, 5.5177e-03, 9.6853e-04, 9.9351e-01,\n",
      "        1.2182e-02, 4.0758e-02, 9.4706e-01, 1.5843e-02, 2.1658e-01, 7.6758e-01,\n",
      "        1.5543e-02, 7.8766e-02, 9.0569e-01, 7.1878e-03, 2.3877e-01, 7.5405e-01,\n",
      "        1.5591e-02, 1.6141e-01, 8.2300e-01, 4.9957e-03, 4.6131e-01, 5.3370e-01,\n",
      "        7.3382e-03, 3.0775e-01, 6.8491e-01, 1.1682e-02, 5.2868e-01, 4.5964e-01,\n",
      "        1.1929e-02, 2.4053e-02, 9.6402e-01, 8.0038e-03, 1.0012e-01, 8.9188e-01,\n",
      "        7.9113e-03, 1.5518e-01, 8.3691e-01, 3.6311e-02, 1.4939e-01, 8.1430e-01,\n",
      "        1.3450e-02, 1.0520e-01, 8.8135e-01, 2.0323e-01, 2.5834e-01, 5.3844e-01],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 5000\n",
      "netloss -0.1131 regloss 0.0000(beta=11.0009) closs0.0000(model size: 0.7100MB constraint:None)\n",
      "alpha:\n",
      " tensor([1.9959e-01, 4.4208e-01, 3.5834e-01, 1.4097e-02, 1.8887e-01, 7.9703e-01,\n",
      "        2.6885e-03, 3.0604e-02, 9.6671e-01, 5.7246e-03, 8.1277e-03, 9.8615e-01,\n",
      "        2.0451e-03, 1.5990e-02, 9.8197e-01, 5.4416e-03, 1.1946e-01, 8.7509e-01,\n",
      "        4.6421e-04, 9.3606e-01, 6.3481e-02, 9.0639e-03, 6.5609e-02, 9.2533e-01,\n",
      "        7.2713e-03, 1.7734e-02, 9.7499e-01, 9.9013e-03, 1.2743e-01, 8.6267e-01,\n",
      "        9.0556e-01, 9.1516e-02, 2.9194e-03, 7.0864e-03, 1.7099e-02, 9.7582e-01,\n",
      "        3.4525e-03, 3.7616e-03, 9.9279e-01, 1.9990e-04, 9.6348e-01, 3.6319e-02,\n",
      "        1.1697e-02, 3.1241e-02, 9.5706e-01, 9.5332e-03, 2.4339e-01, 7.4708e-01,\n",
      "        3.0117e-05, 1.7995e-03, 9.9817e-01, 4.2382e-03, 7.8078e-02, 9.1768e-01,\n",
      "        5.1457e-03, 1.4606e-02, 9.8025e-01, 2.7168e-01, 6.0672e-03, 7.2226e-01,\n",
      "        4.5802e-03, 2.6641e-02, 9.6878e-01, 1.7317e-03, 7.9952e-03, 9.9027e-01,\n",
      "        1.2029e-03, 1.1075e-02, 9.8772e-01, 8.2225e-04, 1.6904e-02, 9.8227e-01,\n",
      "        4.5899e-03, 5.7793e-03, 9.8963e-01, 2.8879e-03, 1.0337e-02, 9.8677e-01,\n",
      "        3.7425e-04, 8.6714e-03, 9.9095e-01, 5.6880e-03, 1.4136e-01, 8.5295e-01,\n",
      "        2.8667e-03, 1.2096e-03, 9.9592e-01, 2.9028e-03, 3.1651e-02, 9.6545e-01,\n",
      "        4.8013e-03, 1.0918e-01, 8.8602e-01, 4.6036e-03, 6.7322e-03, 9.8866e-01,\n",
      "        1.8921e-03, 4.8369e-04, 9.9762e-01, 4.9992e-04, 3.6560e-03, 9.9584e-01,\n",
      "        1.3733e-03, 2.5793e-02, 9.7283e-01, 9.3300e-04, 6.3550e-03, 9.9271e-01,\n",
      "        7.8464e-03, 1.3384e-02, 9.7877e-01, 9.1101e-04, 4.0895e-03, 9.9500e-01,\n",
      "        3.5478e-02, 1.2030e-01, 8.4422e-01, 1.9815e-02, 2.9960e-01, 6.8059e-01,\n",
      "        3.0232e-02, 1.9493e-01, 7.7484e-01, 1.9211e-03, 6.6214e-02, 9.3186e-01,\n",
      "        5.0975e-03, 8.6715e-02, 9.0819e-01, 2.4121e-03, 3.1981e-04, 9.9727e-01,\n",
      "        7.3825e-03, 2.5312e-02, 9.6731e-01, 9.1136e-03, 1.5445e-01, 8.3644e-01,\n",
      "        8.4606e-03, 4.0802e-02, 9.5074e-01, 6.2746e-03, 7.1281e-01, 2.8092e-01,\n",
      "        1.1091e-02, 1.3484e-01, 8.5407e-01, 2.5080e-03, 9.4823e-01, 4.9264e-02,\n",
      "        8.0473e-03, 9.3687e-01, 5.5084e-02, 2.7564e-03, 7.7895e-02, 9.1935e-01,\n",
      "        1.2267e-02, 3.4937e-02, 9.5280e-01, 6.7796e-03, 1.1145e-01, 8.8177e-01,\n",
      "        6.3370e-03, 3.9501e-01, 5.9865e-01, 4.4374e-01, 1.3864e-01, 4.1762e-01,\n",
      "        6.5788e-02, 1.3682e-01, 7.9740e-01, 2.0323e-01, 2.5834e-01, 5.3843e-01],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 6000\n",
      "netloss -0.2351 regloss 0.0000(beta=9.2007) closs0.0000(model size: 0.6479MB constraint:None)\n",
      "alpha:\n",
      " tensor([1.9957e-01, 4.4210e-01, 3.5834e-01, 5.2937e-03, 9.9280e-02, 8.9543e-01,\n",
      "        8.9988e-04, 1.0306e-02, 9.8879e-01, 2.0779e-03, 2.0513e-03, 9.9587e-01,\n",
      "        7.5680e-04, 5.1980e-03, 9.9405e-01, 1.4088e-03, 2.0011e-02, 9.7858e-01,\n",
      "        1.0670e-04, 2.5998e-02, 9.7390e-01, 2.0014e-03, 9.3600e-01, 6.1995e-02,\n",
      "        4.1518e-03, 8.8889e-01, 1.0695e-01, 7.1287e-03, 6.2000e-02, 9.3087e-01,\n",
      "        9.8817e-01, 1.1450e-02, 3.7898e-04, 2.8908e-03, 4.8083e-03, 9.9230e-01,\n",
      "        5.6082e-03, 3.0782e-02, 9.6361e-01, 6.9045e-05, 9.9250e-01, 7.4332e-03,\n",
      "        5.7528e-03, 9.6479e-03, 9.8460e-01, 2.7665e-03, 8.5508e-01, 1.4216e-01,\n",
      "        1.3149e-05, 4.5142e-04, 9.9954e-01, 1.9858e-03, 4.5845e-02, 9.5217e-01,\n",
      "        2.2516e-03, 4.9768e-03, 9.9277e-01, 4.2544e-01, 4.2684e-03, 5.7029e-01,\n",
      "        1.7370e-03, 7.0686e-03, 9.9119e-01, 6.2581e-04, 2.5571e-03, 9.9682e-01,\n",
      "        3.3846e-04, 2.6250e-03, 9.9704e-01, 2.5345e-04, 4.1238e-03, 9.9562e-01,\n",
      "        1.3211e-03, 1.4640e-03, 9.9721e-01, 1.1286e-03, 3.2987e-03, 9.9557e-01,\n",
      "        1.1934e-04, 2.3856e-03, 9.9750e-01, 1.5550e-03, 7.2985e-01, 2.6859e-01,\n",
      "        8.9286e-04, 3.3403e-04, 9.9877e-01, 8.4531e-04, 8.0718e-03, 9.9108e-01,\n",
      "        1.2100e-03, 2.7918e-02, 9.7087e-01, 1.5638e-03, 2.0273e-03, 9.9641e-01,\n",
      "        5.3913e-04, 1.3433e-04, 9.9933e-01, 1.5172e-04, 8.8037e-04, 9.9897e-01,\n",
      "        4.5268e-04, 7.2790e-03, 9.9227e-01, 3.2894e-04, 2.1308e-03, 9.9754e-01,\n",
      "        2.3110e-03, 3.1411e-03, 9.9455e-01, 2.7400e-04, 1.1592e-03, 9.9857e-01,\n",
      "        1.7287e-02, 6.4535e-02, 9.1818e-01, 5.4333e-03, 7.7080e-02, 9.1749e-01,\n",
      "        9.2576e-03, 9.5254e-01, 3.8204e-02, 5.6060e-04, 1.5853e-02, 9.8359e-01,\n",
      "        1.8941e-03, 2.8967e-02, 9.6914e-01, 9.2187e-04, 1.0225e-04, 9.9898e-01,\n",
      "        4.0061e-03, 1.5482e-02, 9.8051e-01, 5.0879e-03, 1.5038e-01, 8.4453e-01,\n",
      "        4.0056e-03, 1.9191e-02, 9.7680e-01, 1.7813e-03, 9.7148e-01, 2.6736e-02,\n",
      "        1.2958e-02, 4.7006e-01, 5.1698e-01, 1.1214e-03, 9.8932e-01, 9.5628e-03,\n",
      "        6.1908e-03, 9.8230e-01, 1.1514e-02, 7.3943e-04, 1.5316e-02, 9.8394e-01,\n",
      "        7.0734e-03, 8.0587e-01, 1.8706e-01, 3.4286e-03, 6.1262e-01, 3.8395e-01,\n",
      "        1.5735e-03, 9.5936e-01, 3.9064e-02, 5.5859e-01, 1.2868e-01, 3.1273e-01,\n",
      "        9.4194e-01, 1.0092e-02, 4.7966e-02, 2.0323e-01, 2.5834e-01, 5.3844e-01],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 7000\n",
      "netloss -0.2615 regloss 0.0000(beta=7.4005) closs0.0000(model size: 0.6261MB constraint:None)\n",
      "alpha:\n",
      " tensor([1.9955e-01, 4.4211e-01, 3.5833e-01, 2.3807e-03, 5.7897e-02, 9.3972e-01,\n",
      "        4.0637e-04, 4.7123e-03, 9.9488e-01, 9.4343e-04, 8.0766e-04, 9.9825e-01,\n",
      "        3.6075e-04, 2.2897e-03, 9.9735e-01, 6.6144e-04, 7.5306e-03, 9.9181e-01,\n",
      "        4.0814e-05, 8.0450e-03, 9.9191e-01, 7.7660e-04, 9.8345e-01, 1.5771e-02,\n",
      "        1.4161e-03, 9.7948e-01, 1.9104e-02, 5.6558e-03, 3.3897e-02, 9.6045e-01,\n",
      "        9.9557e-01, 4.2834e-03, 1.4299e-04, 1.4118e-03, 1.9606e-03, 9.9663e-01,\n",
      "        5.6847e-03, 9.4876e-01, 4.5551e-02, 3.5009e-05, 9.9704e-01, 2.9246e-03,\n",
      "        3.2083e-03, 4.1333e-03, 9.9266e-01, 9.9732e-04, 9.6213e-01, 3.6873e-02,\n",
      "        7.7430e-06, 1.8649e-04, 9.9981e-01, 1.0320e-03, 2.9407e-02, 9.6956e-01,\n",
      "        1.1235e-03, 2.1975e-03, 9.9668e-01, 4.5060e-01, 3.6597e-03, 5.4574e-01,\n",
      "        8.5551e-04, 2.9021e-03, 9.9624e-01, 2.8917e-04, 1.1317e-03, 9.9858e-01,\n",
      "        1.4709e-04, 1.0615e-03, 9.9879e-01, 1.1717e-04, 1.6885e-03, 9.9819e-01,\n",
      "        5.7015e-04, 6.0099e-04, 9.9883e-01, 5.4633e-04, 1.4677e-03, 9.9799e-01,\n",
      "        5.4221e-05, 1.0086e-03, 9.9894e-01, 4.1639e-04, 9.5137e-01, 4.8213e-02,\n",
      "        3.9395e-04, 1.4094e-04, 9.9947e-01, 3.7615e-04, 3.3532e-03, 9.9627e-01,\n",
      "        5.0435e-04, 1.1552e-02, 9.8794e-01, 7.1557e-04, 8.8246e-04, 9.9840e-01,\n",
      "        2.3228e-04, 5.7282e-05, 9.9971e-01, 6.7508e-05, 3.5902e-04, 9.9957e-01,\n",
      "        2.1559e-04, 3.1666e-03, 9.9662e-01, 1.5306e-04, 9.7586e-04, 9.9887e-01,\n",
      "        1.0129e-03, 1.2525e-03, 9.9773e-01, 1.2108e-04, 5.0195e-04, 9.9938e-01,\n",
      "        7.2278e-03, 3.1613e-02, 9.6116e-01, 2.1405e-03, 2.8209e-02, 9.6965e-01,\n",
      "        6.0409e-03, 9.8155e-01, 1.2410e-02, 2.5522e-04, 6.5125e-03, 9.9323e-01,\n",
      "        9.0228e-04, 1.2916e-02, 9.8618e-01, 4.3648e-04, 4.4516e-05, 9.9952e-01,\n",
      "        2.2720e-03, 1.0071e-02, 9.8766e-01, 3.3733e-03, 3.0081e-01, 6.9582e-01,\n",
      "        2.0951e-03, 9.9867e-03, 9.8792e-01, 8.2556e-04, 9.9051e-01, 8.6679e-03,\n",
      "        5.1720e-03, 9.3113e-01, 6.3701e-02, 6.6195e-04, 9.9566e-01, 3.6800e-03,\n",
      "        9.7414e-03, 9.8457e-01, 5.6884e-03, 3.4180e-04, 6.0350e-03, 9.9362e-01,\n",
      "        2.7491e-03, 9.6454e-01, 3.2707e-02, 8.3927e-04, 9.4212e-01, 5.7042e-02,\n",
      "        6.5603e-04, 9.8802e-01, 1.1320e-02, 6.0072e-01, 1.4309e-01, 2.5619e-01,\n",
      "        9.8420e-01, 2.7758e-03, 1.3027e-02, 2.0323e-01, 2.5834e-01, 5.3843e-01],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8000\n",
      "netloss -0.2870 regloss 0.0000(beta=5.6004) closs0.0000(model size: 0.6080MB constraint:None)\n",
      "alpha:\n",
      " tensor([1.9956e-01, 4.4211e-01, 3.5834e-01, 1.2078e-03, 3.5878e-02, 9.6291e-01,\n",
      "        2.1186e-04, 2.4833e-03, 9.9730e-01, 5.0466e-04, 3.9703e-04, 9.9910e-01,\n",
      "        1.9613e-04, 1.1793e-03, 9.9862e-01, 3.6966e-04, 3.6102e-03, 9.9602e-01,\n",
      "        2.0629e-05, 3.6677e-03, 9.9631e-01, 4.1269e-04, 9.9285e-01, 6.7329e-03,\n",
      "        7.5139e-04, 9.9153e-01, 7.7207e-03, 4.7751e-03, 1.9874e-02, 9.7535e-01,\n",
      "        9.9785e-01, 2.0769e-03, 6.9652e-05, 7.6744e-04, 9.5645e-04, 9.9828e-01,\n",
      "        4.1936e-03, 9.8214e-01, 1.3666e-02, 2.0154e-05, 9.9855e-01, 1.4282e-03,\n",
      "        1.8839e-03, 2.0530e-03, 9.9606e-01, 5.0563e-04, 9.8390e-01, 1.5595e-02,\n",
      "        5.1027e-06, 9.3448e-05, 9.9990e-01, 5.6559e-04, 1.9222e-02, 9.8021e-01,\n",
      "        6.1380e-04, 1.1158e-03, 9.9827e-01, 4.7912e-01, 3.1122e-03, 5.1777e-01,\n",
      "        4.7214e-04, 1.4288e-03, 9.9810e-01, 1.5190e-04, 5.8219e-04, 9.9927e-01,\n",
      "        7.5901e-05, 5.2577e-04, 9.9940e-01, 6.3110e-05, 8.3877e-04, 9.9910e-01,\n",
      "        2.9160e-04, 2.9917e-04, 9.9941e-01, 2.9473e-04, 7.5378e-04, 9.9895e-01,\n",
      "        2.8605e-05, 5.0857e-04, 9.9946e-01, 1.9171e-04, 9.8149e-01, 1.8315e-02,\n",
      "        2.0303e-04, 7.1002e-05, 9.9973e-01, 1.9698e-04, 1.6779e-03, 9.9813e-01,\n",
      "        2.5449e-04, 5.7809e-03, 9.9396e-01, 3.7574e-04, 4.5104e-04, 9.9917e-01,\n",
      "        1.1881e-04, 2.9139e-05, 9.9985e-01, 3.5155e-05, 1.7814e-04, 9.9979e-01,\n",
      "        1.1785e-04, 1.6221e-03, 9.9826e-01, 8.1019e-05, 5.1274e-04, 9.9941e-01,\n",
      "        5.2242e-04, 6.1212e-04, 9.9887e-01, 6.2711e-05, 2.5719e-04, 9.9968e-01,\n",
      "        3.3460e-03, 1.6242e-02, 9.8041e-01, 1.0377e-03, 1.3078e-02, 9.8588e-01,\n",
      "        5.5224e-03, 9.8835e-01, 6.1321e-03, 1.3622e-04, 3.2453e-03, 9.9662e-01,\n",
      "        4.8255e-04, 6.5835e-03, 9.9293e-01, 2.3238e-04, 2.2673e-05, 9.9974e-01,\n",
      "        1.3037e-03, 6.5874e-03, 9.9211e-01, 1.4455e-03, 8.3285e-01, 1.6570e-01,\n",
      "        1.1535e-03, 5.4284e-03, 9.9342e-01, 4.5012e-04, 9.9566e-01, 3.8926e-03,\n",
      "        2.4287e-03, 9.7683e-01, 2.0739e-02, 4.2718e-04, 9.9780e-01, 1.7735e-03,\n",
      "        8.1996e-01, 1.7443e-01, 5.6083e-03, 1.8680e-04, 2.9610e-03, 9.9685e-01,\n",
      "        1.6155e-03, 9.8560e-01, 1.2784e-02, 3.7039e-04, 9.7922e-01, 2.0413e-02,\n",
      "        3.4641e-04, 9.9471e-01, 4.9406e-03, 5.3932e-01, 2.5194e-01, 2.0874e-01,\n",
      "        9.9283e-01, 1.2618e-03, 5.9126e-03, 2.0323e-01, 2.5834e-01, 5.3843e-01],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 9000\n",
      "netloss -0.2943 regloss 0.0000(beta=3.8002) closs0.0000(model size: 0.6024MB constraint:None)\n",
      "alpha:\n",
      " tensor([1.9951e-01, 4.4215e-01, 3.5833e-01, 6.2058e-04, 2.1520e-02, 9.7786e-01,\n",
      "        1.1622e-04, 1.3760e-03, 9.9851e-01, 2.9144e-04, 2.1436e-04, 9.9949e-01,\n",
      "        1.1206e-04, 6.4433e-04, 9.9924e-01, 2.1795e-04, 1.8823e-03, 9.9790e-01,\n",
      "        1.1362e-05, 1.8968e-03, 9.9809e-01, 2.3771e-04, 9.9642e-01, 3.3405e-03,\n",
      "        4.3762e-04, 9.9576e-01, 3.8038e-03, 4.3069e-03, 1.2228e-02, 9.8347e-01,\n",
      "        9.9886e-01, 1.0988e-03, 3.6974e-05, 4.2991e-04, 4.9836e-04, 9.9907e-01,\n",
      "        4.3992e-03, 9.8924e-01, 6.3588e-03, 1.2020e-05, 9.9924e-01, 7.5259e-04,\n",
      "        1.0957e-03, 1.0710e-03, 9.9783e-01, 2.8516e-04, 9.9184e-01, 7.8765e-03,\n",
      "        3.4818e-06, 5.0283e-05, 9.9995e-01, 3.0354e-04, 1.1440e-02, 9.8826e-01,\n",
      "        3.4204e-04, 5.9786e-04, 9.9906e-01, 4.8603e-01, 2.1133e-03, 5.1186e-01,\n",
      "        2.7030e-04, 7.5413e-04, 9.9898e-01, 8.2811e-05, 3.1588e-04, 9.9960e-01,\n",
      "        4.1751e-05, 2.8112e-04, 9.9968e-01, 3.5877e-05, 4.4768e-04, 9.9952e-01,\n",
      "        1.5841e-04, 1.5982e-04, 9.9968e-01, 1.6504e-04, 4.0927e-04, 9.9943e-01,\n",
      "        1.5923e-05, 2.7376e-04, 9.9971e-01, 1.0406e-04, 9.9104e-01, 8.8524e-03,\n",
      "        1.1045e-04, 3.8190e-05, 9.9985e-01, 1.0926e-04, 8.9806e-04, 9.9899e-01,\n",
      "        1.3741e-04, 3.0984e-03, 9.9676e-01, 2.0720e-04, 2.4450e-04, 9.9955e-01,\n",
      "        6.4916e-05, 1.5853e-05, 9.9992e-01, 1.9426e-05, 9.5273e-05, 9.9989e-01,\n",
      "        6.7459e-05, 8.8184e-04, 9.9905e-01, 4.4844e-05, 2.8242e-04, 9.9967e-01,\n",
      "        2.8665e-04, 3.2396e-04, 9.9939e-01, 3.4457e-05, 1.4030e-04, 9.9983e-01,\n",
      "        1.4944e-03, 8.2087e-03, 9.9030e-01, 5.2338e-04, 6.5263e-03, 9.9295e-01,\n",
      "        7.9339e-03, 9.8822e-01, 3.8455e-03, 7.6630e-05, 1.7349e-03, 9.9819e-01,\n",
      "        2.6590e-04, 3.4889e-03, 9.9625e-01, 1.2898e-04, 1.2295e-05, 9.9986e-01,\n",
      "        7.0889e-04, 4.0099e-03, 9.9528e-01, 5.6385e-04, 9.5206e-01, 4.7380e-02,\n",
      "        6.2513e-04, 2.8631e-03, 9.9651e-01, 2.5252e-04, 9.9780e-01, 1.9463e-03,\n",
      "        1.2543e-03, 9.8917e-01, 9.5708e-03, 2.8111e-04, 9.9879e-01, 9.2860e-04,\n",
      "        9.7611e-01, 2.2869e-02, 1.0184e-03, 1.0798e-04, 1.5772e-03, 9.9831e-01,\n",
      "        8.0956e-04, 9.9354e-01, 5.6497e-03, 1.8526e-04, 9.9031e-01, 9.5027e-03,\n",
      "        1.9373e-04, 9.9735e-01, 2.4600e-03, 5.1564e-01, 3.9100e-01, 9.3361e-02,\n",
      "        9.9616e-01, 6.7303e-04, 3.1630e-03, 2.0323e-01, 2.5834e-01, 5.3842e-01],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 10000\n",
      "netloss -0.3219 regloss 0.0000(beta=2.0000) closs0.0000(model size: 0.6013MB constraint:None)\n",
      "alpha:\n",
      " tensor([1.9949e-01, 4.4217e-01, 3.5833e-01, 3.3967e-04, 1.3327e-02, 9.8633e-01,\n",
      "        6.6633e-05, 7.9585e-04, 9.9914e-01, 1.7286e-04, 1.2091e-04, 9.9971e-01,\n",
      "        6.6291e-05, 3.6788e-04, 9.9957e-01, 1.3380e-04, 1.0438e-03, 9.9882e-01,\n",
      "        6.5777e-06, 1.0503e-03, 9.9894e-01, 1.4394e-04, 9.9805e-01, 1.8086e-03,\n",
      "        2.6707e-04, 9.9768e-01, 2.0529e-03, 3.8793e-03, 7.5111e-03, 9.8861e-01,\n",
      "        9.9936e-01, 6.1984e-04, 2.0908e-05, 2.4969e-04, 2.7493e-04, 9.9948e-01,\n",
      "        1.0787e-02, 9.8529e-01, 3.9203e-03, 7.3714e-06, 9.9957e-01, 4.1975e-04,\n",
      "        6.5557e-04, 5.9312e-04, 9.9875e-01, 1.7061e-04, 9.9548e-01, 4.3468e-03,\n",
      "        2.4308e-06, 2.8345e-05, 9.9997e-01, 1.7108e-04, 7.0167e-03, 9.9281e-01,\n",
      "        1.9733e-04, 3.3293e-04, 9.9947e-01, 5.1205e-01, 1.4685e-03, 4.8648e-01,\n",
      "        1.5894e-04, 4.1807e-04, 9.9942e-01, 4.7046e-05, 1.7938e-04, 9.9977e-01,\n",
      "        2.4020e-05, 1.5855e-04, 9.9982e-01, 2.1205e-05, 2.5166e-04, 9.9973e-01,\n",
      "        9.0337e-05, 9.0106e-05, 9.9982e-01, 9.5612e-05, 2.3184e-04, 9.9967e-01,\n",
      "        9.2364e-06, 1.5476e-04, 9.9984e-01, 5.9772e-05, 9.9534e-01, 4.6025e-03,\n",
      "        6.2928e-05, 2.1576e-05, 9.9992e-01, 6.3305e-05, 5.0635e-04, 9.9943e-01,\n",
      "        7.8286e-05, 1.7546e-03, 9.9817e-01, 1.1923e-04, 1.3906e-04, 9.9974e-01,\n",
      "        3.7050e-05, 9.0282e-06, 9.9995e-01, 1.1185e-05, 5.3607e-05, 9.9994e-01,\n",
      "        4.0081e-05, 5.0186e-04, 9.9946e-01, 2.5874e-05, 1.6261e-04, 9.9981e-01,\n",
      "        1.6377e-04, 1.8065e-04, 9.9966e-01, 1.9765e-05, 8.0129e-05, 9.9990e-01,\n",
      "        7.3679e-04, 4.4561e-03, 9.9481e-01, 2.8377e-04, 3.5304e-03, 9.9619e-01,\n",
      "        6.1154e-01, 3.8041e-01, 8.0473e-03, 4.5010e-05, 9.7840e-04, 9.9898e-01,\n",
      "        1.5330e-04, 1.9520e-03, 9.9789e-01, 7.4344e-05, 6.9907e-06, 9.9992e-01,\n",
      "        4.0315e-04, 2.5251e-03, 9.9707e-01, 2.8429e-04, 9.7953e-01, 2.0189e-02,\n",
      "        3.5497e-04, 1.5919e-03, 9.9805e-01, 1.4784e-04, 9.9880e-01, 1.0514e-03,\n",
      "        7.0184e-04, 9.9435e-01, 4.9447e-03, 1.8657e-04, 9.9930e-01, 5.1175e-04,\n",
      "        9.9044e-01, 9.1199e-03, 4.3775e-04, 6.4609e-05, 8.8296e-04, 9.9905e-01,\n",
      "        4.5099e-04, 9.9667e-01, 2.8837e-03, 1.0219e-04, 9.9493e-01, 4.9682e-03,\n",
      "        1.1359e-04, 9.9856e-01, 1.3245e-03, 4.2979e-01, 5.2852e-01, 4.1690e-02,\n",
      "        9.9784e-01, 3.7866e-04, 1.7828e-03, 2.0324e-01, 2.5834e-01, 5.3842e-01],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "v = optimize(n_iteration=10000,lr=2e-3,beta=[20,2],lambda1=0,lambda2=0,naive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "36728f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_decision\n",
      " {'conv1': '4bits', 'layer1.0.conv1': '8bits', 'layer1.0.conv2': '8bits', 'layer1.1.conv1': '8bits', 'layer1.1.conv2': '8bits', 'layer1.2.conv1': '8bits', 'layer1.2.conv2': '8bits', 'layer1.3.conv1': '4bits', 'layer1.3.conv2': '4bits', 'layer1.4.conv1': '8bits', 'layer1.4.conv2': '2bits', 'layer1.5.conv1': '8bits', 'layer1.5.conv2': '4bits', 'layer1.6.conv1': '4bits', 'layer1.6.conv2': '8bits', 'layer1.7.conv1': '4bits', 'layer1.7.conv2': '8bits', 'layer1.8.conv1': '8bits', 'layer1.8.conv2': '8bits', 'layer2.0.conv1': '2bits', 'layer2.0.conv2': '8bits', 'layer2.0.downsample.0': '8bits', 'layer2.1.conv1': '8bits', 'layer2.1.conv2': '8bits', 'layer2.2.conv1': '8bits', 'layer2.2.conv2': '8bits', 'layer2.3.conv1': '8bits', 'layer2.3.conv2': '4bits', 'layer2.4.conv1': '8bits', 'layer2.4.conv2': '8bits', 'layer2.5.conv1': '8bits', 'layer2.5.conv2': '8bits', 'layer2.6.conv1': '8bits', 'layer2.6.conv2': '8bits', 'layer2.7.conv1': '8bits', 'layer2.7.conv2': '8bits', 'layer2.8.conv1': '8bits', 'layer2.8.conv2': '8bits', 'layer3.0.conv1': '8bits', 'layer3.0.conv2': '8bits', 'layer3.0.downsample.0': '2bits', 'layer3.1.conv1': '8bits', 'layer3.1.conv2': '8bits', 'layer3.2.conv1': '8bits', 'layer3.2.conv2': '8bits', 'layer3.3.conv1': '4bits', 'layer3.3.conv2': '8bits', 'layer3.4.conv1': '4bits', 'layer3.4.conv2': '4bits', 'layer3.5.conv1': '4bits', 'layer3.5.conv2': '2bits', 'layer3.6.conv1': '8bits', 'layer3.6.conv2': '4bits', 'layer3.7.conv1': '4bits', 'layer3.7.conv2': '4bits', 'layer3.8.conv1': '4bits', 'layer3.8.conv2': '2bits', 'fc': '8bits'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 0.8681,\n",
       " 'qtl_acc': 0.8681,\n",
       " 'mean_loss': 0.4387716224676446,\n",
       " 'qtl_loss': 0.4387716224676446,\n",
       " 'test time': 2.700641393661499,\n",
       " 'acc_list': array([0.8681]),\n",
       " 'loss_list': array([0.43877162])}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f242b9d1",
   "metadata": {},
   "source": [
    "## Random MPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c568ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_size = []\n",
    "# random_acc = []\n",
    "for i in range(500):\n",
    "    v = torch.randn(L)\n",
    "    res,size = evaluate_decision(v)\n",
    "    random_size.append(size)\n",
    "    random_acc.append(res['mean_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4da697",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_size,random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18de513",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resnet56_random_baseline.pkl','wb') as f:\n",
    "    pickle.dump({'size':random_size,'acc':random_acc},f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61085bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(random_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d354c4",
   "metadata": {},
   "source": [
    "## Pareto-Frontier of FeintLady vs Inter-Layer Dependency Unaware Optimization (Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48f9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fix lambda1 to 1e-3\n",
    "# search lambda2 from 1e-5 to 1e-10\n",
    "# each HP (lambda2) try 5 runs\n",
    "\n",
    "lambda2s = np.logspace(-5,-10,50) #lambda1=1e-3,n=5000,lr=1e-3,beta=[20,2] for resnet20 on cifar10\n",
    "lambda2s = np.logspace(-5,-10,50) #lambda1=1e-1,n=5000,lr=1e-3,beta=[20,2] for resnet20 on cifar100\n",
    "sample_size = 5\n",
    "naive_loss,naive_size = [],[]\n",
    "feint_loss,feint_size = [],[]\n",
    "\n",
    "for lambda2 in lambda2s:\n",
    "    print('lambda2:',lambda2)\n",
    "    for repeat in range(sample_size):\n",
    "        v = optimize(n_iteration=5000,lr=1e-3,beta=[20,2],lambda1=1e-1,lambda2=lambda2,naive=True)\n",
    "        perf,size = evaluate_decision(v)\n",
    "        naive_loss.append(perf)\n",
    "        naive_size.append(size)\n",
    "\n",
    "        v = optimize(n_iteration=5000,lr=1e-3,beta=[20,2],lambda1=1e-1,lambda2=lambda2,naive=False)\n",
    "        perf,size = evaluate_decision(v)\n",
    "        feint_loss.append(perf)\n",
    "        feint_size.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12da08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_size = np.array(naive_size)\n",
    "feint_size = np.array(feint_size)\n",
    "naive_acc = [naive_loss[i]['mean_acc'] for i in range(len(naive_loss))]\n",
    "feint_acc = [feint_loss[i]['mean_acc'] for i in range(len(feint_loss))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('c100resnet56scatterplot.pkl','wb') as f:\n",
    "    pickle.dump({'naive_size':naive_size,'naive_acc':naive_acc,\n",
    "                 'feint_size':feint_size,'feint_acc':feint_acc},f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa465467",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(naive_size,naive_acc,color='red',alpha=0.5,label='Inter-Layer Depedency Unaware Optimization')\n",
    "plt.scatter(feint_size,feint_acc,color='blue',alpha=0.5,label='FeintLady Optimization')\n",
    "plt.xlabel('Hardware cost')\n",
    "plt.ylabel('Performance')\n",
    "plt.legend()\n",
    "# plt.imshow(X_std,cmap='hot')\n",
    "# plt.xlabel('layer index')\n",
    "# plt.ylabel('layer index')\n",
    "plt.savefig('c100resnet56FeintEffecacy.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a211db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(naive_size,naive_acc,color='red',alpha=0.5,label='naive')\n",
    "# plt.scatter(naive_size,naive_acc,color='blue',alpha=0.5,label='feint')\n",
    "plt.xlabel('hardware cost')\n",
    "plt.ylabel('performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc8630",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8252488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fname = 'result_cifar100_shufflenetv2_x2_0_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_sfn20 = pickle.load(f)\n",
    "\n",
    "fname = 'result_cifar100_shufflenetv2_x1_5_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_sfn15 = pickle.load(f)\n",
    "    \n",
    "fname = 'result_cifar100_mobilenetv2_x1_4_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_mbn14 = pickle.load(f)\n",
    "\n",
    "fname = 'result_cifar100_mobilenetv2_x0_75_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_mbn075 = pickle.load(f)\n",
    "    \n",
    "\n",
    "fname = 'result_cifar100_resnet56_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_rsn56 = pickle.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in res_rsn56: print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF_(xs,ys,mode='max',roundtoprecision=1):\n",
    "    pf = {}\n",
    "    for x,y in zip(xs,ys):\n",
    "        new_x = round(x,roundtoprecision)\n",
    "        if new_x in pf:\n",
    "            pf[new_x] = eval(mode)(pf[new_x],y)\n",
    "        else:\n",
    "            pf[new_x] = y\n",
    "    \n",
    "    pf_x,pf_y = [],[]\n",
    "    \n",
    "    for x in pf:\n",
    "        pf_x.append(x)\n",
    "        pf_y.append(pf[x])\n",
    "    \n",
    "    pf_x, pf_y = np.array(pf_x),np.array(pf_y)\n",
    "    \n",
    "    return pf_x,pf_y\n",
    "\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de56442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_1_mbn075,y_1_mbn075 = getPF(res_mbn075['naive_size'],res_mbn075['naive_acc'])\n",
    "x_2_mbn075,y_2_mbn075 = getPF(res_mbn075['feint_size'],res_mbn075['feint_acc'])\n",
    "\n",
    "x_1_mbn14,y_1_mbn14 = getPF(res_mbn14['naive_size'],res_mbn14['naive_acc'])\n",
    "x_2_mbn14,y_2_mbn14 = getPF(res_mbn14['feint_size'],res_mbn14['feint_acc'])\n",
    "\n",
    "x_1_sfn20,y_1_sfn20 = getPF(res_sfn20['naive_size'],res_sfn20['naive_acc'])\n",
    "x_2_sfn20,y_2_sfn20 = getPF(res_sfn20['feint_size'],res_sfn20['feint_acc'])\n",
    "\n",
    "x_1_sfn15,y_1_sfn15 = getPF(res_sfn15['naive_size'],res_sfn15['naive_acc'])\n",
    "x_2_sfn15,y_2_sfn15 = getPF(res_sfn15['feint_size'],res_sfn15['feint_acc'])\n",
    "\n",
    "x_1_rsn56,y_1_rsn56 = getPF(res_rsn56['naive_size'],res_rsn56['naive_acc'])\n",
    "x_2_rsn56,y_2_rsn56 = getPF(res_rsn56['feint_size'],res_rsn56['feint_acc'])\n",
    "\n",
    "#x_random,y_random = getPF(random_size,random_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random baseline vs use/not use gradient on resnet56\n",
    "# plt.rcParams['figure.figsize'] = (12,8)\n",
    "fname = 'result_cifar10_resnet56_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_rsn = pickle.load(f)\n",
    "fname = 'resnet56_random_baseline.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    rand_rsn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8529a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(res_rsn['feint_size'][:],res_rsn['feint_acc'][:],color='blue',\n",
    "            marker='o',s=20,alpha=0.5,label='Cross-layer Gradients Used')\n",
    "\n",
    "plt.scatter(res_rsn['naive_size'][:],res_rsn['naive_acc'][:],color='red',\n",
    "            marker='o',s=20,alpha=0.5,label='Cross-layer Gradients Ignored')\n",
    "\n",
    "plt.scatter(rand_rsn['size'],rand_rsn['acc'],color='black',marker='o',s=20,alpha=0.5,\n",
    "            label='Random Guess')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "plt.savefig('c10resnet.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105629d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "plt.plot(x_1_mbn14,y_1_mbn14,color='red',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='mobilenetv2_x1_4(N)')\n",
    "plt.plot(x_2_mbn14,y_2_mbn14,color='blue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='mobilenetv2_x1_4(A)')\n",
    "\n",
    "# plt.plot(x_1_mbn075,y_1_mbn075,color='red',\n",
    "#          marker='^',markersize=3,alpha=0.5,linewidth=1,label='mobilenetv2_x0_75(N)')\n",
    "# plt.plot(x_2_mbn075,y_2_mbn075,color='blue',\n",
    "#          marker='v',markersize=3,alpha=0.5,linewidth=1,label='mobilenetv2_x0_75(A)')\n",
    "\n",
    "plt.plot(x_1_sfn20,y_1_sfn20,color='lightcoral',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='shufflenetv2_x2_0(N)')\n",
    "plt.plot(x_2_sfn20,y_2_sfn20,color='lightblue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='sufflenetv2_x2_0(A)')\n",
    "\n",
    "plt.plot(x_1_sfn15,y_1_sfn15,color='orangered',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='shufflenetv2_x1_5(N)')\n",
    "plt.plot(x_2_sfn15,y_2_sfn15,color='cyan',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='sufflenetv2_x1_5(A)')\n",
    "\n",
    "plt.plot(x_1_rsn56,y_1_rsn56,color='darkred',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='resnet56(N)')\n",
    "plt.plot(x_2_rsn56,y_2_rsn56,color='darkblue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='resnet56(A)')\n",
    "\n",
    "\n",
    "# plt.scatter(x_1,y_1,color='red',marker='^',s=10,alpha=0.5)\n",
    "# plt.scatter(x_2,y_2,color='blue',marker='v',s=10,alpha=0.5)\n",
    "\n",
    "plt.ylim([0.68,0.76])\n",
    "plt.xlim([0.,4])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "\n",
    "# plt.ylim([0.7,0.755])\n",
    "# plt.xlim([2.7,4.0])\n",
    "plt.savefig('c100pareto_3nets.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7068778",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "plt.plot(np.log(x_1_mbn)[100:],y_1_mbn[100:],color='red',marker='^',markersize=3,alpha=0.5,linewidth=1,label='mobilenet(A)')\n",
    "plt.plot(np.log(x_2_mbn)[100:],y_2_mbn[100:],color='blue',marker='v',markersize=3,alpha=0.5,linewidth=1,label='mobilenet(N)')\n",
    "\n",
    "plt.plot(np.log(x_1_sfn)[200:],y_1_sfn[200:],color='lightcoral',marker='^',markersize=3,alpha=0.5,linewidth=1,label='shufflenet(A)')\n",
    "plt.plot(np.log(x_2_sfn)[200:],y_2_sfn[200:],color='lightblue',marker='v',markersize=3,alpha=0.5,linewidth=1,label='sufflenet(N)')\n",
    "\n",
    "plt.plot(np.log(x_1_rsn)[0:],y_1_rsn[0:],color='darkred',marker='^',markersize=3,alpha=0.5,linewidth=1,label='resnet(A)')\n",
    "plt.plot(np.log(x_2_rsn)[0:],y_2_rsn[0:],color='darkblue',marker='v',markersize=3,alpha=0.5,linewidth=1,label='resnet(N)')\n",
    "# plt.scatter(x_1,y_1,color='red',marker='^',s=10,alpha=0.5)\n",
    "# plt.scatter(x_2,y_2,color='blue',marker='v',s=10,alpha=0.5)\n",
    "# plt.ylim([0.66,0.76])\n",
    "# plt.xlim([0.5,3.5])\n",
    "plt.ylim([0.65,0.76])\n",
    "plt.xlim([-1,1.8])\n",
    "plt.xlabel('Log Model Size (in MB)',fontsize=20)\n",
    "plt.ylabel('Test Accuracy',fontsize=20)\n",
    "plt.legend()\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "# plt.ylim([0.7,0.755])\n",
    "# plt.xlim([2.7,4.0])\n",
    "#plt.savefig('c100pareto.pdf',transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e6627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
