{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2109f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zihao/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch,torchvision,os,time\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from utils.util import get_loader,evaluate\n",
    "from utils.layer import qConv2d,qLinear\n",
    "from utils.train import QAVAT_train\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models             \n",
    "\n",
    "              # for example model\n",
    "from mqbench.prepare_by_platform import prepare_by_platform   # add quant nodes for specific Backend\n",
    "from mqbench.prepare_by_platform import BackendType           # contain various Backend, like TensorRT, NNIE, etc.\n",
    "from mqbench.utils.state import enable_calibration            # turn on calibration algorithm, determine scale, zero_point, etc.\n",
    "from mqbench.utils.state import enable_quantization           # turn on actually quantization, like FP32 -> INT8\n",
    "from mqbench.utils.state import disable_all           # turn on actually quantization, like FP32 -> INT8\n",
    "from copy import deepcopy\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet56\", pretrained=True).cuda()\n",
    "# model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_mobilenetv2_x0_5\", pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53657ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train,test = get_loader('cifar10'.upper(),batch_size=128,test_batch_size=128)\n",
    "train.num_workers = 2\n",
    "test.num_workers = 2\n",
    "train.pin_in_memory = True\n",
    "test.pin_in_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f67af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration data used to calibrate PTQ and MPQ\n",
    "calib_data = []\n",
    "i = 0\n",
    "for img,label in train:\n",
    "    i += 1\n",
    "    calib_data.append((img,label))\n",
    "    if i == 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d31b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MPQ_scheme = (2,4,8)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007f436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare 2bits model using MQBench\n",
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 2 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 2 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Set layer conv1 to 8 bit.\n",
      "[MQBENCH] INFO: Set layer fc to 8 bit.\n",
      "[MQBENCH] INFO: Set x post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set view post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant view_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n"
     ]
    }
   ],
   "source": [
    "def getModuleByName(model,moduleName):\n",
    "    '''\n",
    "        replace module with name modelName.moduleName with newModule\n",
    "    '''\n",
    "    tokens = moduleName.split('.')\n",
    "    m = model\n",
    "    for tok in tokens:\n",
    "        m = getattr(m,tok)\n",
    "    return m\n",
    "\n",
    "for b in MPQ_scheme:\n",
    "    mqb_fp_model = deepcopy(model)\n",
    "    \n",
    "    # MSE calibration on model parameters\n",
    "    backend = BackendType.Academic\n",
    "    extra_config = {\n",
    "        'extra_qconfig_dict': {\n",
    "            'w_observer': 'MSEObserver',                              # custom weight observer\n",
    "            'a_observer': 'EMAMSEObserver',                              # custom activation observer\n",
    "            'w_fakequantize': 'FixedFakeQuantize',                    # custom weight fake quantize function\n",
    "            'a_fakequantize': 'FixedFakeQuantize',                    # custom activation fake quantize function\n",
    "            'w_qscheme': {\n",
    "                'bit': b,                                             # custom bitwidth for weight,\n",
    "                'symmetry': True,                                    # custom whether quant is symmetric for weight,\n",
    "                'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for weight,\n",
    "                'pot_scale': False,                                   # custom whether scale is power of two for weight.\n",
    "            },\n",
    "            'a_qscheme': {\n",
    "                'bit': b,                                             # custom bitwidth for activation,\n",
    "                'symmetry': False,                                    # custom whether quant is symmetric for activation,\n",
    "                'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for activation,\n",
    "                'pot_scale': False,                                   # custom whether scale is power of two for activation.\n",
    "            }\n",
    "        }                                                         # custom tracer behavior, checkout https://github.com/pytorch/pytorch/blob/efcbbb177eacdacda80b94ad4ce34b9ed6cf687a/torch/fx/_symbolic_trace.py#L836\n",
    "    }\n",
    "    print(f'Prepare {b}bits model using MQBench')\n",
    "\n",
    "    exec(f'mqb_{b}bits_model=prepare_by_platform(mqb_fp_model, backend,extra_config).cuda()')\n",
    "    \n",
    "    # calibration loop\n",
    "    enable_calibration(eval(f'mqb_{b}bits_model'))\n",
    "    for img,label in calib_data:\n",
    "        eval(f'mqb_{b}bits_model')(img.cuda())  \n",
    "    disable_all(eval(f'mqb_{b}bits_model'))\n",
    "    # evaluation loop\n",
    "    enable_quantization(eval(f'mqb_{b}bits_model'))\n",
    "    print('evaluate mqb quantized model')\n",
    "    evaluate(test,eval(f'mqb_{b}bits_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test,mqb_2bits_model),evaluate(test,mqb_4bits_model), evaluate(test,mqb_8bits_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670eec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mqb_fp_model = deepcopy(mqb_8bits_model)\n",
    "disable_all(mqb_fp_model)\n",
    "mqb_mix_model = deepcopy(mqb_fp_model)\n",
    "\n",
    "# 1. record all modules we want to consider\n",
    "types_to_quant = (torch.nn.Conv2d,torch.nn.Linear)\n",
    "\n",
    "layer_input_map = {}\n",
    "\n",
    "for node in mqb_8bits_model.graph.nodes:\n",
    "    try:\n",
    "        node_target = getModuleByName(mqb_mix_model,node.target)\n",
    "        if isinstance(node_target,types_to_quant):\n",
    "            node_args = node.args[0]\n",
    "            print('input of ',node.target,' is ',node_args)\n",
    "            layer_input_map[node.target] = str(node_args.target)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fd113",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_metric = ('mean_acc',evaluate(test,mqb_fp_model)['mean_acc'])\n",
    "ref_metric = ('mean_loss',evaluate(calib_data,mqb_fp_model)['mean_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dcd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(perturb_scheme):\n",
    "    # perturb_scheme: {layer_name:(act_bits,weight_bits)}\n",
    "    for layer_name in perturb_scheme:\n",
    "        a_bits,w_bits = perturb_scheme[layer_name]\n",
    "        \n",
    "        if a_bits is not None:\n",
    "            mix_module = getModuleByName(mqb_mix_model,layer_name)\n",
    "            tar_module = getModuleByName(eval(f'mqb_{w_bits}bits_model'),layer_name)\n",
    "            # replace input quant to use a_bits quantization\n",
    "            a_cmd = f'mix_module.weight_fake_quant=tar_module.weight_fake_quant'\n",
    "            exec(a_cmd)\n",
    "        \n",
    "        if w_bits is not None:\n",
    "        \n",
    "            # replace weight quant to use w_bits quantization\n",
    "            w_cmd = f'mqb_mix_model.{layer_input_map[layer_name]}=mqb_{a_bits}bits_model.{layer_input_map[layer_name]}'\n",
    "            exec(w_cmd)\n",
    "        \n",
    "        #print(layer_name)\n",
    "        #print(a_cmd)\n",
    "        #print(w_cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturb functionality test\n",
    "perturb_scheme = {}\n",
    "for layer_name in layer_input_map:\n",
    "    perturb_scheme[layer_name] = (4,8)\n",
    "perturb(perturb_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbd747",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test,mqb_mix_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "mqb_mix_model = deepcopy(mqb_8bits_model)\n",
    "disable_all(mqb_mix_model)\n",
    "evaluate(test,mqb_mix_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846ea48",
   "metadata": {},
   "source": [
    "## CLADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6716b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_loss(perturb_scheme,ref_metric=ref_metric,eval_data=calib_data,printInfo=False):\n",
    "    global mqb_mix_model\n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        perturb(perturb_scheme)\n",
    "            \n",
    "        # do evaluation\n",
    "        res = evaluate(eval_data,mqb_mix_model)\n",
    "        perturbed_loss = res[ref_metric[0]] - ref_metric[1]\n",
    "        \n",
    "        if printInfo:\n",
    "            print(res)\n",
    "        \n",
    "        # recover layers\n",
    "        mqb_mix_model = deepcopy(mqb_fp_model)\n",
    "            \n",
    "    return perturbed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4162ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# perturb loss functionality check\n",
    "for layer in layer_input_map:\n",
    "    for a_bits in MPQ_scheme:\n",
    "        for w_bits in MPQ_scheme:\n",
    "            p = perturb_loss({layer:(a_bits,w_bits)},eval_data=test,printInfo=True)\n",
    "            print(f'{layer} (a:{a_bits} bits,w:{w_bits} bits), accuracy degradation: {p*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47dd85f",
   "metadata": {},
   "source": [
    "## Build Cached Grad if not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f370df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "s_time = time.time()\n",
    "cached = {}\n",
    "for n in layers_to_quant:\n",
    "    for m in layers_to_quant:\n",
    "        for s1 in MPQ_scheme:\n",
    "            for s2 in MPQ_scheme:\n",
    "                if (n,m,s1,s2) not in cached:\n",
    "                    if n == m:\n",
    "                        print(f'mix perturb layer {n} to {s1}bits and {s2}bits')\n",
    "                        p = perturb_loss({n:(s1,s2)},ref_metric,calib_data,mix_perturb=True)\n",
    "                    else:\n",
    "                        print(f'perturb layer {n} to {s1}bits and layer {m} to {s2}bits')\n",
    "                        p = perturb_loss({n:s1,m:s2},ref_metric,calib_data,mix_perturb=False)\n",
    "                    \n",
    "                    cached[(n,m,s1,s2)] = cached[(m,n,s2,s1)] = p\n",
    "                    \n",
    "print(f'{time.time()-s_time:.2f} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239967a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index = {}\n",
    "cnt = 0\n",
    "for layer in layers_to_quant:\n",
    "    for s in MPQ_scheme:\n",
    "        layer_index[layer+f'{s}bits'] = cnt\n",
    "        cnt += 1\n",
    "L = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hm = np.zeros(shape=(L,L))\n",
    "for n in layers_to_quant:\n",
    "    for m in layers_to_quant:\n",
    "        for s1 in MPQ_scheme:\n",
    "            for s2 in MPQ_scheme:\n",
    "                hm[layer_index[n+f'{s1}bits'],layer_index[m+f'{s2}bits']] = cached[(n,m,s1,s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad = np.zeros_like(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99559c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generalw248_c10resnet56_calib','wb') as f:\n",
    "    pickle.dump({'Ltilde':hm,'layer_index':layer_index},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_loss(['conv1',],ref_metric,eval_data=calib_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc001d",
   "metadata": {},
   "source": [
    "## Load Cached Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generalw248_c10resnet56_calib','rb') as f:\n",
    "    hm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf87d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2layerscheme = [None for i in range(hm['Ltilde'].shape[0])]\n",
    "\n",
    "for name in hm['layer_index']:\n",
    "    index = hm['layer_index'][name]\n",
    "    layer_name = name[:-5]\n",
    "    scheme = name[-5:]\n",
    "    a = hm['Ltilde']\n",
    "    print(f'index {index} layer {layer_name} scheme {scheme} Ltilde {a[index,index].item():.6f}')\n",
    "    \n",
    "    index2layerscheme[index] = (layer_name,scheme)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hm['Ltilde'],cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = hm['Ltilde'].shape[0]\n",
    "cached_grad = np.zeros_like(hm['Ltilde'])\n",
    "for i in range(L):\n",
    "    for j in range(L):\n",
    "        layer_i,scheme_i = index2layerscheme[i]\n",
    "        layer_j,scheme_j = index2layerscheme[j]\n",
    "        if layer_i == layer_j:\n",
    "            if scheme_i == scheme_j:\n",
    "                cached_grad[i,j] = cached_grad[j,i] = 2*hm['Ltilde'][i,j]\n",
    "            else:\n",
    "                #cached_grad[i,j] = cached_grad[j,i] = 4 * hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "                cached_grad[i,j] = cached_grad[j,i] = 0\n",
    "        else:\n",
    "            cached_grad[i,j] = cached_grad[j,i] = hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "        '''\n",
    "        print(index2layerscheme[i])\n",
    "        print(index2layerscheme[j])\n",
    "        '''\n",
    "        '''\n",
    "        if i == j:\n",
    "            cached_grad[i,j] = 0.5 * hm['Ltilde'][i,j]\n",
    "        else:\n",
    "            cached_grad[i,j] = 0.25 * (hm['Ltilde'][i,j]-hm['Ltilde'][i,i]-hm['Ltilde'][j,j])\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached_grad[cached_grad<0]=0\n",
    "plt.imshow(cached_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4555d2",
   "metadata": {},
   "source": [
    "### Define a naive cost function: model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5886f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = np.array([0 for i in range(L)])\n",
    "for l in hm['layer_index']:\n",
    "    index = hm['layer_index'][l]\n",
    "    layer_name, scheme = index2layerscheme[index]\n",
    "    layer_size[index] = torch.numel(layers_to_quant[layer_name]['fp'].weight) * int(scheme[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random variable v\n",
    "# use recitfied sigmoid h(v) to represent alpha\n",
    "# freg is 1-(1-2h(v))**beta, annealing beta to \n",
    "\n",
    "if not isinstance(cached_grad,torch.Tensor):\n",
    "    cached_grad = torch.Tensor(cached_grad)\n",
    "\n",
    "layer_size_tensor = torch.Tensor(layer_size)\n",
    "\n",
    "def lossfunc(v,beta,lambda1,lambda2,printInfo=False,naive=False,b=None):\n",
    "    \n",
    "    alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(MPQ_scheme))).reshape(-1,)\n",
    "    \n",
    "    if not naive:\n",
    "        outer_alpha = torch.outer(alpha,alpha)\n",
    "        netloss = torch.sum(outer_alpha * cached_grad)\n",
    "    else:\n",
    "        netloss = torch.sum(torch.diagonal(cached_grad) * alpha)\n",
    "        \n",
    "    model_size = torch.sum(layer_size_tensor * alpha)/8/1024/1024 # model size in MB\n",
    "            \n",
    "    regloss = torch.sum(1-(torch.abs(1-2*alpha))**beta)\n",
    "    regloss *= lambda1\n",
    "\n",
    "    if b is None:\n",
    "        closs = lambda2 * model_size\n",
    "    else:\n",
    "        closs = lambda2 * torch.clamp(model_size-b,0)\n",
    "    \n",
    "    totloss = netloss + regloss + closs\n",
    "    \n",
    "    if printInfo:\n",
    "        print(f'netloss {netloss.item():.4f} regloss {regloss.item():.4f}(beta={beta:.4f}) closs{closs.item():.4f}(model size: {model_size.item():.4f}MB constraint:{b})')\n",
    "        print('alpha:\\n',alpha)\n",
    "        \n",
    "    return totloss    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04760381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(n_iteration,lr,beta,lambda1,lambda2,b=None,naive=False):\n",
    "    \n",
    "    v = torch.nn.Parameter(torch.randn(L))\n",
    "    optim = torch.optim.Adam([v,],lr=lr)\n",
    "    bs = np.linspace(beta[0],beta[1],n_iteration)\n",
    "    \n",
    "    for i in range(n_iteration):\n",
    "        if i==0 or (i+1) % 1000 == 0:\n",
    "            printInfo = True\n",
    "            print(f'Iter {i+1}')\n",
    "        else:\n",
    "            printInfo = False\n",
    "            \n",
    "        optim.zero_grad()\n",
    "        loss = lossfunc(v,bs[i],lambda1,lambda2,printInfo=printInfo,b=b,naive=naive)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    return v\n",
    "\n",
    "def evaluate_decision(v,printInfo=False,test=test):\n",
    "    v = v.detach()\n",
    "    # alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(MPQ_scheme)))\n",
    "    offset = torch.ones(int(L/len(MPQ_scheme)),dtype=int) * len(MPQ_scheme)\n",
    "    offset = offset.cumsum(dim=-1) - len(MPQ_scheme)\n",
    "    select = v.reshape(-1,len(MPQ_scheme)).argmax(dim=1) + offset\n",
    "    \n",
    "    modelsize = (layer_size[select]).sum()/8/1024/1024\n",
    "    \n",
    "    decisions = {}\n",
    "    for scheme_id in select.numpy():\n",
    "        layer,scheme = index2layerscheme[scheme_id]\n",
    "        decisions[layer] = scheme\n",
    "    \n",
    "    print(\"evaluate_decision\\n\",decisions)\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        for n in decisions:\n",
    "            layers_to_quant[n]['mix'].weight.data = layers_to_quant[n][decisions[n]].weight.data\n",
    "        # do evaluation\n",
    "        res = evaluate(test,torch_mix_model)\n",
    "        # recover layers\n",
    "        for n in decisions:\n",
    "            layers_to_quant[n]['mix'].weight.data = layers_to_quant[n]['fp'].weight.data\n",
    "    return res,modelsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = optimize(n_iteration=5000,lr=2e-3,beta=[20,2],lambda1=1e-6,lambda2=1e-4,naive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36728f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86cae2",
   "metadata": {},
   "source": [
    "## Use only 4 and 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPQ_scheme = (2,4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41525df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e90096",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_index = []\n",
    "for index in range(len(index2layerscheme)):\n",
    "    if (int(index2layerscheme[index][1][:-4])) not in MPQ_scheme:\n",
    "        del_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e87d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad = np.delete(cached_grad,[del_index],axis=0)\n",
    "cached_grad = np.delete(cached_grad,[del_index],axis=1)\n",
    "index2layerscheme = np.delete(index2layerscheme,[del_index],axis=0)\n",
    "layer_size = np.delete(layer_size,[del_index],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173aa3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8123e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17952ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(cached_grad,torch.Tensor):\n",
    "    cached_grad = torch.Tensor(cached_grad)\n",
    "\n",
    "layer_size_tensor = torch.Tensor(layer_size)\n",
    "\n",
    "def lossfunc(v,beta,lambda1,lambda2,printInfo=False,naive=False,b=None):\n",
    "    \n",
    "    alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(MPQ_scheme))).reshape(-1,)\n",
    "    \n",
    "    if not naive:\n",
    "        outer_alpha = torch.outer(alpha,alpha)\n",
    "        netloss = torch.sum(outer_alpha * cached_grad)\n",
    "    else:\n",
    "        netloss = torch.sum(torch.diagonal(cached_grad) * alpha)\n",
    "        \n",
    "    model_size = torch.sum(layer_size_tensor * alpha)/8/1024/1024 # model size in MB\n",
    "            \n",
    "    regloss = torch.sum(1-(torch.abs(1-2*alpha))**beta)\n",
    "    regloss *= lambda1\n",
    "\n",
    "    if b is None:\n",
    "        closs = lambda2 * model_size\n",
    "    else:\n",
    "        closs = lambda2 * torch.clamp(model_size-b,0)\n",
    "    \n",
    "    totloss = netloss + regloss + closs\n",
    "    \n",
    "    if printInfo:\n",
    "        print(f'netloss {netloss.item():.4f} regloss {regloss.item():.4f}(beta={beta:.4f}) closs{closs.item():.4f}(model size: {model_size.item():.4f}MB constraint:{b})')\n",
    "        print('alpha:\\n',alpha)\n",
    "        \n",
    "    return totloss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e218688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(n_iteration,lr,beta,lambda1,lambda2,b=None,naive=False):\n",
    "    \n",
    "    v = torch.nn.Parameter(torch.randn(L))\n",
    "    optim = torch.optim.Adam([v,],lr=lr)\n",
    "    bs = np.linspace(beta[0],beta[1],n_iteration)\n",
    "    \n",
    "    for i in range(n_iteration):\n",
    "        if i==0 or (i+1) % 1000 == 0:\n",
    "            printInfo = True\n",
    "            print(f'Iter {i+1}')\n",
    "        else:\n",
    "            printInfo = False\n",
    "            \n",
    "        optim.zero_grad()\n",
    "        loss = lossfunc(v,bs[i],lambda1,lambda2,printInfo=printInfo,b=b,naive=naive)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    return v\n",
    "\n",
    "def evaluate_decision(v,printInfo=False,test=test):\n",
    "    v = v.detach()\n",
    "    # alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(MPQ_scheme)))\n",
    "    offset = torch.ones(int(L/len(MPQ_scheme)),dtype=int) * len(MPQ_scheme)\n",
    "    offset = offset.cumsum(dim=-1) - len(MPQ_scheme)\n",
    "    select = v.reshape(-1,len(MPQ_scheme)).argmax(dim=1) + offset\n",
    "    \n",
    "    modelsize = (layer_size[select]).sum()/8/1024/1024\n",
    "    \n",
    "    decisions = {}\n",
    "    for scheme_id in select.numpy():\n",
    "        layer,scheme = index2layerscheme[scheme_id]\n",
    "        decisions[layer] = scheme\n",
    "    \n",
    "    print(\"evaluate_decision\\n\",decisions)\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        for n in decisions:\n",
    "            layers_to_quant[n]['mix'].weight.data = layers_to_quant[n][decisions[n]].weight.data\n",
    "        # do evaluation\n",
    "        res = evaluate(test,torch_mix_model)\n",
    "        # recover layers\n",
    "        for n in decisions:\n",
    "            layers_to_quant[n]['mix'].weight.data = layers_to_quant[n]['fp'].weight.data\n",
    "    return res,modelsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f242b9d1",
   "metadata": {},
   "source": [
    "## Random MPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c568ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_size = []\n",
    "# random_acc = []\n",
    "for i in range(500):\n",
    "    v = torch.randn(L)\n",
    "    res,size = evaluate_decision(v)\n",
    "    random_size.append(size)\n",
    "    random_acc.append(res['mean_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4da697",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_size,random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18de513",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resnet56_random_baseline.pkl','wb') as f:\n",
    "    pickle.dump({'size':random_size,'acc':random_acc},f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61085bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(random_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d354c4",
   "metadata": {},
   "source": [
    "## Pareto-Frontier of FeintLady vs Inter-Layer Dependency Unaware Optimization (Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = (5000,10000)\n",
    "lambda1s = np.logspace(-6,-3,3)\n",
    "lambda2s = np.logspace(-3,1,50) \n",
    "sample_size = 5\n",
    "results = {}\n",
    "for n_iter in n_iters:\n",
    "    for lambda1 in lambda1s:\n",
    "        for lambda2 in lambda2s:\n",
    "            feint_loss,feint_size = [],[]\n",
    "            trial_name = f'{MPQ_scheme}bits_CLADO_lambda1{lambda1}_lambda2{lambda2}_{n_iter}iters'\n",
    "            print(trial_name)\n",
    "            for repeat in range(sample_size):\n",
    "                v = optimize(n_iteration=n_iter,lr=2e-3,beta=[20,2],lambda1=lambda1,lambda2=lambda2,naive=False)\n",
    "                perf,size = evaluate_decision(v)\n",
    "                feint_loss.append(perf)\n",
    "                feint_size.append(size)\n",
    "            results[trial_name] = {'size':feint_size,'perf':feint_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = (5000,10000)\n",
    "lambda1s = np.logspace(-6,-3,3)\n",
    "lambda2s = np.logspace(-6,-1,50) #lambda1=1e-3,n=5000,lr=1e-3,beta=[20,2] for resnet20 on cifar10\n",
    "sample_size = 5\n",
    "\n",
    "for n_iter in n_iters:\n",
    "    for lambda1 in lambda1s:\n",
    "        for lambda2 in lambda2s:\n",
    "            naive_loss,naive_size = [],[]\n",
    "            print('lambda2:',lambda2)\n",
    "            trial_name = f'{MPQ_scheme}bits_NAIVE_lambda1{lambda1}_lambda2{lambda2}_{n_iter}iters'\n",
    "            for repeat in range(sample_size):\n",
    "                v = optimize(n_iteration=n_iter,lr=2e-3,beta=[20,2],lambda1=lambda1,lambda2=lambda2,naive=True)\n",
    "                perf,size = evaluate_decision(v)\n",
    "                naive_loss.append(perf)\n",
    "                naive_size.append(size)\n",
    "            results[trial_name] = {'size':naive_size,'perf':naive_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('general248c10resnet56results.pkl','wb') as f:\n",
    "    pickle.dump(results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c56c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved/general48c10resnet56results.pkl','rb') as f:\n",
    "    c48 = pickle.load(f)\n",
    "with open('saved/general248c10resnet56results.pkl','rb') as f:\n",
    "    c248 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15010711",
   "metadata": {},
   "outputs": [],
   "source": [
    "clado_size,clado_acc = [], []\n",
    "naive_size,naive_acc = [], []\n",
    "for trial in c48:\n",
    "    size = c48[trial]['size']\n",
    "    perf = c48[trial]['perf']\n",
    "    perf = [x['mean_acc'] for x in perf]\n",
    "    if 'NAIVE' in trial:\n",
    "        naive_size,naive_acc = naive_size+size,naive_acc+perf\n",
    "    if 'CLADO' in trial:\n",
    "        clado_size,clado_acc = clado_size+size,clado_acc+perf \n",
    "    #size = np.array(size)\n",
    "    #perf = np.array(perf)\n",
    "    #size,perf = getPF(size,perf)\n",
    "    #plt.plot(size,perf,label=trial)\n",
    "c48_naive_pf = getPF(np.array(naive_size),np.array(naive_acc))\n",
    "c48_clado_pf = getPF(np.array(clado_size),np.array(clado_acc))\n",
    "plt.plot(c48_naive_pf[0],c48_naive_pf[1],label='(4,8)bits naive MPQ')\n",
    "plt.plot(c48_clado_pf[0],c48_clado_pf[1],label='(4,8)bits clado MPQ')\n",
    "\n",
    "clado_size,clado_acc = [], []\n",
    "naive_size,naive_acc = [], []\n",
    "for trial in c248:\n",
    "    size = c248[trial]['size']\n",
    "    perf = c248[trial]['perf']\n",
    "    perf = [x['mean_acc'] for x in perf]\n",
    "    if 'NAIVE' in trial:\n",
    "        naive_size,naive_acc = naive_size+size,naive_acc+perf\n",
    "    if 'CLADO' in trial:\n",
    "        clado_size,clado_acc = clado_size+size,clado_acc+perf \n",
    "    #size = np.array(size)\n",
    "    #perf = np.array(perf)\n",
    "    #size,perf = getPF(size,perf)\n",
    "    #plt.plot(size,perf,label=trial)\n",
    "c248_naive_pf = getPF(np.array(naive_size),np.array(naive_acc))\n",
    "c248_clado_pf = getPF(np.array(clado_size),np.array(clado_acc))\n",
    "plt.plot(c248_naive_pf[0],c248_naive_pf[1],label='(2,4,8)bits naive MPQ')\n",
    "plt.plot(c248_clado_pf[0],c248_clado_pf[1],label='(2,4,8)bits clado MPQ')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim([0.4,0.7])\n",
    "plt.ylim([0.88,0.95])\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "plt.savefig('c10resnet56_w248.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12da08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c48_naive_size = np.array(c48['naive_size'])\n",
    "c48_naive_loss = c48['naive_loss']\n",
    "c48_feint_size = np.array(c48['feint_size'])\n",
    "c48_feint_loss = c48['feint_loss']\n",
    "\n",
    "c48_naive_acc = []\n",
    "for i in range(len(c48_naive_loss)):\n",
    "    c48_naive_acc.append(c48_naive_loss[i]['mean_acc'])\n",
    "\n",
    "c48_feint_acc = []\n",
    "for i in range(len(c48_feint_loss)):\n",
    "    c48_feint_acc.append(c48_feint_loss[i]['mean_acc'])\n",
    "\n",
    "c248_naive_size = np.array(c248['naive_size'])\n",
    "c248_naive_loss = c248['naive_loss']\n",
    "c248_feint_size = np.array(c248['feint_size'])\n",
    "c248_feint_loss = c248['feint_loss']\n",
    "\n",
    "c248_naive_acc = []\n",
    "for i in range(len(c248_naive_loss)):\n",
    "    c248_naive_acc.append(c248_naive_loss[i]['mean_acc'])\n",
    "\n",
    "c248_feint_acc = []\n",
    "for i in range(len(c248_feint_loss)):\n",
    "    c248_feint_acc.append(c248_feint_loss[i]['mean_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa465467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "\n",
    "c48_feint_size,c48_feint_acc = getPF(c48_feint_size,c48_feint_acc)\n",
    "\n",
    "c48_naive_size,c48_naive_acc = getPF(c48_naive_size,c48_naive_acc)\n",
    "\n",
    "c248_feint_size,c248_feint_acc = getPF(c248_feint_size,c248_feint_acc)\n",
    "\n",
    "c248_naive_size,c248_naive_acc = getPF(c248_naive_size,c248_naive_acc)\n",
    "\n",
    "plt.scatter(c48_naive_size,c48_naive_acc,color='lightcoral',alpha=0.5,label='c48 Inter-Layer Depedency Unaware Optimization')\n",
    "plt.scatter(c48_feint_size,c48_feint_acc,color='lightblue',alpha=0.5,label='c48 FeintLady Optimization')\n",
    "# plt.scatter(c248_naive_size,c248_naive_acc,color='red',alpha=0.5,label='c248 CLADO Used')\n",
    "# plt.scatter(c248_feint_size,c248_feint_acc,color='blue',alpha=0.5,label='c248 CLADO Not Used')\n",
    "\n",
    "plt.xlabel('Hardware cost')\n",
    "plt.ylabel('Performance')\n",
    "plt.legend()\n",
    "#plt.savefig('c100resnet56FeintEffecacy.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a211db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(naive_size,naive_acc,color='red',alpha=0.5,label='naive')\n",
    "# plt.scatter(naive_size,naive_acc,color='blue',alpha=0.5,label='feint')\n",
    "plt.xlabel('hardware cost')\n",
    "plt.ylabel('performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc8630",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8252488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fname = 'result_cifar100_shufflenetv2_x2_0_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_sfn20 = pickle.load(f)\n",
    "\n",
    "fname = 'result_cifar100_shufflenetv2_x1_5_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_sfn15 = pickle.load(f)\n",
    "    \n",
    "fname = 'result_cifar100_mobilenetv2_x1_4_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_mbn14 = pickle.load(f)\n",
    "\n",
    "fname = 'result_cifar100_mobilenetv2_x0_75_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_mbn075 = pickle.load(f)\n",
    "    \n",
    "\n",
    "fname = 'result_cifar100_resnet56_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_rsn56 = pickle.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in res_rsn56: print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF_(xs,ys,mode='max',roundtoprecision=1):\n",
    "    pf = {}\n",
    "    for x,y in zip(xs,ys):\n",
    "        new_x = round(x,roundtoprecision)\n",
    "        if new_x in pf:\n",
    "            pf[new_x] = eval(mode)(pf[new_x],y)\n",
    "        else:\n",
    "            pf[new_x] = y\n",
    "    \n",
    "    pf_x,pf_y = [],[]\n",
    "    \n",
    "    for x in pf:\n",
    "        pf_x.append(x)\n",
    "        pf_y.append(pf[x])\n",
    "    \n",
    "    pf_x, pf_y = np.array(pf_x),np.array(pf_y)\n",
    "    \n",
    "    return pf_x,pf_y\n",
    "\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de56442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_1_mbn075,y_1_mbn075 = getPF(res_mbn075['naive_size'],res_mbn075['naive_acc'])\n",
    "x_2_mbn075,y_2_mbn075 = getPF(res_mbn075['feint_size'],res_mbn075['feint_acc'])\n",
    "\n",
    "x_1_mbn14,y_1_mbn14 = getPF(res_mbn14['naive_size'],res_mbn14['naive_acc'])\n",
    "x_2_mbn14,y_2_mbn14 = getPF(res_mbn14['feint_size'],res_mbn14['feint_acc'])\n",
    "\n",
    "x_1_sfn20,y_1_sfn20 = getPF(res_sfn20['naive_size'],res_sfn20['naive_acc'])\n",
    "x_2_sfn20,y_2_sfn20 = getPF(res_sfn20['feint_size'],res_sfn20['feint_acc'])\n",
    "\n",
    "x_1_sfn15,y_1_sfn15 = getPF(res_sfn15['naive_size'],res_sfn15['naive_acc'])\n",
    "x_2_sfn15,y_2_sfn15 = getPF(res_sfn15['feint_size'],res_sfn15['feint_acc'])\n",
    "\n",
    "x_1_rsn56,y_1_rsn56 = getPF(res_rsn56['naive_size'],res_rsn56['naive_acc'])\n",
    "x_2_rsn56,y_2_rsn56 = getPF(res_rsn56['feint_size'],res_rsn56['feint_acc'])\n",
    "\n",
    "#x_random,y_random = getPF(random_size,random_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random baseline vs use/not use gradient on resnet56\n",
    "# plt.rcParams['figure.figsize'] = (12,8)\n",
    "fname = 'result_cifar10_resnet56_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_rsn = pickle.load(f)\n",
    "fname = 'resnet56_random_baseline.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    rand_rsn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8529a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(res_rsn['feint_size'][:],res_rsn['feint_acc'][:],color='blue',\n",
    "            marker='o',s=20,alpha=0.5,label='Cross-layer Gradients Used')\n",
    "\n",
    "plt.scatter(res_rsn['naive_size'][:],res_rsn['naive_acc'][:],color='red',\n",
    "            marker='o',s=20,alpha=0.5,label='Cross-layer Gradients Ignored')\n",
    "\n",
    "plt.scatter(rand_rsn['size'],rand_rsn['acc'],color='black',marker='o',s=20,alpha=0.5,\n",
    "            label='Random Guess')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "plt.savefig('c10resnet.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105629d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "plt.plot(x_1_mbn14,y_1_mbn14,color='red',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='mobilenetv2_x1_4(N)')\n",
    "plt.plot(x_2_mbn14,y_2_mbn14,color='blue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='mobilenetv2_x1_4(A)')\n",
    "\n",
    "# plt.plot(x_1_mbn075,y_1_mbn075,color='red',\n",
    "#          marker='^',markersize=3,alpha=0.5,linewidth=1,label='mobilenetv2_x0_75(N)')\n",
    "# plt.plot(x_2_mbn075,y_2_mbn075,color='blue',\n",
    "#          marker='v',markersize=3,alpha=0.5,linewidth=1,label='mobilenetv2_x0_75(A)')\n",
    "\n",
    "plt.plot(x_1_sfn20,y_1_sfn20,color='lightcoral',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='shufflenetv2_x2_0(N)')\n",
    "plt.plot(x_2_sfn20,y_2_sfn20,color='lightblue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='sufflenetv2_x2_0(A)')\n",
    "\n",
    "plt.plot(x_1_sfn15,y_1_sfn15,color='orangered',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='shufflenetv2_x1_5(N)')\n",
    "plt.plot(x_2_sfn15,y_2_sfn15,color='cyan',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='sufflenetv2_x1_5(A)')\n",
    "\n",
    "plt.plot(x_1_rsn56,y_1_rsn56,color='darkred',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='resnet56(N)')\n",
    "plt.plot(x_2_rsn56,y_2_rsn56,color='darkblue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='resnet56(A)')\n",
    "\n",
    "\n",
    "# plt.scatter(x_1,y_1,color='red',marker='^',s=10,alpha=0.5)\n",
    "# plt.scatter(x_2,y_2,color='blue',marker='v',s=10,alpha=0.5)\n",
    "\n",
    "plt.ylim([0.68,0.76])\n",
    "plt.xlim([0.,4])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "\n",
    "# plt.ylim([0.7,0.755])\n",
    "# plt.xlim([2.7,4.0])\n",
    "plt.savefig('c100pareto_3nets.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7068778",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "plt.plot(np.log(x_1_mbn)[100:],y_1_mbn[100:],color='red',marker='^',markersize=3,alpha=0.5,linewidth=1,label='mobilenet(A)')\n",
    "plt.plot(np.log(x_2_mbn)[100:],y_2_mbn[100:],color='blue',marker='v',markersize=3,alpha=0.5,linewidth=1,label='mobilenet(N)')\n",
    "\n",
    "plt.plot(np.log(x_1_sfn)[200:],y_1_sfn[200:],color='lightcoral',marker='^',markersize=3,alpha=0.5,linewidth=1,label='shufflenet(A)')\n",
    "plt.plot(np.log(x_2_sfn)[200:],y_2_sfn[200:],color='lightblue',marker='v',markersize=3,alpha=0.5,linewidth=1,label='sufflenet(N)')\n",
    "\n",
    "plt.plot(np.log(x_1_rsn)[0:],y_1_rsn[0:],color='darkred',marker='^',markersize=3,alpha=0.5,linewidth=1,label='resnet(A)')\n",
    "plt.plot(np.log(x_2_rsn)[0:],y_2_rsn[0:],color='darkblue',marker='v',markersize=3,alpha=0.5,linewidth=1,label='resnet(N)')\n",
    "# plt.scatter(x_1,y_1,color='red',marker='^',s=10,alpha=0.5)\n",
    "# plt.scatter(x_2,y_2,color='blue',marker='v',s=10,alpha=0.5)\n",
    "# plt.ylim([0.66,0.76])\n",
    "# plt.xlim([0.5,3.5])\n",
    "plt.ylim([0.65,0.76])\n",
    "plt.xlim([-1,1.8])\n",
    "plt.xlabel('Log Model Size (in MB)',fontsize=20)\n",
    "plt.ylabel('Test Accuracy',fontsize=20)\n",
    "plt.legend()\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "# plt.ylim([0.7,0.755])\n",
    "# plt.xlim([2.7,4.0])\n",
    "#plt.savefig('c100pareto.pdf',transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e6627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
