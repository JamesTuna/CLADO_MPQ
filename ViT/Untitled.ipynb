{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision,os,time,pickle\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from mqbench.prepare_by_platform import prepare_by_platform   # add quant nodes for specific Backend\n",
    "from mqbench.prepare_by_platform import BackendType           # contain various Backend, like TensorRT, NNIE, etc.\n",
    "from mqbench.utils.state import enable_calibration            # turn on calibration algorithm, determine scale, zero_point, etc.\n",
    "from mqbench.utils.state import enable_quantization           # turn on actually quantization, like FP32 -> INT8\n",
    "from mqbench.utils.state import disable_all\n",
    "from copy import deepcopy\n",
    "from mqbench.advanced_ptq import ptq_reconstruction\n",
    "from functools import partial\n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6ca9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,os\n",
    "import torchvision as tv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29588f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c1a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.cuda = 0\n",
    "        self.nthreads = 8\n",
    "        self.bs = 64\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27eceb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "modelname=\"vit_b_16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02b9cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'I1K'\n",
    "mn = dataset.lower()+ '_' + modelname\n",
    "model = eval(\"tv.models.\" + modelname)(pretrained=True).cuda(args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc9c4679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.1+cu117'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a564a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "class I1K():\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_dir='~/data/imagenet',\n",
    "            cuda=False,\n",
    "            num_workers=8,\n",
    "            train_batch_size=64,\n",
    "            test_batch_size=500,\n",
    "            shuffle=False\n",
    "        ):\n",
    "        gpu_conf = {\n",
    "            'num_workers': num_workers,\n",
    "            'pin_memory': True,\n",
    "            'persistent_workers': True\n",
    "        } if cuda else {}\n",
    "        normalize = tv.transforms.Normalize(\n",
    "            (0.485, 0.456, 0.406), (0.229, 0.224, 0.225),\n",
    "        )\n",
    "        self.train = torch.utils.data.DataLoader(\n",
    "            tv.datasets.ImageFolder(\n",
    "                data_dir + '/train',\n",
    "                tv.transforms.Compose([\n",
    "                    tv.transforms.Resize(256),\n",
    "                    tv.transforms.CenterCrop(224),\n",
    "                    tv.transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                ])),\n",
    "            batch_size=train_batch_size,\n",
    "            shuffle=shuffle,\n",
    "            **gpu_conf)\n",
    "        self.val = torch.utils.data.DataLoader(\n",
    "            tv.datasets.ImageFolder(\n",
    "                data_dir + '/val',\n",
    "                tv.transforms.Compose([\n",
    "                    tv.transforms.Resize(256),\n",
    "                    tv.transforms.CenterCrop(224),\n",
    "                    tv.transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                ])),\n",
    "            batch_size=test_batch_size,\n",
    "            shuffle=False,\n",
    "            **gpu_conf)\n",
    "#ds = I1K(data_dir=os.path.join('/tools/d-matrix/ml/data', \"imagenet\"),\n",
    "#         train_batch_size=args.bs,test_batch_size=args.bs,cuda=True,shuffle=True)\n",
    "ds = I1K(data_dir=os.path.join('/home/usr1/zd2922/data', \"imagenet\"),\n",
    "        train_batch_size=args.bs,test_batch_size=args.bs,cuda=True,shuffle=True)\n",
    "\n",
    "# ds = I1K(data_dir=os.path.join('/work2/07149/zdeng/frontera/data', \"imagenet\"),\n",
    "#          train_batch_size=args.bs,test_batch_size=args.bs,cuda=True,shuffle=True)\n",
    "ds.train.num_workers = args.nthreads\n",
    "ds.val.num_workers = args.nthreads\n",
    "\n",
    "train = ds.train\n",
    "test = ds.val\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def evaluate(val_loader, model,\n",
    "             criterion = torch.nn.CrossEntropyLoss().cuda(args.cuda),device=f'cuda:{args.cuda}'):\n",
    "    s_time = time.time()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    count,top1,top5,losses = 0,0,0,0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images, target = images.to(device), target.to(device)\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses = losses * count/(count+images.size(0)) + loss * images.size(0)/(count+images.size(0))\n",
    "            top1 = top1 * count/(count+images.size(0)) + acc1 * images.size(0)/(count+images.size(0))\n",
    "            top5 = top5 * count/(count+images.size(0)) + acc5 * images.size(0)/(count+images.size(0))\n",
    "            count += images.size(0)\n",
    "    test_time = time.time() - s_time\n",
    "\n",
    "    return {'top1':top1,'top5':top5,'loss':losses,'time':test_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d5c38b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.save(model,'vit_b_16.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d4f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
