{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2109f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision,os,time\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from utils.util import get_loader,evaluate\n",
    "from utils.layer import qConv2d,qLinear\n",
    "from utils.train import QAVAT_train\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models             \n",
    "\n",
    "              # for example model\n",
    "from mqbench.prepare_by_platform import prepare_by_platform   # add quant nodes for specific Backend\n",
    "from mqbench.prepare_by_platform import BackendType           # contain various Backend, like TensorRT, NNIE, etc.\n",
    "from mqbench.utils.state import enable_calibration            # turn on calibration algorithm, determine scale, zero_point, etc.\n",
    "from mqbench.utils.state import enable_quantization           # turn on actually quantization, like FP32 -> INT8\n",
    "from mqbench.utils.state import disable_all           # turn on actually quantization, like FP32 -> INT8\n",
    "from copy import deepcopy\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_resnet56\", pretrained=True).cuda()\n",
    "# model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_mobilenetv2_x0_5\", pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53657ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "train,test = get_loader('cifar100'.upper(),batch_size=128,test_batch_size=128)\n",
    "train.num_workers = 2\n",
    "test.num_workers = 2\n",
    "train.pin_in_memory = True\n",
    "test.pin_in_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration data used to calibrate PTQ and MPQ\n",
    "calib_data = []\n",
    "calib_fp_output = []\n",
    "i = 0\n",
    "for img,label in train:\n",
    "    i += 1\n",
    "    calib_data.append((img,label))\n",
    "    calib_fp_output.append(model(img.cuda()))\n",
    "    if i == 8:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35691fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calib_fp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d31b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPQ_scheme = (2,4,8)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007f436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getModuleByName(model,moduleName):\n",
    "    '''\n",
    "        replace module with name modelName.moduleName with newModule\n",
    "    '''\n",
    "    tokens = moduleName.split('.')\n",
    "    m = model\n",
    "    for tok in tokens:\n",
    "        m = getattr(m,tok)\n",
    "    return m\n",
    "\n",
    "for b in MPQ_scheme:\n",
    "    mqb_fp_model = deepcopy(model)\n",
    "    \n",
    "    # MSE calibration on model parameters\n",
    "    backend = BackendType.Academic\n",
    "    extra_config = {\n",
    "        'extra_qconfig_dict': {\n",
    "            'w_observer': 'MSEObserver',                              # custom weight observer\n",
    "            'a_observer': 'EMAMSEObserver',                              # custom activation observer\n",
    "            'w_fakequantize': 'FixedFakeQuantize',                    # custom weight fake quantize function\n",
    "            'a_fakequantize': 'FixedFakeQuantize',                    # custom activation fake quantize function\n",
    "            'w_qscheme': {\n",
    "                'bit': b,                                             # custom bitwidth for weight,\n",
    "                'symmetry': True,                                    # custom whether quant is symmetric for weight,\n",
    "                'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for weight,\n",
    "                'pot_scale': False,                                   # custom whether scale is power of two for weight.\n",
    "            },\n",
    "            'a_qscheme': {\n",
    "                'bit': b,                                             # custom bitwidth for activation,\n",
    "                'symmetry': False,                                    # custom whether quant is symmetric for activation,\n",
    "                'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for activation,\n",
    "                'pot_scale': False,                                   # custom whether scale is power of two for activation.\n",
    "            }\n",
    "        }                                                         # custom tracer behavior, checkout https://github.com/pytorch/pytorch/blob/efcbbb177eacdacda80b94ad4ce34b9ed6cf687a/torch/fx/_symbolic_trace.py#L836\n",
    "    }\n",
    "    print(f'Prepare {b}bits model using MQBench')\n",
    "\n",
    "    exec(f'mqb_{b}bits_model=prepare_by_platform(mqb_fp_model, backend,extra_config).cuda()')\n",
    "    \n",
    "    # calibration loop\n",
    "    enable_calibration(eval(f'mqb_{b}bits_model'))\n",
    "    for img,label in calib_data:\n",
    "        eval(f'mqb_{b}bits_model')(img.cuda())  \n",
    "    disable_all(eval(f'mqb_{b}bits_model'))\n",
    "    # evaluation loop\n",
    "    enable_quantization(eval(f'mqb_{b}bits_model'))\n",
    "    print('evaluate mqb quantized model')\n",
    "    evaluate(test,eval(f'mqb_{b}bits_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test,mqb_2bits_model),evaluate(test,mqb_4bits_model), evaluate(test,mqb_8bits_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d8226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mqb_fp_model = deepcopy(mqb_8bits_model)\n",
    "disable_all(mqb_fp_model)\n",
    "mqb_mix_model = deepcopy(mqb_fp_model)\n",
    "\n",
    "# 1. record all modules we want to consider\n",
    "types_to_quant = (torch.nn.Conv2d,torch.nn.Linear)\n",
    "\n",
    "layer_input_map = {}\n",
    "\n",
    "for node in mqb_8bits_model.graph.nodes:\n",
    "    try:\n",
    "        node_target = getModuleByName(mqb_mix_model,node.target)\n",
    "        if isinstance(node_target,types_to_quant):\n",
    "            node_args = node.args[0]\n",
    "            print('input of ',node.target,' is ',node_args)\n",
    "            layer_input_map[node.target] = str(node_args.target)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_metric = ('mean_acc',evaluate(test,mqb_fp_model)['mean_acc'])\n",
    "ref_metric = ('mean_loss',evaluate(calib_data,mqb_fp_model)['mean_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeec63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(perturb_scheme):\n",
    "    # perturb_scheme: {layer_name:(act_bits,weight_bits)}\n",
    "    for layer_name in perturb_scheme:\n",
    "        a_bits,w_bits = perturb_scheme[layer_name]\n",
    "        \n",
    "        if w_bits is not None:\n",
    "            mix_module = getModuleByName(mqb_mix_model,layer_name)\n",
    "            tar_module = getModuleByName(eval(f'mqb_{w_bits}bits_model'),layer_name)\n",
    "            # replace weight quant to use a_bits quantization\n",
    "            w_cmd = f'mix_module.weight_fake_quant=tar_module.weight_fake_quant'\n",
    "            exec(w_cmd)\n",
    "        \n",
    "        if a_bits is not None:\n",
    "        \n",
    "            # replace act quant to use w_bits quantization\n",
    "            a_cmd = f'mqb_mix_model.{layer_input_map[layer_name]}=mqb_{a_bits}bits_model.{layer_input_map[layer_name]}'\n",
    "            exec(a_cmd)\n",
    "        \n",
    "        #print(layer_name)\n",
    "        #print(a_cmd)\n",
    "        #print(w_cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee550ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturb functionality test\n",
    "perturb_scheme = {}\n",
    "for layer_name in layer_input_map:\n",
    "    perturb_scheme[layer_name] = (4,8)\n",
    "perturb(perturb_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test,mqb_mix_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mqb_mix_model = deepcopy(mqb_8bits_model)\n",
    "disable_all(mqb_mix_model)\n",
    "evaluate(test,mqb_mix_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846ea48",
   "metadata": {},
   "source": [
    "## CLADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6716b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "kl_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "def kldiv(quant_logit,fp_logit):\n",
    "    inp = F.log_softmax(quant_logit,dim=-1)\n",
    "    tar = F.softmax(fp_logit,dim=-1)\n",
    "    return kl_loss(inp,tar)\n",
    "\n",
    "def perturb_loss(perturb_scheme,ref_metric=ref_metric,\n",
    "                 eval_data=calib_data,printInfo=False,KL=False):\n",
    "    \n",
    "    global mqb_mix_model\n",
    "    mqb_mix_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        perturb(perturb_scheme)\n",
    "            \n",
    "        # do evaluation\n",
    "        if not KL:\n",
    "            res = evaluate(eval_data,mqb_mix_model)\n",
    "            perturbed_loss = res[ref_metric[0]] - ref_metric[1]\n",
    "        else:\n",
    "            perturbed_loss = []\n",
    "            \n",
    "            for (data,fp_out) in zip(calib_data,calib_fp_output):\n",
    "                img,label = data\n",
    "                quant_out = mqb_mix_model(img.cuda())\n",
    "                perturbed_loss.append(kldiv(quant_out,fp_out))\n",
    "            #print(perturbed_loss)\n",
    "            perturbed_loss = torch.tensor(perturbed_loss).mean()    \n",
    "        \n",
    "        if printInfo:\n",
    "            print(f'use kl {KL} perturbed loss {perturbed_loss}')\n",
    "        \n",
    "        # recover layers\n",
    "        mqb_mix_model = deepcopy(mqb_fp_model)\n",
    "            \n",
    "    return perturbed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4162ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perturb loss functionality check\n",
    "# del layer_input_map['conv1']\n",
    "# del layer_input_map['fc']\n",
    "\n",
    "for layer in layer_input_map:\n",
    "    for a_bits in MPQ_scheme:\n",
    "        for w_bits in MPQ_scheme:\n",
    "            print(f'{layer} (a:{a_bits} bits,w:{w_bits} bits))')\n",
    "            p = perturb_loss({layer:(a_bits,w_bits)},eval_data=test,printInfo=True,KL=True)\n",
    "            #print(f'{layer} (a:{a_bits} bits,w:{w_bits} bits), accuracy degradation: {p*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47dd85f",
   "metadata": {},
   "source": [
    "## Build Cached Grad if not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del layer_input_map['conv1']\n",
    "# del layer_input_map['fc']\n",
    "\n",
    "import time\n",
    "s_time = time.time()\n",
    "cached = {}\n",
    "aw_scheme = []\n",
    "for a_bits in MPQ_scheme:\n",
    "    for w_bits in MPQ_scheme:\n",
    "        aw_scheme.append((a_bits,w_bits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d37d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aw_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f370df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KL=True\n",
    "for n in layer_input_map:\n",
    "    for m in layer_input_map:\n",
    "        for naw in aw_scheme:\n",
    "            for maw in aw_scheme:\n",
    "                if (n,m,naw,maw) not in cached:\n",
    "                    if n == m:\n",
    "                        if naw == maw:\n",
    "                            \n",
    "                            p = perturb_loss({n:naw},ref_metric,calib_data,KL=KL)\n",
    "                            print(f'perturb layer {n} to A{naw[0]}W{naw[1]} p={p}')\n",
    "                        else:\n",
    "                            p = 0\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        p = perturb_loss({n:naw,m:maw},ref_metric,calib_data,KL=KL)\n",
    "                        print(f'perturb layer {n} to A{naw[0]}W{naw[1]} and layer {m} to A{maw[0]}W{maw[1]} p={p}')\n",
    "                    \n",
    "                    cached[(n,m,naw,maw)] = cached[(m,n,maw,naw)] = p\n",
    "                    \n",
    "print(f'{time.time()-s_time:.2f} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf90f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239967a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index = {}\n",
    "cnt = 0\n",
    "for layer in layer_input_map:\n",
    "    for s in aw_scheme:\n",
    "        layer_index[layer+f'{s}bits'] = cnt\n",
    "        cnt += 1\n",
    "L = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece828de",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hm = np.zeros(shape=(L,L))\n",
    "for n in layer_input_map:\n",
    "    for m in layer_input_map:\n",
    "        for naw in aw_scheme:\n",
    "            for maw in aw_scheme:\n",
    "                hm[layer_index[n+f'{naw}bits'],layer_index[m+f'{maw}bits']] = cached[(n,m,naw,maw)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad = np.zeros_like(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99559c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generala248w248_c100resnet56_calib_kl','wb') as f:\n",
    "    pickle.dump({'Ltilde':hm,'layer_index':layer_index},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_loss(['conv1',],ref_metric,eval_data=calib_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc001d",
   "metadata": {},
   "source": [
    "## Load Cached Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generala248w248_c100resnet56_calib_kl','rb') as f:\n",
    "    hm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1de436",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf70d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm['layer_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf87d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2layerscheme = [None for i in range(hm['Ltilde'].shape[0])]\n",
    "\n",
    "for name in hm['layer_index']:\n",
    "    index = hm['layer_index'][name]\n",
    "    layer_name = name[:-10]\n",
    "    scheme = name[-10:]\n",
    "    a = hm['Ltilde']\n",
    "    print(f'index {index} layer {layer_name} scheme {scheme} Ltilde {a[index,index].item():.6f}')\n",
    "    \n",
    "    index2layerscheme[index] = (layer_name,scheme)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hm['Ltilde'],cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = hm['Ltilde'].shape[0]\n",
    "cached_grad = np.zeros_like(hm['Ltilde'])\n",
    "for i in range(L):\n",
    "    for j in range(L):\n",
    "        layer_i,scheme_i = index2layerscheme[i]\n",
    "        layer_j,scheme_j = index2layerscheme[j]\n",
    "        if layer_i == layer_j:\n",
    "            if scheme_i == scheme_j:\n",
    "                cached_grad[i,j] = cached_grad[j,i] = 2 * hm['Ltilde'][i,j]\n",
    "            else:\n",
    "                #cached_grad[i,j] = cached_grad[j,i] = 4 * hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "                cached_grad[i,j] = cached_grad[j,i] = 0\n",
    "        else:\n",
    "            cached_grad[i,j] = cached_grad[j,i] = hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "        '''\n",
    "        print(index2layerscheme[i])\n",
    "        print(index2layerscheme[j])\n",
    "        '''\n",
    "        '''\n",
    "        if i == j:\n",
    "            cached_grad[i,j] = 0.5 * hm['Ltilde'][i,j]\n",
    "        else:\n",
    "            cached_grad[i,j] = 0.25 * (hm['Ltilde'][i,j]-hm['Ltilde'][i,i]-hm['Ltilde'][j,j])\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34a3a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cached_grad[cached_grad<0]=0\n",
    "plt.imshow(cached_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bfca8",
   "metadata": {},
   "source": [
    "### Count bitoperations for layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a839b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer_hook(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(layer_hook, self).__init__()\n",
    "        self.in_shape = None\n",
    "        self.out_shape = None\n",
    "\n",
    "    def hook(self, module, inp, outp):\n",
    "        self.in_shape = inp[0].size()\n",
    "        self.out_shape = outp.size()\n",
    "    \n",
    "\n",
    "hooks = {}\n",
    "\n",
    "for layer in hm['layer_index']:\n",
    "    m = getModuleByName(model,layer[:-10])\n",
    "    hook = layer_hook()\n",
    "    hooks[layer[:-10]] = (hook,m.register_forward_hook(hook.hook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc42d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in hooks:\n",
    "    hooks[layer][1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56512fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,label in train:\n",
    "    model(img.cuda())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e26a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_bitops(layer_name,a_bits,w_bits):\n",
    "    \n",
    "    m = getModuleByName(model,layer_name)\n",
    "    \n",
    "    if isinstance(m,torch.nn.Conv2d):\n",
    "        _,cin,_,_ = hooks[layer_name][0].in_shape\n",
    "        _,cout,hout,wout = hooks[layer_name][0].out_shape\n",
    "        \n",
    "        print('in',hooks[layer_name][0].in_shape)\n",
    "        print('out',hooks[layer_name][0].out_shape)\n",
    "        \n",
    "        n_muls = cin * m.weight.size()[2] * m.weight.size()[3] * cout * hout * wout\n",
    "        n_accs = (cin * m.weight.size()[2] * m.weight.size()[3] - 1) * cout * hout * wout\n",
    "        \n",
    "        bitops_per_mul = 2 * a_bits * w_bits\n",
    "        bitops_per_acc = (a_bits + w_bits) + np.ceil(np.log2(cin * m.weight.size()[2] * m.weight.size()[3]))\n",
    "        \n",
    "        print(f'n_muls {n_muls} ops_per_mul {bitops_per_mul} totl {n_muls*bitops_per_mul}')\n",
    "        print(f'n_accs {n_accs} ops_per_acc {bitops_per_acc} totl {n_accs*bitops_per_acc}')\n",
    "        print()\n",
    "        \n",
    "        return n_muls * bitops_per_mul + n_accs * bitops_per_acc\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0cbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2layerscheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = np.array([0 for i in range(L)])\n",
    "for l in hm['layer_index']:\n",
    "    index = hm['layer_index'][l]\n",
    "    layer_name, scheme = index2layerscheme[index]\n",
    "    scheme = eval(scheme[:-4])\n",
    "    layer_size[index] = torch.numel(getModuleByName(model,layer_name).weight) * int(scheme[1])\n",
    "\n",
    "layer_bitops = []\n",
    "\n",
    "for layer in hooks:\n",
    "    print(layer)\n",
    "    get_layer_bitops(layer,8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4555d2",
   "metadata": {},
   "source": [
    "### Define a naive cost function: model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5886f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = np.array([0 for i in range(L)])\n",
    "layer_bitops = np.array([0 for i in range(L)])\n",
    "for l in hm['layer_index']:\n",
    "    index = hm['layer_index'][l]\n",
    "    layer_name, scheme = index2layerscheme[index]\n",
    "    a_bits,w_bits = eval(scheme[:-4])\n",
    "    #print(layer_name,a_bits,w_bits)\n",
    "    layer_size[index] = torch.numel(getModuleByName(model,layer_name).weight) * int(w_bits)\n",
    "    layer_bitops[index] = get_layer_bitops(layer,a_bits,w_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79495d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7a908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_bitops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de435fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aw_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha =  torch.nn.Softmax(dim=1)(v.reshape(-1,len(aw_scheme))).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((torch.outer(alpha,alpha)*cached_grad).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c991f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(504):\n",
    "    print((torch.outer(alpha,alpha).detach().numpy())[i,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e54776",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.outer(alpha,alpha)*cached_grad).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random variable v\n",
    "# use recitfied sigmoid h(v) to represent alpha\n",
    "# freg is 1-(1-2h(v))**beta, annealing beta to \n",
    "\n",
    "if not isinstance(cached_grad,torch.Tensor):\n",
    "    cached_grad = torch.Tensor(cached_grad)\n",
    "\n",
    "layer_size_tensor = torch.Tensor(layer_size)\n",
    "layer_bitops_tensor = torch.Tensor(layer_bitops)\n",
    "\n",
    "def lossfunc(v,beta,lambda1,lambda2,printInfo=False,naive=False,b=None):\n",
    "    \n",
    "    alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(aw_scheme))).reshape(-1,)\n",
    "    \n",
    "    if not naive:\n",
    "        outer_alpha = torch.outer(alpha,alpha)\n",
    "        netloss = torch.sum(outer_alpha * cached_grad)\n",
    "    else:\n",
    "        netloss = torch.sum(torch.diagonal(cached_grad) * alpha)\n",
    "        \n",
    "    model_size = torch.sum(layer_size_tensor * alpha)/8/1024/1024 # model size in MB\n",
    "    model_bitops = torch.sum(layer_bitops_tensor * alpha)/10**9\n",
    "            \n",
    "    regloss = torch.sum(1-(torch.abs(1-2*alpha))**beta)\n",
    "    regloss *= lambda1\n",
    "\n",
    "    if b is None:\n",
    "        closs = lambda2 * model_bitops\n",
    "    else:\n",
    "        closs = lambda2 * torch.clamp(model_bitops-b,0)\n",
    "    \n",
    "    totloss = netloss + regloss + closs\n",
    "    \n",
    "    if printInfo:\n",
    "        print(f'netloss {netloss.item():.4f} regloss {regloss.item():.4f}(beta={beta:.4f}) closs{closs.item():.4f}(bitops: {model_bitops.item():.2f}G constraint:{b})')\n",
    "        print(f'model size: {model_size.item():.4f}MB')\n",
    "        print('alpha:\\n',alpha)\n",
    "        \n",
    "    return totloss    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04760381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(n_iteration,lr,beta,lambda1,lambda2,b=None,naive=False):\n",
    "    \n",
    "    v = torch.nn.Parameter(torch.randn(L))\n",
    "    optim = torch.optim.Adam([v,],lr=lr)\n",
    "    bs = np.linspace(beta[0],beta[1],n_iteration)\n",
    "    \n",
    "    for i in range(n_iteration):\n",
    "        if i==0 or (i+1) % 1000 == 0:\n",
    "            printInfo = True\n",
    "            print(f'Iter {i+1}')\n",
    "        else:\n",
    "            printInfo = False\n",
    "            \n",
    "        optim.zero_grad()\n",
    "        loss = lossfunc(v,bs[i],lambda1,lambda2,printInfo=printInfo,b=b,naive=naive)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    return v\n",
    "\n",
    "def evaluate_decision(v,printInfo=False,test=test):\n",
    "    global mqb_mix_model\n",
    "    v = v.detach()\n",
    "    # alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(MPQ_scheme)))\n",
    "    offset = torch.ones(int(L/len(aw_scheme)),dtype=int) * len(aw_scheme)\n",
    "    offset = offset.cumsum(dim=-1) - len(aw_scheme)\n",
    "    select = v.reshape(-1,len(aw_scheme)).argmax(dim=1) + offset\n",
    "    \n",
    "    modelsize = (layer_size[select]).sum()/8/1024/1024\n",
    "    bitops = (layer_bitops[select]).sum()/10**9\n",
    "    \n",
    "    decisions = {}\n",
    "    for scheme_id in select.numpy():\n",
    "        layer,scheme = index2layerscheme[scheme_id]\n",
    "        decisions[layer] = eval(scheme[:-4])\n",
    "    \n",
    "    print(\"evaluate_decision\\n\",decisions)\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # perturb layers\n",
    "        perturb(decisions)\n",
    "            \n",
    "        # do evaluation\n",
    "        res = evaluate(test,mqb_mix_model)\n",
    "        \n",
    "        # recover layers\n",
    "        mqb_mix_model = deepcopy(mqb_fp_model)\n",
    "    return res,modelsize,bitops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fae4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2layerscheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = optimize(n_iteration=10000,lr=1e-2,beta=[20,2],lambda1=0,lambda2=0,naive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36728f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f242b9d1",
   "metadata": {},
   "source": [
    "## Random MPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c568ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_size = []\n",
    "# random_acc = []\n",
    "for i in range(500):\n",
    "    v = torch.randn(L)\n",
    "    res,size = evaluate_decision(v)\n",
    "    random_size.append(size)\n",
    "    random_acc.append(res['mean_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4da697",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_size,random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18de513",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resnet56_random_baseline.pkl','wb') as f:\n",
    "    pickle.dump({'size':random_size,'acc':random_acc},f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61085bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(random_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d354c4",
   "metadata": {},
   "source": [
    "## Pareto-Frontier of FeintLady vs Inter-Layer Dependency Unaware Optimization (Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = (5000,10000)\n",
    "lambda1s = np.logspace(-6,-3,3)\n",
    "lambda2s = np.logspace(-3,1,50) \n",
    "sample_size = 5\n",
    "results = {}\n",
    "for n_iter in n_iters:\n",
    "    for lambda1 in lambda1s:\n",
    "        for lambda2 in lambda2s:\n",
    "            feint_loss,feint_size = [],[]\n",
    "            trial_name = f'{MPQ_scheme}bits_CLADO_lambda1{lambda1}_lambda2{lambda2}_{n_iter}iters'\n",
    "            print(trial_name)\n",
    "            for repeat in range(sample_size):\n",
    "                v = optimize(n_iteration=n_iter,lr=2e-3,beta=[20,2],lambda1=lambda1,lambda2=lambda2,naive=False)\n",
    "                perf,size = evaluate_decision(v)\n",
    "                feint_loss.append(perf)\n",
    "                feint_size.append(size)\n",
    "            results[trial_name] = {'size':feint_size,'perf':feint_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = (5000,10000)\n",
    "lambda1s = np.logspace(-6,-3,3)\n",
    "lambda2s = np.logspace(-6,-1,50) #lambda1=1e-3,n=5000,lr=1e-3,beta=[20,2] for resnet20 on cifar10\n",
    "sample_size = 5\n",
    "\n",
    "for n_iter in n_iters:\n",
    "    for lambda1 in lambda1s:\n",
    "        for lambda2 in lambda2s:\n",
    "            naive_loss,naive_size = [],[]\n",
    "            print('lambda2:',lambda2)\n",
    "            trial_name = f'{MPQ_scheme}bits_NAIVE_lambda1{lambda1}_lambda2{lambda2}_{n_iter}iters'\n",
    "            for repeat in range(sample_size):\n",
    "                v = optimize(n_iteration=n_iter,lr=2e-3,beta=[20,2],lambda1=lambda1,lambda2=lambda2,naive=True)\n",
    "                perf,size = evaluate_decision(v)\n",
    "                naive_loss.append(perf)\n",
    "                naive_size.append(size)\n",
    "            results[trial_name] = {'size':naive_size,'perf':naive_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('general248c10resnet56results.pkl','wb') as f:\n",
    "    pickle.dump(results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c56c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved/general48c10resnet56results.pkl','rb') as f:\n",
    "    c48 = pickle.load(f)\n",
    "with open('saved/general248c10resnet56results.pkl','rb') as f:\n",
    "    c248 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15010711",
   "metadata": {},
   "outputs": [],
   "source": [
    "clado_size,clado_acc = [], []\n",
    "naive_size,naive_acc = [], []\n",
    "for trial in c48:\n",
    "    size = c48[trial]['size']\n",
    "    perf = c48[trial]['perf']\n",
    "    perf = [x['mean_acc'] for x in perf]\n",
    "    if 'NAIVE' in trial:\n",
    "        naive_size,naive_acc = naive_size+size,naive_acc+perf\n",
    "    if 'CLADO' in trial:\n",
    "        clado_size,clado_acc = clado_size+size,clado_acc+perf \n",
    "    #size = np.array(size)\n",
    "    #perf = np.array(perf)\n",
    "    #size,perf = getPF(size,perf)\n",
    "    #plt.plot(size,perf,label=trial)\n",
    "c48_naive_pf = getPF(np.array(naive_size),np.array(naive_acc))\n",
    "c48_clado_pf = getPF(np.array(clado_size),np.array(clado_acc))\n",
    "plt.plot(c48_naive_pf[0],c48_naive_pf[1],label='(4,8)bits naive MPQ')\n",
    "plt.plot(c48_clado_pf[0],c48_clado_pf[1],label='(4,8)bits clado MPQ')\n",
    "\n",
    "clado_size,clado_acc = [], []\n",
    "naive_size,naive_acc = [], []\n",
    "for trial in c248:\n",
    "    size = c248[trial]['size']\n",
    "    perf = c248[trial]['perf']\n",
    "    perf = [x['mean_acc'] for x in perf]\n",
    "    if 'NAIVE' in trial:\n",
    "        naive_size,naive_acc = naive_size+size,naive_acc+perf\n",
    "    if 'CLADO' in trial:\n",
    "        clado_size,clado_acc = clado_size+size,clado_acc+perf \n",
    "    #size = np.array(size)\n",
    "    #perf = np.array(perf)\n",
    "    #size,perf = getPF(size,perf)\n",
    "    #plt.plot(size,perf,label=trial)\n",
    "c248_naive_pf = getPF(np.array(naive_size),np.array(naive_acc))\n",
    "c248_clado_pf = getPF(np.array(clado_size),np.array(clado_acc))\n",
    "plt.plot(c248_naive_pf[0],c248_naive_pf[1],label='(2,4,8)bits naive MPQ')\n",
    "plt.plot(c248_clado_pf[0],c248_clado_pf[1],label='(2,4,8)bits clado MPQ')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim([0.4,0.7])\n",
    "plt.ylim([0.88,0.95])\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "plt.savefig('c10resnet56_w248.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12da08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c48_naive_size = np.array(c48['naive_size'])\n",
    "c48_naive_loss = c48['naive_loss']\n",
    "c48_feint_size = np.array(c48['feint_size'])\n",
    "c48_feint_loss = c48['feint_loss']\n",
    "\n",
    "c48_naive_acc = []\n",
    "for i in range(len(c48_naive_loss)):\n",
    "    c48_naive_acc.append(c48_naive_loss[i]['mean_acc'])\n",
    "\n",
    "c48_feint_acc = []\n",
    "for i in range(len(c48_feint_loss)):\n",
    "    c48_feint_acc.append(c48_feint_loss[i]['mean_acc'])\n",
    "\n",
    "c248_naive_size = np.array(c248['naive_size'])\n",
    "c248_naive_loss = c248['naive_loss']\n",
    "c248_feint_size = np.array(c248['feint_size'])\n",
    "c248_feint_loss = c248['feint_loss']\n",
    "\n",
    "c248_naive_acc = []\n",
    "for i in range(len(c248_naive_loss)):\n",
    "    c248_naive_acc.append(c248_naive_loss[i]['mean_acc'])\n",
    "\n",
    "c248_feint_acc = []\n",
    "for i in range(len(c248_feint_loss)):\n",
    "    c248_feint_acc.append(c248_feint_loss[i]['mean_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa465467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "\n",
    "c48_feint_size,c48_feint_acc = getPF(c48_feint_size,c48_feint_acc)\n",
    "\n",
    "c48_naive_size,c48_naive_acc = getPF(c48_naive_size,c48_naive_acc)\n",
    "\n",
    "c248_feint_size,c248_feint_acc = getPF(c248_feint_size,c248_feint_acc)\n",
    "\n",
    "c248_naive_size,c248_naive_acc = getPF(c248_naive_size,c248_naive_acc)\n",
    "\n",
    "plt.scatter(c48_naive_size,c48_naive_acc,color='lightcoral',alpha=0.5,label='c48 Inter-Layer Depedency Unaware Optimization')\n",
    "plt.scatter(c48_feint_size,c48_feint_acc,color='lightblue',alpha=0.5,label='c48 FeintLady Optimization')\n",
    "# plt.scatter(c248_naive_size,c248_naive_acc,color='red',alpha=0.5,label='c248 CLADO Used')\n",
    "# plt.scatter(c248_feint_size,c248_feint_acc,color='blue',alpha=0.5,label='c248 CLADO Not Used')\n",
    "\n",
    "plt.xlabel('Hardware cost')\n",
    "plt.ylabel('Performance')\n",
    "plt.legend()\n",
    "#plt.savefig('c100resnet56FeintEffecacy.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a211db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(naive_size,naive_acc,color='red',alpha=0.5,label='naive')\n",
    "# plt.scatter(naive_size,naive_acc,color='blue',alpha=0.5,label='feint')\n",
    "plt.xlabel('hardware cost')\n",
    "plt.ylabel('performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc8630",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8252488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fname = 'result_cifar100_shufflenetv2_x2_0_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_sfn20 = pickle.load(f)\n",
    "\n",
    "fname = 'result_cifar100_shufflenetv2_x1_5_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_sfn15 = pickle.load(f)\n",
    "    \n",
    "fname = 'result_cifar100_mobilenetv2_x1_4_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_mbn14 = pickle.load(f)\n",
    "\n",
    "fname = 'result_cifar100_mobilenetv2_x0_75_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_mbn075 = pickle.load(f)\n",
    "    \n",
    "\n",
    "fname = 'result_cifar100_resnet56_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_rsn56 = pickle.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in res_rsn56: print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF_(xs,ys,mode='max',roundtoprecision=1):\n",
    "    pf = {}\n",
    "    for x,y in zip(xs,ys):\n",
    "        new_x = round(x,roundtoprecision)\n",
    "        if new_x in pf:\n",
    "            pf[new_x] = eval(mode)(pf[new_x],y)\n",
    "        else:\n",
    "            pf[new_x] = y\n",
    "    \n",
    "    pf_x,pf_y = [],[]\n",
    "    \n",
    "    for x in pf:\n",
    "        pf_x.append(x)\n",
    "        pf_y.append(pf[x])\n",
    "    \n",
    "    pf_x, pf_y = np.array(pf_x),np.array(pf_y)\n",
    "    \n",
    "    return pf_x,pf_y\n",
    "\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de56442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_1_mbn075,y_1_mbn075 = getPF(res_mbn075['naive_size'],res_mbn075['naive_acc'])\n",
    "x_2_mbn075,y_2_mbn075 = getPF(res_mbn075['feint_size'],res_mbn075['feint_acc'])\n",
    "\n",
    "x_1_mbn14,y_1_mbn14 = getPF(res_mbn14['naive_size'],res_mbn14['naive_acc'])\n",
    "x_2_mbn14,y_2_mbn14 = getPF(res_mbn14['feint_size'],res_mbn14['feint_acc'])\n",
    "\n",
    "x_1_sfn20,y_1_sfn20 = getPF(res_sfn20['naive_size'],res_sfn20['naive_acc'])\n",
    "x_2_sfn20,y_2_sfn20 = getPF(res_sfn20['feint_size'],res_sfn20['feint_acc'])\n",
    "\n",
    "x_1_sfn15,y_1_sfn15 = getPF(res_sfn15['naive_size'],res_sfn15['naive_acc'])\n",
    "x_2_sfn15,y_2_sfn15 = getPF(res_sfn15['feint_size'],res_sfn15['feint_acc'])\n",
    "\n",
    "x_1_rsn56,y_1_rsn56 = getPF(res_rsn56['naive_size'],res_rsn56['naive_acc'])\n",
    "x_2_rsn56,y_2_rsn56 = getPF(res_rsn56['feint_size'],res_rsn56['feint_acc'])\n",
    "\n",
    "#x_random,y_random = getPF(random_size,random_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random baseline vs use/not use gradient on resnet56\n",
    "# plt.rcParams['figure.figsize'] = (12,8)\n",
    "fname = 'result_cifar10_resnet56_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_rsn = pickle.load(f)\n",
    "fname = 'resnet56_random_baseline.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    rand_rsn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8529a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(res_rsn['feint_size'][:],res_rsn['feint_acc'][:],color='blue',\n",
    "            marker='o',s=20,alpha=0.5,label='Cross-layer Gradients Used')\n",
    "\n",
    "plt.scatter(res_rsn['naive_size'][:],res_rsn['naive_acc'][:],color='red',\n",
    "            marker='o',s=20,alpha=0.5,label='Cross-layer Gradients Ignored')\n",
    "\n",
    "plt.scatter(rand_rsn['size'],rand_rsn['acc'],color='black',marker='o',s=20,alpha=0.5,\n",
    "            label='Random Guess')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "plt.savefig('c10resnet.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105629d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "plt.plot(x_1_mbn14,y_1_mbn14,color='red',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='mobilenetv2_x1_4(N)')\n",
    "plt.plot(x_2_mbn14,y_2_mbn14,color='blue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='mobilenetv2_x1_4(A)')\n",
    "\n",
    "# plt.plot(x_1_mbn075,y_1_mbn075,color='red',\n",
    "#          marker='^',markersize=3,alpha=0.5,linewidth=1,label='mobilenetv2_x0_75(N)')\n",
    "# plt.plot(x_2_mbn075,y_2_mbn075,color='blue',\n",
    "#          marker='v',markersize=3,alpha=0.5,linewidth=1,label='mobilenetv2_x0_75(A)')\n",
    "\n",
    "plt.plot(x_1_sfn20,y_1_sfn20,color='lightcoral',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='shufflenetv2_x2_0(N)')\n",
    "plt.plot(x_2_sfn20,y_2_sfn20,color='lightblue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='sufflenetv2_x2_0(A)')\n",
    "\n",
    "plt.plot(x_1_sfn15,y_1_sfn15,color='orangered',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='shufflenetv2_x1_5(N)')\n",
    "plt.plot(x_2_sfn15,y_2_sfn15,color='cyan',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='sufflenetv2_x1_5(A)')\n",
    "\n",
    "plt.plot(x_1_rsn56,y_1_rsn56,color='darkred',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='resnet56(N)')\n",
    "plt.plot(x_2_rsn56,y_2_rsn56,color='darkblue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='resnet56(A)')\n",
    "\n",
    "\n",
    "# plt.scatter(x_1,y_1,color='red',marker='^',s=10,alpha=0.5)\n",
    "# plt.scatter(x_2,y_2,color='blue',marker='v',s=10,alpha=0.5)\n",
    "\n",
    "plt.ylim([0.68,0.76])\n",
    "plt.xlim([0.,4])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "\n",
    "# plt.ylim([0.7,0.755])\n",
    "# plt.xlim([2.7,4.0])\n",
    "plt.savefig('c100pareto_3nets.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7068778",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "plt.plot(np.log(x_1_mbn)[100:],y_1_mbn[100:],color='red',marker='^',markersize=3,alpha=0.5,linewidth=1,label='mobilenet(A)')\n",
    "plt.plot(np.log(x_2_mbn)[100:],y_2_mbn[100:],color='blue',marker='v',markersize=3,alpha=0.5,linewidth=1,label='mobilenet(N)')\n",
    "\n",
    "plt.plot(np.log(x_1_sfn)[200:],y_1_sfn[200:],color='lightcoral',marker='^',markersize=3,alpha=0.5,linewidth=1,label='shufflenet(A)')\n",
    "plt.plot(np.log(x_2_sfn)[200:],y_2_sfn[200:],color='lightblue',marker='v',markersize=3,alpha=0.5,linewidth=1,label='sufflenet(N)')\n",
    "\n",
    "plt.plot(np.log(x_1_rsn)[0:],y_1_rsn[0:],color='darkred',marker='^',markersize=3,alpha=0.5,linewidth=1,label='resnet(A)')\n",
    "plt.plot(np.log(x_2_rsn)[0:],y_2_rsn[0:],color='darkblue',marker='v',markersize=3,alpha=0.5,linewidth=1,label='resnet(N)')\n",
    "# plt.scatter(x_1,y_1,color='red',marker='^',s=10,alpha=0.5)\n",
    "# plt.scatter(x_2,y_2,color='blue',marker='v',s=10,alpha=0.5)\n",
    "# plt.ylim([0.66,0.76])\n",
    "# plt.xlim([0.5,3.5])\n",
    "plt.ylim([0.65,0.76])\n",
    "plt.xlim([-1,1.8])\n",
    "plt.xlabel('Log Model Size (in MB)',fontsize=20)\n",
    "plt.ylabel('Test Accuracy',fontsize=20)\n",
    "plt.legend()\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "# plt.ylim([0.7,0.755])\n",
    "# plt.xlim([2.7,4.0])\n",
    "#plt.savefig('c100pareto.pdf',transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e6627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
