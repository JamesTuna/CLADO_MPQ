{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39d6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zihao/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch,torchvision,os,pyhessian,time\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pyhessian\n",
    "from utils.util import get_loader,evaluate\n",
    "from utils.layer import qConv2d,qLinear\n",
    "from utils.train import QAVAT_train\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd582253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "int4model = deepcopy(model)\n",
    "int4model.load_state_dict(torch.load('int4model.ckpt')())\n",
    "\n",
    "bfp12model = deepcopy(model)\n",
    "bfp12model.load_state_dict(torch.load('bfp12model.ckpt')())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9574be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train,test = get_loader('cifar10'.upper(),batch_size=128,test_batch_size=512)\n",
    "train.num_workers = 4\n",
    "test.num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1584428c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 0.9089,\n",
       " 'qtl_acc': 0.9089,\n",
       " 'mean_loss': 0.34937334805727005,\n",
       " 'qtl_loss': 0.34937334805727005,\n",
       " 'test time': 0.8863584995269775,\n",
       " 'acc_list': array([0.9089]),\n",
       " 'loss_list': array([0.34937335])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test,bfp12model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd39225",
   "metadata": {},
   "outputs": [],
   "source": [
    "int4params,_ = pyhessian.get_params_grad(int4model)\n",
    "bfp12params,_ = pyhessian.get_params_grad(bfp12model)\n",
    "fp32params,_ = pyhessian.get_params_grad(model)\n",
    "int4_error = [(x-y) for x,y in zip(int4params,fp32params)]\n",
    "bfp12_error = [(x-y) for x,y in zip(bfp12params,fp32params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf30386",
   "metadata": {},
   "outputs": [],
   "source": [
    "int4_l2 = pyhessian.group_product(int4_error,int4_error)**0.5\n",
    "bfp12_l2 = pyhessian.group_product(bfp12_error,bfp12_error)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2518ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "int4_error_var = [x.std() for x in int4_error]\n",
    "bfp12_error_var = [x.std() for x in bfp12_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94606e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      "tensor(0., device='cuda:0', grad_fn=<DivBackward0>) tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(int4_error_var,bfp12_error_var):\n",
    "    print(x/int4_l2,y/bfp12_l2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed2ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceModuleByName(modelName,moduleName,newModuleName):\n",
    "    '''\n",
    "        replace module with name modelName.moduleName with newModule\n",
    "    '''\n",
    "    tokens = moduleName.split('.')\n",
    "    eval_str = modelName\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            eval_str += f'[{int(token)}]'\n",
    "        except:\n",
    "            eval_str += f'.{token}'\n",
    "            \n",
    "    exec(eval_str+f'={newModuleName}')\n",
    "    \n",
    "for name,module in model.named_modules():\n",
    "    if isinstance(module,torch.nn.Conv2d):\n",
    "        #print(name,' is a conv2d')\n",
    "        newLayer = qConv2d(0,0,0,init_from=module).cuda()\n",
    "        replaceModuleByName('model',name,'newLayer')\n",
    "    elif isinstance(module,torch.nn.Linear):\n",
    "        #print(name,' is a linear')\n",
    "        newLayer = qLinear(0,0,init_from=module).cuda()\n",
    "        replaceModuleByName('model',name,'newLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564183ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1/100 [20 batches 0.5547 seconds]:\n",
      "loss 0.4870 acc 0.8762\n",
      "test 2/100 [20 batches 0.5924 seconds]:\n",
      "loss 0.4282 acc 0.8859\n",
      "test 3/100 [20 batches 0.5666 seconds]:\n",
      "loss 0.5003 acc 0.8734\n",
      "test 4/100 [20 batches 0.5466 seconds]:\n",
      "loss 0.7593 acc 0.8162\n",
      "test 5/100 [20 batches 0.5696 seconds]:\n",
      "loss 0.6431 acc 0.8366\n",
      "test 6/100 [20 batches 0.6038 seconds]:\n",
      "loss 0.6848 acc 0.8364\n",
      "test 7/100 [20 batches 0.5801 seconds]:\n",
      "loss 0.4612 acc 0.8830\n",
      "test 8/100 [20 batches 0.6352 seconds]:\n",
      "loss 0.5914 acc 0.8434\n",
      "test 9/100 [20 batches 0.5738 seconds]:\n",
      "loss 0.5673 acc 0.8528\n",
      "test 10/100 [20 batches 0.5855 seconds]:\n",
      "loss 0.4061 acc 0.8919\n",
      "test 11/100 [20 batches 0.5670 seconds]:\n",
      "loss 0.5334 acc 0.8684\n",
      "test 12/100 [20 batches 0.5618 seconds]:\n",
      "loss 0.6005 acc 0.8426\n",
      "test 13/100 [20 batches 0.5532 seconds]:\n",
      "loss 0.5191 acc 0.8614\n",
      "test 14/100 [20 batches 0.5935 seconds]:\n",
      "loss 0.4605 acc 0.8801\n",
      "test 15/100 [20 batches 0.5766 seconds]:\n",
      "loss 0.5660 acc 0.8645\n",
      "test 16/100 [20 batches 0.5743 seconds]:\n",
      "loss 0.4718 acc 0.8710\n",
      "test 17/100 [20 batches 0.5695 seconds]:\n",
      "loss 0.6532 acc 0.8443\n",
      "test 18/100 [20 batches 0.6118 seconds]:\n",
      "loss 0.6164 acc 0.8496\n",
      "test 19/100 [20 batches 0.5585 seconds]:\n",
      "loss 0.6581 acc 0.8491\n",
      "test 20/100 [20 batches 0.5620 seconds]:\n",
      "loss 0.5540 acc 0.8559\n",
      "test 21/100 [20 batches 0.5927 seconds]:\n",
      "loss 0.4892 acc 0.8807\n",
      "test 22/100 [20 batches 0.5618 seconds]:\n",
      "loss 0.4667 acc 0.8760\n",
      "test 23/100 [20 batches 0.5700 seconds]:\n",
      "loss 0.5701 acc 0.8608\n",
      "test 24/100 [20 batches 0.5661 seconds]:\n",
      "loss 0.9274 acc 0.7978\n",
      "test 25/100 [20 batches 0.5589 seconds]:\n",
      "loss 0.6082 acc 0.8486\n",
      "test 26/100 [20 batches 0.5448 seconds]:\n",
      "loss 1.0059 acc 0.7852\n",
      "test 27/100 [20 batches 0.5727 seconds]:\n",
      "loss 0.5370 acc 0.8636\n",
      "test 28/100 [20 batches 0.5566 seconds]:\n",
      "loss 0.5149 acc 0.8721\n",
      "test 29/100 [20 batches 0.5618 seconds]:\n",
      "loss 0.5226 acc 0.8680\n",
      "test 30/100 [20 batches 0.5834 seconds]:\n",
      "loss 0.5633 acc 0.8563\n",
      "test 31/100 [20 batches 0.5694 seconds]:\n",
      "loss 0.4762 acc 0.8762\n",
      "test 32/100 [20 batches 0.5617 seconds]:\n",
      "loss 0.5603 acc 0.8567\n",
      "test 33/100 [20 batches 0.5525 seconds]:\n",
      "loss 0.7470 acc 0.8337\n",
      "test 34/100 [20 batches 0.5709 seconds]:\n",
      "loss 0.5406 acc 0.8742\n",
      "test 35/100 [20 batches 0.6056 seconds]:\n",
      "loss 0.7195 acc 0.8256\n",
      "test 36/100 [20 batches 0.6093 seconds]:\n",
      "loss 0.4767 acc 0.8795\n",
      "test 37/100 [20 batches 0.5536 seconds]:\n",
      "loss 0.5336 acc 0.8696\n",
      "test 38/100 [20 batches 0.5899 seconds]:\n",
      "loss 0.7281 acc 0.8331\n",
      "test 39/100 [20 batches 0.5585 seconds]:\n",
      "loss 0.4987 acc 0.8690\n",
      "test 40/100 [20 batches 0.5891 seconds]:\n",
      "loss 0.5374 acc 0.8651\n",
      "test 41/100 [20 batches 0.5742 seconds]:\n",
      "loss 0.5178 acc 0.8692\n",
      "test 42/100 [20 batches 0.5651 seconds]:\n",
      "loss 0.4502 acc 0.8868\n",
      "test 43/100 [20 batches 0.5654 seconds]:\n",
      "loss 0.4516 acc 0.8800\n",
      "test 44/100 [20 batches 0.5854 seconds]:\n",
      "loss 0.4611 acc 0.8792\n",
      "test 45/100 [20 batches 0.5695 seconds]:\n",
      "loss 0.9318 acc 0.7844\n",
      "test 46/100 [20 batches 0.5881 seconds]:\n",
      "loss 0.4579 acc 0.8760\n",
      "test 47/100 [20 batches 0.5821 seconds]:\n",
      "loss 0.6759 acc 0.8339\n",
      "test 48/100 [20 batches 0.5794 seconds]:\n",
      "loss 0.5972 acc 0.8535\n",
      "test 49/100 [20 batches 0.5769 seconds]:\n",
      "loss 0.8924 acc 0.7995\n",
      "test 50/100 [20 batches 0.5793 seconds]:\n",
      "loss 0.7035 acc 0.8216\n",
      "test 51/100 [20 batches 0.5863 seconds]:\n",
      "loss 0.4890 acc 0.8810\n",
      "test 52/100 [20 batches 0.5729 seconds]:\n",
      "loss 0.4153 acc 0.8910\n",
      "test 53/100 [20 batches 0.5980 seconds]:\n",
      "loss 0.6779 acc 0.8378\n",
      "test 54/100 [20 batches 0.5553 seconds]:\n",
      "loss 0.4676 acc 0.8758\n",
      "test 55/100 [20 batches 0.5862 seconds]:\n",
      "loss 0.8837 acc 0.7917\n",
      "test 56/100 [20 batches 0.5674 seconds]:\n",
      "loss 0.4762 acc 0.8769\n",
      "test 57/100 [20 batches 0.6249 seconds]:\n",
      "loss 0.6583 acc 0.8471\n",
      "test 58/100 [20 batches 0.5467 seconds]:\n",
      "loss 0.5767 acc 0.8580\n",
      "test 59/100 [20 batches 0.5606 seconds]:\n",
      "loss 0.4470 acc 0.8807\n",
      "test 60/100 [20 batches 0.5554 seconds]:\n",
      "loss 0.5436 acc 0.8636\n",
      "test 61/100 [20 batches 0.5697 seconds]:\n",
      "loss 0.5749 acc 0.8555\n",
      "test 62/100 [20 batches 0.5601 seconds]:\n",
      "loss 0.4976 acc 0.8655\n",
      "test 63/100 [20 batches 0.5595 seconds]:\n",
      "loss 0.7869 acc 0.8178\n",
      "test 64/100 [20 batches 0.5700 seconds]:\n",
      "loss 0.7894 acc 0.8260\n",
      "test 65/100 [20 batches 0.5765 seconds]:\n",
      "loss 0.6070 acc 0.8528\n",
      "test 66/100 [20 batches 0.5926 seconds]:\n",
      "loss 0.5346 acc 0.8683\n",
      "test 67/100 [20 batches 0.5874 seconds]:\n",
      "loss 0.8030 acc 0.8197\n",
      "test 68/100 [20 batches 0.5580 seconds]:\n",
      "loss 0.4468 acc 0.8814\n",
      "test 69/100 [20 batches 0.5548 seconds]:\n",
      "loss 0.7153 acc 0.8237\n",
      "test 70/100 [20 batches 0.5703 seconds]:\n",
      "loss 0.5426 acc 0.8613\n",
      "test 71/100 [20 batches 0.5654 seconds]:\n",
      "loss 0.5631 acc 0.8528\n",
      "test 72/100 [20 batches 0.5906 seconds]:\n",
      "loss 0.4438 acc 0.8819\n",
      "test 73/100 [20 batches 0.5953 seconds]:\n",
      "loss 0.5048 acc 0.8773\n",
      "test 74/100 [20 batches 0.5854 seconds]:\n",
      "loss 0.6795 acc 0.8258\n",
      "test 75/100 [20 batches 0.5634 seconds]:\n",
      "loss 0.6265 acc 0.8473\n",
      "test 76/100 [20 batches 0.5714 seconds]:\n",
      "loss 0.5162 acc 0.8715\n",
      "test 77/100 [20 batches 0.5829 seconds]:\n",
      "loss 0.5929 acc 0.8552\n",
      "test 78/100 [20 batches 0.5613 seconds]:\n",
      "loss 0.6492 acc 0.8457\n",
      "test 79/100 [20 batches 0.5588 seconds]:\n",
      "loss 0.4758 acc 0.8758\n",
      "test 80/100 [20 batches 0.5696 seconds]:\n",
      "loss 0.4209 acc 0.8874\n",
      "test 81/100 [20 batches 0.5795 seconds]:\n",
      "loss 0.7670 acc 0.8222\n",
      "test 82/100 [20 batches 0.5676 seconds]:\n",
      "loss 0.5726 acc 0.8566\n",
      "test 83/100 [20 batches 0.6488 seconds]:\n",
      "loss 0.4559 acc 0.8792\n",
      "test 84/100 [20 batches 0.5793 seconds]:\n",
      "loss 0.5408 acc 0.8676\n",
      "test 85/100 [20 batches 0.5683 seconds]:\n",
      "loss 0.5431 acc 0.8658\n",
      "test 86/100 [20 batches 0.5547 seconds]:\n",
      "loss 0.8937 acc 0.8000\n",
      "test 87/100 [20 batches 0.5807 seconds]:\n",
      "loss 0.5276 acc 0.8711\n",
      "test 88/100 [20 batches 0.6029 seconds]:\n",
      "loss 0.5664 acc 0.8563\n",
      "test 89/100 [20 batches 0.5476 seconds]:\n",
      "loss 0.5505 acc 0.8570\n",
      "test 90/100 [20 batches 0.5584 seconds]:\n",
      "loss 0.6125 acc 0.8536\n"
     ]
    }
   ],
   "source": [
    "evaluate(test,model,noise_std=0.2,repeat=100,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2665b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = {}\n",
    "C['epochs'] = 30\n",
    "C['optimizer'] ='SGD'\n",
    "C['lr'] = 1e-3\n",
    "C['decay_ep'] = 10\n",
    "C['decay_ratio'] = 0.1\n",
    "C['device'] = 'cuda'\n",
    "C['valPerEp'] = 1\n",
    "C['noise_std'] = 0.2\n",
    "C['valSample'] = 10\n",
    "C['trial_name'] = 'qavat_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "QAVAT_train(model,train,test,config=C,imgSize=32,imgFlat=False,\n",
    "                lossfunc=torch.nn.CrossEntropyLoss(),printPerEpoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f2045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
