{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39d6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zihao/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch,torchvision,os,pyhessian,time\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pyhessian\n",
    "from utils.util import get_loader,evaluate\n",
    "from utils.layer import qConv2d,qLinear\n",
    "from utils.train import QAVAT_train\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd582253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "int4model = deepcopy(model)\n",
    "int4model.load_state_dict(torch.load('int4model.ckpt')())\n",
    "\n",
    "bfp12model = deepcopy(model)\n",
    "bfp12model.load_state_dict(torch.load('bfp12model.ckpt')())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9574be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train,test = get_loader('cifar10'.upper(),batch_size=128,test_batch_size=512)\n",
    "train.num_workers = 4\n",
    "test.num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test,bfp12model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd39225",
   "metadata": {},
   "outputs": [],
   "source": [
    "int4params,_ = pyhessian.get_params_grad(int4model)\n",
    "bfp12params,_ = pyhessian.get_params_grad(bfp12model)\n",
    "fp32params,_ = pyhessian.get_params_grad(model)\n",
    "int4_error = [(x-y) for x,y in zip(int4params,fp32params)]\n",
    "bfp12_error = [(x-y) for x,y in zip(bfp12params,fp32params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf30386",
   "metadata": {},
   "outputs": [],
   "source": [
    "int4_l2 = pyhessian.group_product(int4_error,int4_error)**0.5\n",
    "bfp12_l2 = pyhessian.group_product(bfp12_error,bfp12_error)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2518ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "int4_error_var = [x.std() for x in int4_error]\n",
    "bfp12_error_var = [x.std() for x in bfp12_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94606e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in zip(int4_error_var,bfp12_error_var):\n",
    "    print(x/int4_l2,y/bfp12_l2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed2ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceModuleByName(modelName,moduleName,newModuleName):\n",
    "    '''\n",
    "        replace module with name modelName.moduleName with newModule\n",
    "    '''\n",
    "    tokens = moduleName.split('.')\n",
    "    eval_str = modelName\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            eval_str += f'[{int(token)}]'\n",
    "        except:\n",
    "            eval_str += f'.{token}'\n",
    "            \n",
    "    exec(eval_str+f'={newModuleName}')\n",
    "    \n",
    "for name,module in model.named_modules():\n",
    "    if isinstance(module,torch.nn.Conv2d):\n",
    "        #print(name,' is a conv2d')\n",
    "        newLayer = qConv2d(0,0,0,init_from=module).cuda()\n",
    "        replaceModuleByName('model',name,'newLayer')\n",
    "    elif isinstance(module,torch.nn.Linear):\n",
    "        #print(name,' is a linear')\n",
    "        newLayer = qLinear(0,0,init_from=module).cuda()\n",
    "        replaceModuleByName('model',name,'newLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564183ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(test,model,noise_std=0.2,repeat=100,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2665b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = {}\n",
    "C['epochs'] = 30\n",
    "C['optimizer'] ='SGD'\n",
    "C['lr'] = 1e-4\n",
    "C['decay_ep'] = 10\n",
    "C['decay_ratio'] = 0.1\n",
    "C['device'] = 'cuda'\n",
    "C['valPerEp'] = 1\n",
    "C['noise_std'] = 0.2\n",
    "C['valSample'] = 10\n",
    "C['trial_name'] = 'qavat_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238dc1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 0.0599571972599496 [9.9927 seconds]\n",
      "Epoch 1 validation [6.3210 seconds]\n",
      "mean acc 0.8609 mean loss 0.5760\n",
      "epoch 2 loss 0.05410358600099297 [9.8717 seconds]\n",
      "Epoch 2 validation [6.1661 seconds]\n",
      "mean acc 0.8564 mean loss 0.5793\n",
      "epoch 3 loss 0.054404750749792744 [10.1709 seconds]\n",
      "Epoch 3 validation [6.2437 seconds]\n",
      "mean acc 0.8581 mean loss 0.5595\n",
      "epoch 4 loss 0.056277968673049794 [10.3481 seconds]\n",
      "Epoch 4 validation [6.2464 seconds]\n",
      "mean acc 0.8769 mean loss 0.4877\n",
      "epoch 5 loss 0.053023095947721276 [9.8010 seconds]\n",
      "Epoch 5 validation [6.2264 seconds]\n",
      "mean acc 0.8605 mean loss 0.5650\n",
      "epoch 6 loss 0.05261811461118634 [9.9082 seconds]\n",
      "Epoch 6 validation [6.2365 seconds]\n",
      "mean acc 0.8446 mean loss 0.6462\n",
      "epoch 7 loss 0.051778007239160484 [9.9243 seconds]\n",
      "Epoch 7 validation [6.1288 seconds]\n",
      "mean acc 0.8731 mean loss 0.5043\n",
      "epoch 8 loss 0.052690284736359214 [9.9709 seconds]\n",
      "Epoch 8 validation [6.2473 seconds]\n",
      "mean acc 0.8625 mean loss 0.5589\n",
      "epoch 9 loss 0.05002013053340108 [9.8643 seconds]\n",
      "Epoch 9 validation [6.2094 seconds]\n",
      "mean acc 0.8565 mean loss 0.5817\n",
      "epoch 10 loss 0.051048251966972026 [10.0726 seconds]\n",
      "Epoch 10 validation [6.4044 seconds]\n",
      "mean acc 0.8614 mean loss 0.5554\n",
      "epoch 11 loss 0.051159413936345474 [9.8920 seconds]\n",
      "Epoch 11 validation [6.2415 seconds]\n",
      "mean acc 0.8656 mean loss 0.5380\n",
      "epoch 12 loss 0.050885444661826276 [9.8103 seconds]\n",
      "Epoch 12 validation [6.2183 seconds]\n",
      "mean acc 0.8604 mean loss 0.5676\n",
      "epoch 13 loss 0.05010082720852722 [10.0572 seconds]\n",
      "Epoch 13 validation [6.2708 seconds]\n",
      "mean acc 0.8694 mean loss 0.5194\n",
      "epoch 14 loss 0.04973527044057846 [10.4417 seconds]\n",
      "Epoch 14 validation [6.2996 seconds]\n",
      "mean acc 0.8672 mean loss 0.5341\n",
      "epoch 15 loss 0.047493235848825 [9.8302 seconds]\n",
      "Epoch 15 validation [6.2108 seconds]\n",
      "mean acc 0.8708 mean loss 0.5054\n",
      "epoch 16 loss 0.053183225362235326 [9.8230 seconds]\n",
      "Epoch 16 validation [6.3450 seconds]\n",
      "mean acc 0.8667 mean loss 0.5231\n",
      "epoch 17 loss 0.04906687136891934 [9.9340 seconds]\n",
      "Epoch 17 validation [6.4272 seconds]\n",
      "mean acc 0.8695 mean loss 0.5228\n",
      "epoch 18 loss 0.05235238302775356 [10.2084 seconds]\n",
      "Epoch 18 validation [6.3644 seconds]\n",
      "mean acc 0.8632 mean loss 0.5502\n",
      "epoch 19 loss 0.049951122368654934 [10.0779 seconds]\n",
      "Epoch 19 validation [6.3561 seconds]\n",
      "mean acc 0.8641 mean loss 0.5450\n",
      "epoch 20 loss 0.05158424391018231 [9.9996 seconds]\n",
      "Epoch 20 validation [6.3218 seconds]\n",
      "mean acc 0.8699 mean loss 0.5240\n",
      "epoch 21 loss 0.04923306520113631 [10.6585 seconds]\n",
      "Epoch 21 validation [6.5329 seconds]\n",
      "mean acc 0.8691 mean loss 0.5094\n",
      "epoch 22 loss 0.05090584739914064 [10.1756 seconds]\n",
      "Epoch 22 validation [6.3379 seconds]\n",
      "mean acc 0.8682 mean loss 0.5230\n",
      "epoch 23 loss 0.04924103844186763 [9.8555 seconds]\n",
      "Epoch 23 validation [6.2306 seconds]\n",
      "mean acc 0.8651 mean loss 0.5563\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "QAVAT_train(model,train,test,config=C,imgSize=32,imgFlat=False,\n",
    "                lossfunc=torch.nn.CrossEntropyLoss(),printPerEpoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test,model,noise_std=0.2,repeat=100,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboardX\n",
    "def QAVATPLUS_train(model,train_loader,test_loader,config,imgSize=32,imgFlat=False,\n",
    "                lossfunc=torch.nn.CrossEntropyLoss(),printPerEpoch=100):\n",
    "\n",
    "    tb = tensorboardX.SummaryWriter(comment=config['trial_name'])\n",
    "    C = config\n",
    "    if C['optimizer'] == 'SGD' or C['optimizer'] == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(),lr=C['lr'],momentum=0.9)\n",
    "    elif C['optimizer'] == 'adam' or C['optimizer'] == 'Adam' or C['optimizer'] == 'ADAM':\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=C['lr'])\n",
    "    else:\n",
    "        print('unrecognized optimizer defined in config')\n",
    "        exit(0)\n",
    "    for epoch in range(C['epochs']):\n",
    "        # lr decay\n",
    "        current_lr = C['lr'] * (C['decay_ratio'] ** (epoch // C['decay_ep']))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = current_lr\n",
    "\n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        # per epoch training, do\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            model.train()\n",
    "            x, label = data\n",
    "            if imgFlat:\n",
    "                x = x.view(-1,imgSize**2)\n",
    "            x = x.to(C['device'])\n",
    "            label = label.to(C['device'])\n",
    "            optimizer.zero_grad()\n",
    "            '''\n",
    "            if config['noise_std'] > 0:\n",
    "                generate_variation(model,noise_std=config['noise_std'])\n",
    "            output = model(x)\n",
    "            l = lossfunc(output,label)\n",
    "            l.backward()\n",
    "            '''\n",
    "            \n",
    "            # use under-variation 2nd-order gradient estimation\n",
    "            # g + sigma^2 (Hw)\n",
    "            # Hw is the hessian-parameter product\n",
    "            # computed using pyhessian (reuse gradient)\n",
    "            \n",
    "            hcp = pyhessian.hessian(model,data=(x,label),criterion=torch.nn.CrossEntropyLoss())\n",
    "    \n",
    "            hw = pyhessian.hessian_vector_product(hcp.gradsH, hcp.params, hcp.params)\n",
    "        \n",
    "            for p,hw_ in zip(hcp.params,hw):\n",
    "                p.grad.data += hw_ * config['noise_std']**2\n",
    "            \n",
    "            optimizer.step()\n",
    "            total_loss += l.data.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            for p in hcp.params:\n",
    "                p.grad = None\n",
    "        \n",
    "        total_loss /= batch_count\n",
    "        tb.add_scalar('epoch loss',total_loss,epoch+1)\n",
    "        tb.add_scalar('epoch time',time.time()-start,epoch+1)\n",
    "        tb.add_scalar('learning rate',current_lr,epoch+1)\n",
    "\n",
    "        # console output\n",
    "        if epoch % printPerEpoch == printPerEpoch-1:\n",
    "            print(\"epoch %s loss %s [%.4f seconds]\"%(epoch+1,total_loss,time.time()-start))\n",
    "\n",
    "        if C['valPerEp'] is None:\n",
    "            continue\n",
    "\n",
    "        # validation\n",
    "        if epoch % C['valPerEp'] == 0:\n",
    "            val = evaluate(test_loader,model,noise_std = C['noise_std'],repeat = C['valSample'],imgSize=imgSize,imgFlat=imgFlat,device = C['device'])\n",
    "\n",
    "            tb.add_scalar('validation/mean accuracy',val['mean_acc'],epoch+1)\n",
    "            tb.add_scalar('validation/qtl accuracy',val['qtl_acc'],epoch+1)\n",
    "            tb.add_scalar('validation/mean loss',val['mean_loss'],epoch+1)\n",
    "            tb.add_scalar('validation/qtl loss',val['qtl_loss'],epoch+1)\n",
    "            tb.add_scalar('validation/validation time',val['test time'],epoch+1)\n",
    "            tb.add_histogram('validation/accuracy',val['acc_list'],epoch+1)\n",
    "            tb.add_histogram('validation/loss',val['loss_list'],epoch+1)\n",
    "\n",
    "            print(\"Epoch %s validation [%.4f seconds]\"%(epoch+1,val['test time']))\n",
    "            print(\"mean acc %.4f mean loss %.4f\"%(val['mean_acc'],val['mean_loss']))\n",
    "\n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1741280",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "C['trial_name'] = 'qavat_plus_train'\n",
    "QAVATPLUS_train(model,train,test,config=C,imgSize=32,imgFlat=False,\n",
    "                lossfunc=torch.nn.CrossEntropyLoss(),printPerEpoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb76442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
