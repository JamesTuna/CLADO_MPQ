{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1149d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision,os,time\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models             \n",
    "\n",
    "from mqbench.prepare_by_platform import prepare_by_platform   # add quant nodes for specific Backend\n",
    "from mqbench.prepare_by_platform import BackendType           # contain various Backend, like TensorRT, NNIE, etc.\n",
    "from mqbench.utils.state import enable_calibration            # turn on calibration algorithm, determine scale, zero_point, etc.\n",
    "from mqbench.utils.state import enable_quantization           # turn on actually quantization, like FP32 -> INT8\n",
    "from mqbench.utils.state import disable_all           \n",
    "from copy import deepcopy\n",
    "from mqbench.advanced_ptq import ptq_reconstruction\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f39020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/zdeng/.conda/envs/mltls/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from mltools.data import I1K\n",
    "import torchvision as tv\n",
    "\n",
    "modelname = 'resnet50'\n",
    "adv_ptq = False\n",
    "dataset = 'I1K'\n",
    "mn = dataset.lower()+ '_' + modelname\n",
    "ds = I1K(data_dir=os.path.join('/tools/d-matrix/ml/data', \"imagenet\"),\n",
    "         train_batch_size=32,test_batch_size=64,cuda=True)\n",
    "model = eval(\"tv.models.\" + modelname)(pretrained=True).cuda()\n",
    "ds.train.num_workers = 4\n",
    "ds.val.num_workers = 8\n",
    "\n",
    "train = ds.train\n",
    "test = ds.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4e0889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def evaluate(val_loader, model,\n",
    "             criterion = torch.nn.CrossEntropyLoss().cuda(),device='cuda'):\n",
    "    s_time = time.time()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    count,top1,top5,losses = 0,0,0,0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images, target = images.to(device), target.to(device)\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses = losses * count/(count+images.size(0)) + loss * images.size(0)/(count+images.size(0))\n",
    "            top1 = top1 * count/(count+images.size(0)) + acc1 * images.size(0)/(count+images.size(0))\n",
    "            top5 = top5 * count/(count+images.size(0)) + acc5 * images.size(0)/(count+images.size(0))\n",
    "            count += images.size(0)\n",
    "    test_time = time.time() - s_time\n",
    "    \n",
    "    return {'top1':top1,'top5':top5,'loss':losses,'time':test_time}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf1b06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top1': tensor([76.1461], device='cuda:0'),\n",
       " 'top5': tensor([92.8722], device='cuda:0'),\n",
       " 'loss': tensor(0.9616, device='cuda:0'),\n",
       " 'time': 123.4330382347107}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluate(test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f67af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration data used to calibrate PTQ and MPQ\n",
    "calib_data = []\n",
    "stacked_tensor = []\n",
    "calib_fp_output = []\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    for img,label in train:\n",
    "        i += 1\n",
    "        stacked_tensor.append(img)\n",
    "        calib_data.append((img,label))\n",
    "        calib_fp_output.append(model(img.cuda()))\n",
    "        if i == 32: # remember to modify this to get 1024 images\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d31b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MPQ_scheme = (2,4,8)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b007f436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare 2bits model using MQBench\n",
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 2 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Set layer conv1 to 8 bit.\n",
      "[MQBENCH] INFO: Set layer fc to 8 bit.\n",
      "dbg node_to_quantize_output\n",
      " odict_keys([x, maxpool, layer1_0_relu, layer1_0_relu_1, layer1_0_relu_2, layer1_1_relu, layer1_1_relu_1, layer1_1_relu_2, layer1_2_relu, layer1_2_relu_1, layer1_2_relu_2, layer2_0_relu, layer2_0_relu_1, layer2_0_relu_2, layer2_1_relu, layer2_1_relu_1, layer2_1_relu_2, layer2_2_relu, layer2_2_relu_1, layer2_2_relu_2, layer2_3_relu, layer2_3_relu_1, layer2_3_relu_2, layer3_0_relu, layer3_0_relu_1, layer3_0_relu_2, layer3_1_relu, layer3_1_relu_1, layer3_1_relu_2, layer3_2_relu, layer3_2_relu_1, layer3_2_relu_2, layer3_3_relu, layer3_3_relu_1, layer3_3_relu_2, layer3_4_relu, layer3_4_relu_1, layer3_4_relu_2, layer3_5_relu, layer3_5_relu_1, layer3_5_relu_2, layer4_0_relu, layer4_0_relu_1, layer4_0_relu_2, layer4_1_relu, layer4_1_relu_1, layer4_1_relu_2, layer4_2_relu, layer4_2_relu_1, flatten])\n",
      "[MQBENCH] INFO: Set x post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant maxpool_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set flatten post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant flatten_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n",
      "Prepare 4bits model using MQBench\n",
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 4 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Set layer conv1 to 8 bit.\n",
      "[MQBENCH] INFO: Set layer fc to 8 bit.\n",
      "dbg node_to_quantize_output\n",
      " odict_keys([x, maxpool, layer1_0_relu, layer1_0_relu_1, layer1_0_relu_2, layer1_1_relu, layer1_1_relu_1, layer1_1_relu_2, layer1_2_relu, layer1_2_relu_1, layer1_2_relu_2, layer2_0_relu, layer2_0_relu_1, layer2_0_relu_2, layer2_1_relu, layer2_1_relu_1, layer2_1_relu_2, layer2_2_relu, layer2_2_relu_1, layer2_2_relu_2, layer2_3_relu, layer2_3_relu_1, layer2_3_relu_2, layer3_0_relu, layer3_0_relu_1, layer3_0_relu_2, layer3_1_relu, layer3_1_relu_1, layer3_1_relu_2, layer3_2_relu, layer3_2_relu_1, layer3_2_relu_2, layer3_3_relu, layer3_3_relu_1, layer3_3_relu_2, layer3_4_relu, layer3_4_relu_1, layer3_4_relu_2, layer3_5_relu, layer3_5_relu_1, layer3_5_relu_2, layer4_0_relu, layer4_0_relu_1, layer4_0_relu_2, layer4_1_relu, layer4_1_relu_1, layer4_1_relu_2, layer4_2_relu, layer4_2_relu_1, flatten])\n",
      "[MQBENCH] INFO: Set x post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant maxpool_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set flatten post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant flatten_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n",
      "Prepare 8bits model using MQBench\n",
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Set layer conv1 to 8 bit.\n",
      "[MQBENCH] INFO: Set layer fc to 8 bit.\n",
      "dbg node_to_quantize_output\n",
      " odict_keys([x, maxpool, layer1_0_relu, layer1_0_relu_1, layer1_0_relu_2, layer1_1_relu, layer1_1_relu_1, layer1_1_relu_2, layer1_2_relu, layer1_2_relu_1, layer1_2_relu_2, layer2_0_relu, layer2_0_relu_1, layer2_0_relu_2, layer2_1_relu, layer2_1_relu_1, layer2_1_relu_2, layer2_2_relu, layer2_2_relu_1, layer2_2_relu_2, layer2_3_relu, layer2_3_relu_1, layer2_3_relu_2, layer3_0_relu, layer3_0_relu_1, layer3_0_relu_2, layer3_1_relu, layer3_1_relu_1, layer3_1_relu_2, layer3_2_relu, layer3_2_relu_1, layer3_2_relu_2, layer3_3_relu, layer3_3_relu_1, layer3_3_relu_2, layer3_4_relu, layer3_4_relu_1, layer3_4_relu_2, layer3_5_relu, layer3_5_relu_1, layer3_5_relu_2, layer4_0_relu, layer4_0_relu_1, layer4_0_relu_2, layer4_1_relu, layer4_1_relu_1, layer4_1_relu_2, layer4_2_relu, layer4_2_relu_1, flatten])\n",
      "[MQBENCH] INFO: Set x post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant maxpool_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_0_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_1_relu_2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer4_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set flatten post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant flatten_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "ptq_reconstruction_config_init = {\n",
    "    'pattern': 'block',                   #? 'layer' for Adaround or 'block' for BRECQ and QDROP\n",
    "    'scale_lr': 4.0e-5,                   #? learning rate for learning step size of activation\n",
    "    'warm_up': 0.2,                       #? 0.2 * max_count iters without regularization to floor or ceil\n",
    "    'weight': 0.01,                       #? loss weight for regularization item\n",
    "    'max_count': 1,                   #? optimization iteration\n",
    "    'b_range': [20,2],                    #? beta decaying range\n",
    "    'keep_gpu': True,                     #? calibration data restore in gpu or cpu\n",
    "    'round_mode': 'learned_hard_sigmoid', #? ways to reconstruct the weight, currently only support learned_hard_sigmoid\n",
    "    'prob': 0.5,                          #? dropping probability of QDROP, 1.0 for Adaround and BRECQ\n",
    "}\n",
    "\n",
    "\n",
    "ptq_reconstruction_config = {\n",
    "    'pattern': 'block',                   #? 'layer' for Adaround or 'block' for BRECQ and QDROP\n",
    "    'scale_lr': 4.0e-5,                   #? learning rate for learning step size of activation\n",
    "    'warm_up': 0.2,                       #? 0.2 * max_count iters without regularization to floor or ceil\n",
    "    'weight': 0.01,                       #? loss weight for regularization item\n",
    "    'max_count': 20000,                   #? optimization iteration\n",
    "    'b_range': [20,2],                    #? beta decaying range\n",
    "    'keep_gpu': True,                     #? calibration data restore in gpu or cpu\n",
    "    'round_mode': 'learned_hard_sigmoid', #? ways to reconstruct the weight, currently only support learned_hard_sigmoid\n",
    "    'prob': 0.5,                          #? dropping probability of QDROP, 1.0 for Adaround and BRECQ\n",
    "}\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "ptq_reconstruction_config = dotdict(ptq_reconstruction_config)\n",
    "ptq_reconstruction_config_init = dotdict(ptq_reconstruction_config_init)\n",
    "\n",
    "def getModuleByName(model,moduleName):\n",
    "    '''\n",
    "        replace module with name modelName.moduleName with newModule\n",
    "    '''\n",
    "    tokens = moduleName.split('.')\n",
    "    m = model\n",
    "    for tok in tokens:\n",
    "        m = getattr(m,tok)\n",
    "    return m\n",
    "\n",
    "for b in MPQ_scheme:\n",
    "    mqb_fp_model = deepcopy(model)\n",
    "    \n",
    "    # MSE calibration on model parameters\n",
    "    backend = BackendType.Academic\n",
    "    extra_config = {\n",
    "        'extra_qconfig_dict': {\n",
    "            'w_observer': 'MSEObserver',                              # custom weight observer\n",
    "            'a_observer': 'EMAMSEObserver',                              # custom activation observer\n",
    "            'w_fakequantize': 'AdaRoundFakeQuantize' if adv_ptq else 'FixedFakeQuantize',\n",
    "            'a_fakequantize': 'QDropFakeQuantize' if adv_ptq else 'FixedFakeQuantize',\n",
    "            'w_qscheme': {\n",
    "                'bit': b,                                             # custom bitwidth for weight,\n",
    "                'symmetry': True,                                    # custom whether quant is symmetric for weight,\n",
    "                'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for weight,\n",
    "                'pot_scale': False,                                   # custom whether scale is power of two for weight.\n",
    "            },\n",
    "            'a_qscheme': {\n",
    "                'bit': 8,                                             # custom bitwidth for activation,\n",
    "                'symmetry': False,                                    # custom whether quant is symmetric for activation,\n",
    "                'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for activation,\n",
    "                'pot_scale': False,                                   # custom whether scale is power of two for activation.\n",
    "            }\n",
    "        }                                                         # custom tracer behavior, checkout https://github.com/pytorch/pytorch/blob/efcbbb177eacdacda80b94ad4ce34b9ed6cf687a/torch/fx/_symbolic_trace.py#L836\n",
    "    }\n",
    "    print(f'Prepare {b}bits model using MQBench')\n",
    "\n",
    "    exec(f'mqb_{b}bits_model=prepare_by_platform(mqb_fp_model, backend,extra_config).cuda()')\n",
    "    \n",
    "    # calibration loop\n",
    "    enable_calibration(eval(f'mqb_{b}bits_model'))\n",
    "    for img,label in calib_data:\n",
    "        eval(f'mqb_{b}bits_model')(img.cuda())\n",
    "    \n",
    "    if adv_ptq:\n",
    "        if os.path.exists(f'QDROP_{b}bits_{mn}.pt'):\n",
    "            exec(f'mqb_{b}bits_model=ptq_reconstruction(mqb_{b}bits_model, stacked_tensor, ptq_reconstruction_config_init).cuda()')\n",
    "            print(f'QDROP model already saved, now loading QDROP_{b}bits_{mn}.pt')\n",
    "            load_from = f'QDROP_{b}bits_{mn}.pt'\n",
    "            exec(f'mqb_{b}bits_model.load_state_dict(torch.load(load_from))')\n",
    "        else:\n",
    "            \n",
    "            exec(f'mqb_{b}bits_model=ptq_reconstruction(mqb_{b}bits_model, stacked_tensor, ptq_reconstruction_config).cuda()')\n",
    "            print(f'saving QDROP tuned model: QDROP_{b}bits_{mn}.pt...')\n",
    "            torch.save(eval(f'mqb_{b}bits_model').state_dict(),f'QDROP_{b}bits_{mn}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c08c97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Disable observer and Disable quantize.\n",
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n",
      "evaluate mqb quantized model\n",
      "{'top1': tensor([0.1000], device='cuda:0'), 'top5': tensor([0.5060], device='cuda:0'), 'loss': tensor(6.9102, device='cuda:0'), 'time': 150.59848380088806}\n",
      "[MQBENCH] INFO: Disable observer and Disable quantize.\n",
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n",
      "evaluate mqb quantized model\n",
      "{'top1': tensor([45.4260], device='cuda:0'), 'top5': tensor([70.3861], device='cuda:0'), 'loss': tensor(2.5618, device='cuda:0'), 'time': 152.38020753860474}\n",
      "[MQBENCH] INFO: Disable observer and Disable quantize.\n",
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n",
      "evaluate mqb quantized model\n",
      "{'top1': tensor([75.7821], device='cuda:0'), 'top5': tensor([92.7382], device='cuda:0'), 'loss': tensor(0.9645, device='cuda:0'), 'time': 153.1205551624298}\n"
     ]
    }
   ],
   "source": [
    "for b in MPQ_scheme: \n",
    "    disable_all(eval(f'mqb_{b}bits_model'))\n",
    "    # evaluation loop\n",
    "    enable_quantization(eval(f'mqb_{b}bits_model'))\n",
    "    eval(f'mqb_{b}bits_model').eval()\n",
    "    print('evaluate mqb quantized model')\n",
    "    print(evaluate(test,eval(f'mqb_{b}bits_model')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1d8226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Disable observer and Disable quantize.\n",
      "input of  conv1  is  x_post_act_fake_quantizer\n",
      "input of  layer1.0.conv1  is  maxpool_post_act_fake_quantizer\n",
      "input of  layer1.0.conv2  is  layer1_0_relu_post_act_fake_quantizer\n",
      "input of  layer1.0.conv3  is  layer1_0_relu_1_post_act_fake_quantizer\n",
      "input of  layer1.0.downsample.0  is  maxpool_post_act_fake_quantizer\n",
      "input of  layer1.1.conv1  is  layer1_0_relu_2_post_act_fake_quantizer\n",
      "input of  layer1.1.conv2  is  layer1_1_relu_post_act_fake_quantizer\n",
      "input of  layer1.1.conv3  is  layer1_1_relu_1_post_act_fake_quantizer\n",
      "input of  layer1.2.conv1  is  layer1_1_relu_2_post_act_fake_quantizer\n",
      "input of  layer1.2.conv2  is  layer1_2_relu_post_act_fake_quantizer\n",
      "input of  layer1.2.conv3  is  layer1_2_relu_1_post_act_fake_quantizer\n",
      "input of  layer2.0.conv1  is  layer1_2_relu_2_post_act_fake_quantizer\n",
      "input of  layer2.0.conv2  is  layer2_0_relu_post_act_fake_quantizer\n",
      "input of  layer2.0.conv3  is  layer2_0_relu_1_post_act_fake_quantizer\n",
      "input of  layer2.0.downsample.0  is  layer1_2_relu_2_post_act_fake_quantizer\n",
      "input of  layer2.1.conv1  is  layer2_0_relu_2_post_act_fake_quantizer\n",
      "input of  layer2.1.conv2  is  layer2_1_relu_post_act_fake_quantizer\n",
      "input of  layer2.1.conv3  is  layer2_1_relu_1_post_act_fake_quantizer\n",
      "input of  layer2.2.conv1  is  layer2_1_relu_2_post_act_fake_quantizer\n",
      "input of  layer2.2.conv2  is  layer2_2_relu_post_act_fake_quantizer\n",
      "input of  layer2.2.conv3  is  layer2_2_relu_1_post_act_fake_quantizer\n",
      "input of  layer2.3.conv1  is  layer2_2_relu_2_post_act_fake_quantizer\n",
      "input of  layer2.3.conv2  is  layer2_3_relu_post_act_fake_quantizer\n",
      "input of  layer2.3.conv3  is  layer2_3_relu_1_post_act_fake_quantizer\n",
      "input of  layer3.0.conv1  is  layer2_3_relu_2_post_act_fake_quantizer\n",
      "input of  layer3.0.conv2  is  layer3_0_relu_post_act_fake_quantizer\n",
      "input of  layer3.0.conv3  is  layer3_0_relu_1_post_act_fake_quantizer\n",
      "input of  layer3.0.downsample.0  is  layer2_3_relu_2_post_act_fake_quantizer\n",
      "input of  layer3.1.conv1  is  layer3_0_relu_2_post_act_fake_quantizer\n",
      "input of  layer3.1.conv2  is  layer3_1_relu_post_act_fake_quantizer\n",
      "input of  layer3.1.conv3  is  layer3_1_relu_1_post_act_fake_quantizer\n",
      "input of  layer3.2.conv1  is  layer3_1_relu_2_post_act_fake_quantizer\n",
      "input of  layer3.2.conv2  is  layer3_2_relu_post_act_fake_quantizer\n",
      "input of  layer3.2.conv3  is  layer3_2_relu_1_post_act_fake_quantizer\n",
      "input of  layer3.3.conv1  is  layer3_2_relu_2_post_act_fake_quantizer\n",
      "input of  layer3.3.conv2  is  layer3_3_relu_post_act_fake_quantizer\n",
      "input of  layer3.3.conv3  is  layer3_3_relu_1_post_act_fake_quantizer\n",
      "input of  layer3.4.conv1  is  layer3_3_relu_2_post_act_fake_quantizer\n",
      "input of  layer3.4.conv2  is  layer3_4_relu_post_act_fake_quantizer\n",
      "input of  layer3.4.conv3  is  layer3_4_relu_1_post_act_fake_quantizer\n",
      "input of  layer3.5.conv1  is  layer3_4_relu_2_post_act_fake_quantizer\n",
      "input of  layer3.5.conv2  is  layer3_5_relu_post_act_fake_quantizer\n",
      "input of  layer3.5.conv3  is  layer3_5_relu_1_post_act_fake_quantizer\n",
      "input of  layer4.0.conv1  is  layer3_5_relu_2_post_act_fake_quantizer\n",
      "input of  layer4.0.conv2  is  layer4_0_relu_post_act_fake_quantizer\n",
      "input of  layer4.0.conv3  is  layer4_0_relu_1_post_act_fake_quantizer\n",
      "input of  layer4.0.downsample.0  is  layer3_5_relu_2_post_act_fake_quantizer\n",
      "input of  layer4.1.conv1  is  layer4_0_relu_2_post_act_fake_quantizer\n",
      "input of  layer4.1.conv2  is  layer4_1_relu_post_act_fake_quantizer\n",
      "input of  layer4.1.conv3  is  layer4_1_relu_1_post_act_fake_quantizer\n",
      "input of  layer4.2.conv1  is  layer4_1_relu_2_post_act_fake_quantizer\n",
      "input of  layer4.2.conv2  is  layer4_2_relu_post_act_fake_quantizer\n",
      "input of  layer4.2.conv3  is  layer4_2_relu_1_post_act_fake_quantizer\n",
      "input of  fc  is  flatten_post_act_fake_quantizer\n"
     ]
    }
   ],
   "source": [
    "mqb_fp_model = deepcopy(mqb_8bits_model)\n",
    "disable_all(mqb_fp_model)\n",
    "mqb_mix_model = deepcopy(mqb_fp_model)\n",
    "\n",
    "# 1. record all modules we want to consider\n",
    "types_to_quant = (torch.nn.Conv2d,torch.nn.Linear)\n",
    "\n",
    "layer_input_map = {}\n",
    "\n",
    "for node in mqb_8bits_model.graph.nodes:\n",
    "    try:\n",
    "        node_target = getModuleByName(mqb_mix_model,node.target)\n",
    "        if isinstance(node_target,types_to_quant):\n",
    "            node_args = node.args[0]\n",
    "            print('input of ',node.target,' is ',node_args)\n",
    "            layer_input_map[node.target] = str(node_args.target)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecaa6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_metric = ('loss',evaluate(calib_data,mqb_fp_model)['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdeec63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(perturb_scheme):\n",
    "    # perturb_scheme: {layer_name:(act_bits,weight_bits)}\n",
    "    for layer_name in perturb_scheme:\n",
    "        a_bits,w_bits = perturb_scheme[layer_name]\n",
    "        \n",
    "        if w_bits is not None:\n",
    "            mix_module = getModuleByName(mqb_mix_model,layer_name)\n",
    "            tar_module = getModuleByName(eval(f'mqb_{w_bits}bits_model'),layer_name)\n",
    "            # replace weight quant to use a_bits quantization\n",
    "            w_cmd = f'mix_module.weight_fake_quant=tar_module.weight_fake_quant'\n",
    "            exec(w_cmd)\n",
    "        \n",
    "        if a_bits is not None:\n",
    "        \n",
    "            # replace act quant to use w_bits quantization\n",
    "            a_cmd = f'mqb_mix_model.{layer_input_map[layer_name]}=mqb_{a_bits}bits_model.{layer_input_map[layer_name]}'\n",
    "            exec(a_cmd)\n",
    "        \n",
    "        #print(layer_name)\n",
    "        #print(a_cmd)\n",
    "        #print(w_cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ee550ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturb functionality test\n",
    "perturb_scheme = {}\n",
    "for layer_name in layer_input_map:\n",
    "    perturb_scheme[layer_name] = (8,8)\n",
    "perturb(perturb_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42af6e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top1': tensor([75.7821], device='cuda:0'),\n",
       " 'top5': tensor([92.7382], device='cuda:0'),\n",
       " 'loss': tensor(0.9645, device='cuda:0'),\n",
       " 'time': 153.06207251548767}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test,mqb_mix_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6987f2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Disable observer and Disable quantize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'top1': tensor([76.1461], device='cuda:0'),\n",
       " 'top5': tensor([92.8722], device='cuda:0'),\n",
       " 'loss': tensor(0.9616, device='cuda:0'),\n",
       " 'time': 136.93065333366394}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mqb_mix_model = deepcopy(mqb_8bits_model)\n",
    "disable_all(mqb_mix_model)\n",
    "evaluate(test,mqb_mix_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846ea48",
   "metadata": {},
   "source": [
    "## CLADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6716b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "kl_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "def kldiv(quant_logit,fp_logit):\n",
    "    inp = F.log_softmax(quant_logit,dim=-1)\n",
    "    tar = F.softmax(fp_logit,dim=-1)\n",
    "    return kl_loss(inp,tar)\n",
    "\n",
    "def perturb_loss(perturb_scheme,ref_metric=ref_metric,\n",
    "                 eval_data=calib_data,printInfo=False,KL=False):\n",
    "    \n",
    "    global mqb_mix_model\n",
    "    mqb_mix_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        perturb(perturb_scheme)\n",
    "            \n",
    "        # do evaluation\n",
    "        if not KL:\n",
    "            res = evaluate(eval_data,mqb_mix_model)\n",
    "            perturbed_loss = res[ref_metric[0]] - ref_metric[1]\n",
    "        else:\n",
    "            perturbed_loss = []\n",
    "            \n",
    "            for (data,fp_out) in zip(calib_data,calib_fp_output):\n",
    "                img,label = data\n",
    "                quant_out = mqb_mix_model(img.cuda())\n",
    "                perturbed_loss.append(kldiv(quant_out,fp_out))\n",
    "            #print(perturbed_loss)\n",
    "            perturbed_loss = torch.tensor(perturbed_loss).mean()    \n",
    "        \n",
    "        if printInfo:\n",
    "            print(f'use kl {KL} perturbed loss {perturbed_loss}')\n",
    "        \n",
    "        # recover layers\n",
    "        mqb_mix_model = deepcopy(mqb_fp_model)\n",
    "            \n",
    "    return perturbed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de4162ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturb loss functionality check\n",
    "# del layer_input_map['conv1']\n",
    "# del layer_input_map['fc']\n",
    "\n",
    "# for layer in layer_input_map:\n",
    "#     for a_bits in MPQ_scheme:\n",
    "#         for w_bits in MPQ_scheme:\n",
    "#             print(f'{layer} (a:{a_bits} bits,w:{w_bits} bits))')\n",
    "#             p = perturb_loss({layer:(a_bits,w_bits)},eval_data=test,printInfo=True,KL=False)\n",
    "#             #print(f'{layer} (a:{a_bits} bits,w:{w_bits} bits), accuracy degradation: {p*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47dd85f",
   "metadata": {},
   "source": [
    "## Build Cached Grad if not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "del layer_input_map['conv1']\n",
    "del layer_input_map['fc']\n",
    "\n",
    "import time\n",
    "s_time = time.time()\n",
    "cached = {}\n",
    "aw_scheme = []\n",
    "for a_bits in MPQ_scheme:\n",
    "    for w_bits in MPQ_scheme:\n",
    "        aw_scheme.append((a_bits,w_bits))\n",
    "\n",
    "aw_scheme = [(8,2),(8,4),(8,8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d37d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aw_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f370df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "KL=True\n",
    "for n in layer_input_map:\n",
    "    for m in layer_input_map:\n",
    "        for naw in aw_scheme:\n",
    "            for maw in aw_scheme:\n",
    "                if (n,m,naw,maw) not in cached:\n",
    "                    if n == m:\n",
    "                        if naw == maw:\n",
    "                            \n",
    "                            p = perturb_loss({n:naw},ref_metric,calib_data,KL=KL)\n",
    "                            print(f'perturb layer {n} to A{naw[0]}W{naw[1]} p={p}')\n",
    "                        else:\n",
    "                            p = 0\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        p = perturb_loss({n:naw,m:maw},ref_metric,calib_data,KL=KL)\n",
    "                        print(f'perturb layer {n} to A{naw[0]}W{naw[1]} and layer {m} to A{maw[0]}W{maw[1]} p={p}')\n",
    "                    \n",
    "                    cached[(n,m,naw,maw)] = cached[(m,n,maw,naw)] = p\n",
    "                    \n",
    "print(f'{time.time()-s_time:.2f} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf90f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239967a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index = {}\n",
    "cnt = 0\n",
    "for layer in layer_input_map:\n",
    "    for s in aw_scheme:\n",
    "        layer_index[layer+f'{s}bits'] = cnt\n",
    "        cnt += 1\n",
    "L = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece828de",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hm = np.zeros(shape=(L,L))\n",
    "for n in layer_input_map:\n",
    "    for m in layer_input_map:\n",
    "        for naw in aw_scheme:\n",
    "            for maw in aw_scheme:\n",
    "                hm[layer_index[n+f'{naw}bits'],layer_index[m+f'{maw}bits']] = cached[(n,m,naw,maw)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad = np.zeros_like(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99559c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generala248w248_i1kresnet50_calib','wb') as f:\n",
    "    pickle.dump({'Ltilde':hm,'layer_index':layer_index},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_loss(['conv1',],ref_metric,eval_data=calib_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc001d",
   "metadata": {},
   "source": [
    "## Load Cached Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "498e1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "# with open('generala248w248_c100resnet56_calib','rb') as f:\n",
    "# with open('CachedGrad_QDROP(2, 4, 8)cifar100_resnet56.pkl','rb') as f:\n",
    "#with open('CachedGrad_((4, 4), (4, 8), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "with open('CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    hm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb1de436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Ltilde', 'layer_index'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bdf70d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer1.0.conv1(8, 2)bits': 0,\n",
       " 'layer1.0.conv1(8, 4)bits': 1,\n",
       " 'layer1.0.conv1(8, 8)bits': 2,\n",
       " 'layer1.0.conv2(8, 2)bits': 3,\n",
       " 'layer1.0.conv2(8, 4)bits': 4,\n",
       " 'layer1.0.conv2(8, 8)bits': 5,\n",
       " 'layer1.0.conv3(8, 2)bits': 6,\n",
       " 'layer1.0.conv3(8, 4)bits': 7,\n",
       " 'layer1.0.conv3(8, 8)bits': 8,\n",
       " 'layer1.0.downsample.0(8, 2)bits': 9,\n",
       " 'layer1.0.downsample.0(8, 4)bits': 10,\n",
       " 'layer1.0.downsample.0(8, 8)bits': 11,\n",
       " 'layer1.1.conv1(8, 2)bits': 12,\n",
       " 'layer1.1.conv1(8, 4)bits': 13,\n",
       " 'layer1.1.conv1(8, 8)bits': 14,\n",
       " 'layer1.1.conv2(8, 2)bits': 15,\n",
       " 'layer1.1.conv2(8, 4)bits': 16,\n",
       " 'layer1.1.conv2(8, 8)bits': 17,\n",
       " 'layer1.1.conv3(8, 2)bits': 18,\n",
       " 'layer1.1.conv3(8, 4)bits': 19,\n",
       " 'layer1.1.conv3(8, 8)bits': 20,\n",
       " 'layer1.2.conv1(8, 2)bits': 21,\n",
       " 'layer1.2.conv1(8, 4)bits': 22,\n",
       " 'layer1.2.conv1(8, 8)bits': 23,\n",
       " 'layer1.2.conv2(8, 2)bits': 24,\n",
       " 'layer1.2.conv2(8, 4)bits': 25,\n",
       " 'layer1.2.conv2(8, 8)bits': 26,\n",
       " 'layer1.2.conv3(8, 2)bits': 27,\n",
       " 'layer1.2.conv3(8, 4)bits': 28,\n",
       " 'layer1.2.conv3(8, 8)bits': 29,\n",
       " 'layer2.0.conv1(8, 2)bits': 30,\n",
       " 'layer2.0.conv1(8, 4)bits': 31,\n",
       " 'layer2.0.conv1(8, 8)bits': 32,\n",
       " 'layer2.0.conv2(8, 2)bits': 33,\n",
       " 'layer2.0.conv2(8, 4)bits': 34,\n",
       " 'layer2.0.conv2(8, 8)bits': 35,\n",
       " 'layer2.0.conv3(8, 2)bits': 36,\n",
       " 'layer2.0.conv3(8, 4)bits': 37,\n",
       " 'layer2.0.conv3(8, 8)bits': 38,\n",
       " 'layer2.0.downsample.0(8, 2)bits': 39,\n",
       " 'layer2.0.downsample.0(8, 4)bits': 40,\n",
       " 'layer2.0.downsample.0(8, 8)bits': 41,\n",
       " 'layer2.1.conv1(8, 2)bits': 42,\n",
       " 'layer2.1.conv1(8, 4)bits': 43,\n",
       " 'layer2.1.conv1(8, 8)bits': 44,\n",
       " 'layer2.1.conv2(8, 2)bits': 45,\n",
       " 'layer2.1.conv2(8, 4)bits': 46,\n",
       " 'layer2.1.conv2(8, 8)bits': 47,\n",
       " 'layer2.1.conv3(8, 2)bits': 48,\n",
       " 'layer2.1.conv3(8, 4)bits': 49,\n",
       " 'layer2.1.conv3(8, 8)bits': 50,\n",
       " 'layer2.2.conv1(8, 2)bits': 51,\n",
       " 'layer2.2.conv1(8, 4)bits': 52,\n",
       " 'layer2.2.conv1(8, 8)bits': 53,\n",
       " 'layer2.2.conv2(8, 2)bits': 54,\n",
       " 'layer2.2.conv2(8, 4)bits': 55,\n",
       " 'layer2.2.conv2(8, 8)bits': 56,\n",
       " 'layer2.2.conv3(8, 2)bits': 57,\n",
       " 'layer2.2.conv3(8, 4)bits': 58,\n",
       " 'layer2.2.conv3(8, 8)bits': 59,\n",
       " 'layer2.3.conv1(8, 2)bits': 60,\n",
       " 'layer2.3.conv1(8, 4)bits': 61,\n",
       " 'layer2.3.conv1(8, 8)bits': 62,\n",
       " 'layer2.3.conv2(8, 2)bits': 63,\n",
       " 'layer2.3.conv2(8, 4)bits': 64,\n",
       " 'layer2.3.conv2(8, 8)bits': 65,\n",
       " 'layer2.3.conv3(8, 2)bits': 66,\n",
       " 'layer2.3.conv3(8, 4)bits': 67,\n",
       " 'layer2.3.conv3(8, 8)bits': 68,\n",
       " 'layer3.0.conv1(8, 2)bits': 69,\n",
       " 'layer3.0.conv1(8, 4)bits': 70,\n",
       " 'layer3.0.conv1(8, 8)bits': 71,\n",
       " 'layer3.0.conv2(8, 2)bits': 72,\n",
       " 'layer3.0.conv2(8, 4)bits': 73,\n",
       " 'layer3.0.conv2(8, 8)bits': 74,\n",
       " 'layer3.0.conv3(8, 2)bits': 75,\n",
       " 'layer3.0.conv3(8, 4)bits': 76,\n",
       " 'layer3.0.conv3(8, 8)bits': 77,\n",
       " 'layer3.0.downsample.0(8, 2)bits': 78,\n",
       " 'layer3.0.downsample.0(8, 4)bits': 79,\n",
       " 'layer3.0.downsample.0(8, 8)bits': 80,\n",
       " 'layer3.1.conv1(8, 2)bits': 81,\n",
       " 'layer3.1.conv1(8, 4)bits': 82,\n",
       " 'layer3.1.conv1(8, 8)bits': 83,\n",
       " 'layer3.1.conv2(8, 2)bits': 84,\n",
       " 'layer3.1.conv2(8, 4)bits': 85,\n",
       " 'layer3.1.conv2(8, 8)bits': 86,\n",
       " 'layer3.1.conv3(8, 2)bits': 87,\n",
       " 'layer3.1.conv3(8, 4)bits': 88,\n",
       " 'layer3.1.conv3(8, 8)bits': 89,\n",
       " 'layer3.2.conv1(8, 2)bits': 90,\n",
       " 'layer3.2.conv1(8, 4)bits': 91,\n",
       " 'layer3.2.conv1(8, 8)bits': 92,\n",
       " 'layer3.2.conv2(8, 2)bits': 93,\n",
       " 'layer3.2.conv2(8, 4)bits': 94,\n",
       " 'layer3.2.conv2(8, 8)bits': 95,\n",
       " 'layer3.2.conv3(8, 2)bits': 96,\n",
       " 'layer3.2.conv3(8, 4)bits': 97,\n",
       " 'layer3.2.conv3(8, 8)bits': 98,\n",
       " 'layer3.3.conv1(8, 2)bits': 99,\n",
       " 'layer3.3.conv1(8, 4)bits': 100,\n",
       " 'layer3.3.conv1(8, 8)bits': 101,\n",
       " 'layer3.3.conv2(8, 2)bits': 102,\n",
       " 'layer3.3.conv2(8, 4)bits': 103,\n",
       " 'layer3.3.conv2(8, 8)bits': 104,\n",
       " 'layer3.3.conv3(8, 2)bits': 105,\n",
       " 'layer3.3.conv3(8, 4)bits': 106,\n",
       " 'layer3.3.conv3(8, 8)bits': 107,\n",
       " 'layer3.4.conv1(8, 2)bits': 108,\n",
       " 'layer3.4.conv1(8, 4)bits': 109,\n",
       " 'layer3.4.conv1(8, 8)bits': 110,\n",
       " 'layer3.4.conv2(8, 2)bits': 111,\n",
       " 'layer3.4.conv2(8, 4)bits': 112,\n",
       " 'layer3.4.conv2(8, 8)bits': 113,\n",
       " 'layer3.4.conv3(8, 2)bits': 114,\n",
       " 'layer3.4.conv3(8, 4)bits': 115,\n",
       " 'layer3.4.conv3(8, 8)bits': 116,\n",
       " 'layer3.5.conv1(8, 2)bits': 117,\n",
       " 'layer3.5.conv1(8, 4)bits': 118,\n",
       " 'layer3.5.conv1(8, 8)bits': 119,\n",
       " 'layer3.5.conv2(8, 2)bits': 120,\n",
       " 'layer3.5.conv2(8, 4)bits': 121,\n",
       " 'layer3.5.conv2(8, 8)bits': 122,\n",
       " 'layer3.5.conv3(8, 2)bits': 123,\n",
       " 'layer3.5.conv3(8, 4)bits': 124,\n",
       " 'layer3.5.conv3(8, 8)bits': 125,\n",
       " 'layer4.0.conv1(8, 2)bits': 126,\n",
       " 'layer4.0.conv1(8, 4)bits': 127,\n",
       " 'layer4.0.conv1(8, 8)bits': 128,\n",
       " 'layer4.0.conv2(8, 2)bits': 129,\n",
       " 'layer4.0.conv2(8, 4)bits': 130,\n",
       " 'layer4.0.conv2(8, 8)bits': 131,\n",
       " 'layer4.0.conv3(8, 2)bits': 132,\n",
       " 'layer4.0.conv3(8, 4)bits': 133,\n",
       " 'layer4.0.conv3(8, 8)bits': 134,\n",
       " 'layer4.0.downsample.0(8, 2)bits': 135,\n",
       " 'layer4.0.downsample.0(8, 4)bits': 136,\n",
       " 'layer4.0.downsample.0(8, 8)bits': 137,\n",
       " 'layer4.1.conv1(8, 2)bits': 138,\n",
       " 'layer4.1.conv1(8, 4)bits': 139,\n",
       " 'layer4.1.conv1(8, 8)bits': 140,\n",
       " 'layer4.1.conv2(8, 2)bits': 141,\n",
       " 'layer4.1.conv2(8, 4)bits': 142,\n",
       " 'layer4.1.conv2(8, 8)bits': 143,\n",
       " 'layer4.1.conv3(8, 2)bits': 144,\n",
       " 'layer4.1.conv3(8, 4)bits': 145,\n",
       " 'layer4.1.conv3(8, 8)bits': 146,\n",
       " 'layer4.2.conv1(8, 2)bits': 147,\n",
       " 'layer4.2.conv1(8, 4)bits': 148,\n",
       " 'layer4.2.conv1(8, 8)bits': 149,\n",
       " 'layer4.2.conv2(8, 2)bits': 150,\n",
       " 'layer4.2.conv2(8, 4)bits': 151,\n",
       " 'layer4.2.conv2(8, 8)bits': 152,\n",
       " 'layer4.2.conv3(8, 2)bits': 153,\n",
       " 'layer4.2.conv3(8, 4)bits': 154,\n",
       " 'layer4.2.conv3(8, 8)bits': 155}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm['layer_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "561a7c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 156)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm['Ltilde'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf87d3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 layer layer1.0.conv1 scheme (8, 2)bits Ltilde 0.130510\n",
      "index 1 layer layer1.0.conv1 scheme (8, 4)bits Ltilde 0.044633\n",
      "index 2 layer layer1.0.conv1 scheme (8, 8)bits Ltilde 0.001955\n",
      "index 3 layer layer1.0.conv2 scheme (8, 2)bits Ltilde 0.454489\n",
      "index 4 layer layer1.0.conv2 scheme (8, 4)bits Ltilde 0.096717\n",
      "index 5 layer layer1.0.conv2 scheme (8, 8)bits Ltilde 0.000384\n",
      "index 6 layer layer1.0.conv3 scheme (8, 2)bits Ltilde 0.676383\n",
      "index 7 layer layer1.0.conv3 scheme (8, 4)bits Ltilde 0.024555\n",
      "index 8 layer layer1.0.conv3 scheme (8, 8)bits Ltilde 0.000159\n",
      "index 9 layer layer1.0.downsample.0 scheme (8, 2)bits Ltilde 1.619576\n",
      "index 10 layer layer1.0.downsample.0 scheme (8, 4)bits Ltilde 0.197855\n",
      "index 11 layer layer1.0.downsample.0 scheme (8, 8)bits Ltilde 0.002924\n",
      "index 12 layer layer1.1.conv1 scheme (8, 2)bits Ltilde 0.161679\n",
      "index 13 layer layer1.1.conv1 scheme (8, 4)bits Ltilde 0.004693\n",
      "index 14 layer layer1.1.conv1 scheme (8, 8)bits Ltilde 0.000088\n",
      "index 15 layer layer1.1.conv2 scheme (8, 2)bits Ltilde 0.179423\n",
      "index 16 layer layer1.1.conv2 scheme (8, 4)bits Ltilde 0.009516\n",
      "index 17 layer layer1.1.conv2 scheme (8, 8)bits Ltilde 0.000305\n",
      "index 18 layer layer1.1.conv3 scheme (8, 2)bits Ltilde 0.105572\n",
      "index 19 layer layer1.1.conv3 scheme (8, 4)bits Ltilde 0.005363\n",
      "index 20 layer layer1.1.conv3 scheme (8, 8)bits Ltilde 0.000033\n",
      "index 21 layer layer1.2.conv1 scheme (8, 2)bits Ltilde 0.201656\n",
      "index 22 layer layer1.2.conv1 scheme (8, 4)bits Ltilde 0.002117\n",
      "index 23 layer layer1.2.conv1 scheme (8, 8)bits Ltilde 0.000083\n",
      "index 24 layer layer1.2.conv2 scheme (8, 2)bits Ltilde 1.068692\n",
      "index 25 layer layer1.2.conv2 scheme (8, 4)bits Ltilde 0.005736\n",
      "index 26 layer layer1.2.conv2 scheme (8, 8)bits Ltilde 0.000073\n",
      "index 27 layer layer1.2.conv3 scheme (8, 2)bits Ltilde 0.079466\n",
      "index 28 layer layer1.2.conv3 scheme (8, 4)bits Ltilde 0.004822\n",
      "index 29 layer layer1.2.conv3 scheme (8, 8)bits Ltilde 0.000033\n",
      "index 30 layer layer2.0.conv1 scheme (8, 2)bits Ltilde 0.271540\n",
      "index 31 layer layer2.0.conv1 scheme (8, 4)bits Ltilde 0.013600\n",
      "index 32 layer layer2.0.conv1 scheme (8, 8)bits Ltilde 0.000175\n",
      "index 33 layer layer2.0.conv2 scheme (8, 2)bits Ltilde 0.546789\n",
      "index 34 layer layer2.0.conv2 scheme (8, 4)bits Ltilde 0.008969\n",
      "index 35 layer layer2.0.conv2 scheme (8, 8)bits Ltilde 0.000053\n",
      "index 36 layer layer2.0.conv3 scheme (8, 2)bits Ltilde 0.771775\n",
      "index 37 layer layer2.0.conv3 scheme (8, 4)bits Ltilde 0.029354\n",
      "index 38 layer layer2.0.conv3 scheme (8, 8)bits Ltilde 0.000289\n",
      "index 39 layer layer2.0.downsample.0 scheme (8, 2)bits Ltilde 0.941005\n",
      "index 40 layer layer2.0.downsample.0 scheme (8, 4)bits Ltilde 0.040544\n",
      "index 41 layer layer2.0.downsample.0 scheme (8, 8)bits Ltilde 0.000390\n",
      "index 42 layer layer2.1.conv1 scheme (8, 2)bits Ltilde 0.105454\n",
      "index 43 layer layer2.1.conv1 scheme (8, 4)bits Ltilde 0.005313\n",
      "index 44 layer layer2.1.conv1 scheme (8, 8)bits Ltilde 0.000048\n",
      "index 45 layer layer2.1.conv2 scheme (8, 2)bits Ltilde 0.816042\n",
      "index 46 layer layer2.1.conv2 scheme (8, 4)bits Ltilde 0.042021\n",
      "index 47 layer layer2.1.conv2 scheme (8, 8)bits Ltilde 0.000116\n",
      "index 48 layer layer2.1.conv3 scheme (8, 2)bits Ltilde 0.104554\n",
      "index 49 layer layer2.1.conv3 scheme (8, 4)bits Ltilde 0.007859\n",
      "index 50 layer layer2.1.conv3 scheme (8, 8)bits Ltilde 0.000070\n",
      "index 51 layer layer2.2.conv1 scheme (8, 2)bits Ltilde 0.131168\n",
      "index 52 layer layer2.2.conv1 scheme (8, 4)bits Ltilde 0.004014\n",
      "index 53 layer layer2.2.conv1 scheme (8, 8)bits Ltilde 0.000048\n",
      "index 54 layer layer2.2.conv2 scheme (8, 2)bits Ltilde 0.376178\n",
      "index 55 layer layer2.2.conv2 scheme (8, 4)bits Ltilde 0.009405\n",
      "index 56 layer layer2.2.conv2 scheme (8, 8)bits Ltilde 0.000049\n",
      "index 57 layer layer2.2.conv3 scheme (8, 2)bits Ltilde 0.318067\n",
      "index 58 layer layer2.2.conv3 scheme (8, 4)bits Ltilde 0.015219\n",
      "index 59 layer layer2.2.conv3 scheme (8, 8)bits Ltilde 0.000109\n",
      "index 60 layer layer2.3.conv1 scheme (8, 2)bits Ltilde 0.136781\n",
      "index 61 layer layer2.3.conv1 scheme (8, 4)bits Ltilde 0.003471\n",
      "index 62 layer layer2.3.conv1 scheme (8, 8)bits Ltilde 0.000048\n",
      "index 63 layer layer2.3.conv2 scheme (8, 2)bits Ltilde 1.844815\n",
      "index 64 layer layer2.3.conv2 scheme (8, 4)bits Ltilde 0.005531\n",
      "index 65 layer layer2.3.conv2 scheme (8, 8)bits Ltilde 0.000043\n",
      "index 66 layer layer2.3.conv3 scheme (8, 2)bits Ltilde 0.129237\n",
      "index 67 layer layer2.3.conv3 scheme (8, 4)bits Ltilde 0.008010\n",
      "index 68 layer layer2.3.conv3 scheme (8, 8)bits Ltilde 0.000052\n",
      "index 69 layer layer3.0.conv1 scheme (8, 2)bits Ltilde 0.876981\n",
      "index 70 layer layer3.0.conv1 scheme (8, 4)bits Ltilde 0.040769\n",
      "index 71 layer layer3.0.conv1 scheme (8, 8)bits Ltilde 0.000173\n",
      "index 72 layer layer3.0.conv2 scheme (8, 2)bits Ltilde 0.475966\n",
      "index 73 layer layer3.0.conv2 scheme (8, 4)bits Ltilde 0.011949\n",
      "index 74 layer layer3.0.conv2 scheme (8, 8)bits Ltilde 0.000057\n",
      "index 75 layer layer3.0.conv3 scheme (8, 2)bits Ltilde 0.430296\n",
      "index 76 layer layer3.0.conv3 scheme (8, 4)bits Ltilde 0.016251\n",
      "index 77 layer layer3.0.conv3 scheme (8, 8)bits Ltilde 0.000176\n",
      "index 78 layer layer3.0.downsample.0 scheme (8, 2)bits Ltilde 0.497442\n",
      "index 79 layer layer3.0.downsample.0 scheme (8, 4)bits Ltilde 0.028993\n",
      "index 80 layer layer3.0.downsample.0 scheme (8, 8)bits Ltilde 0.000305\n",
      "index 81 layer layer3.1.conv1 scheme (8, 2)bits Ltilde 0.963626\n",
      "index 82 layer layer3.1.conv1 scheme (8, 4)bits Ltilde 0.009459\n",
      "index 83 layer layer3.1.conv1 scheme (8, 8)bits Ltilde 0.000117\n",
      "index 84 layer layer3.1.conv2 scheme (8, 2)bits Ltilde 0.984308\n",
      "index 85 layer layer3.1.conv2 scheme (8, 4)bits Ltilde 0.005547\n",
      "index 86 layer layer3.1.conv2 scheme (8, 8)bits Ltilde 0.000159\n",
      "index 87 layer layer3.1.conv3 scheme (8, 2)bits Ltilde 0.139234\n",
      "index 88 layer layer3.1.conv3 scheme (8, 4)bits Ltilde 0.021862\n",
      "index 89 layer layer3.1.conv3 scheme (8, 8)bits Ltilde 0.000458\n",
      "index 90 layer layer3.2.conv1 scheme (8, 2)bits Ltilde 0.258662\n",
      "index 91 layer layer3.2.conv1 scheme (8, 4)bits Ltilde 0.008449\n",
      "index 92 layer layer3.2.conv1 scheme (8, 8)bits Ltilde 0.000136\n",
      "index 93 layer layer3.2.conv2 scheme (8, 2)bits Ltilde 0.368568\n",
      "index 94 layer layer3.2.conv2 scheme (8, 4)bits Ltilde 0.004828\n",
      "index 95 layer layer3.2.conv2 scheme (8, 8)bits Ltilde 0.000057\n",
      "index 96 layer layer3.2.conv3 scheme (8, 2)bits Ltilde 0.132564\n",
      "index 97 layer layer3.2.conv3 scheme (8, 4)bits Ltilde 0.008387\n",
      "index 98 layer layer3.2.conv3 scheme (8, 8)bits Ltilde 0.000196\n",
      "index 99 layer layer3.3.conv1 scheme (8, 2)bits Ltilde 0.202566\n",
      "index 100 layer layer3.3.conv1 scheme (8, 4)bits Ltilde 0.009295\n",
      "index 101 layer layer3.3.conv1 scheme (8, 8)bits Ltilde 0.000132\n",
      "index 102 layer layer3.3.conv2 scheme (8, 2)bits Ltilde 0.157479\n",
      "index 103 layer layer3.3.conv2 scheme (8, 4)bits Ltilde 0.004814\n",
      "index 104 layer layer3.3.conv2 scheme (8, 8)bits Ltilde 0.000070\n",
      "index 105 layer layer3.3.conv3 scheme (8, 2)bits Ltilde 0.111898\n",
      "index 106 layer layer3.3.conv3 scheme (8, 4)bits Ltilde 0.010517\n",
      "index 107 layer layer3.3.conv3 scheme (8, 8)bits Ltilde 0.000240\n",
      "index 108 layer layer3.4.conv1 scheme (8, 2)bits Ltilde 0.157150\n",
      "index 109 layer layer3.4.conv1 scheme (8, 4)bits Ltilde 0.007120\n",
      "index 110 layer layer3.4.conv1 scheme (8, 8)bits Ltilde 0.000209\n",
      "index 111 layer layer3.4.conv2 scheme (8, 2)bits Ltilde 0.169621\n",
      "index 112 layer layer3.4.conv2 scheme (8, 4)bits Ltilde 0.003393\n",
      "index 113 layer layer3.4.conv2 scheme (8, 8)bits Ltilde 0.000057\n",
      "index 114 layer layer3.4.conv3 scheme (8, 2)bits Ltilde 0.095449\n",
      "index 115 layer layer3.4.conv3 scheme (8, 4)bits Ltilde 0.008421\n",
      "index 116 layer layer3.4.conv3 scheme (8, 8)bits Ltilde 0.000262\n",
      "index 117 layer layer3.5.conv1 scheme (8, 2)bits Ltilde 0.199734\n",
      "index 118 layer layer3.5.conv1 scheme (8, 4)bits Ltilde 0.008992\n",
      "index 119 layer layer3.5.conv1 scheme (8, 8)bits Ltilde 0.000241\n",
      "index 120 layer layer3.5.conv2 scheme (8, 2)bits Ltilde 0.198102\n",
      "index 121 layer layer3.5.conv2 scheme (8, 4)bits Ltilde 0.005014\n",
      "index 122 layer layer3.5.conv2 scheme (8, 8)bits Ltilde 0.000169\n",
      "index 123 layer layer3.5.conv3 scheme (8, 2)bits Ltilde 0.108387\n",
      "index 124 layer layer3.5.conv3 scheme (8, 4)bits Ltilde 0.006871\n",
      "index 125 layer layer3.5.conv3 scheme (8, 8)bits Ltilde 0.000092\n",
      "index 126 layer layer4.0.conv1 scheme (8, 2)bits Ltilde 0.639170\n",
      "index 127 layer layer4.0.conv1 scheme (8, 4)bits Ltilde 0.020045\n",
      "index 128 layer layer4.0.conv1 scheme (8, 8)bits Ltilde 0.000867\n",
      "index 129 layer layer4.0.conv2 scheme (8, 2)bits Ltilde 0.204934\n",
      "index 130 layer layer4.0.conv2 scheme (8, 4)bits Ltilde 0.014597\n",
      "index 131 layer layer4.0.conv2 scheme (8, 8)bits Ltilde 0.002124\n",
      "index 132 layer layer4.0.conv3 scheme (8, 2)bits Ltilde 0.322082\n",
      "index 133 layer layer4.0.conv3 scheme (8, 4)bits Ltilde 0.013111\n",
      "index 134 layer layer4.0.conv3 scheme (8, 8)bits Ltilde 0.000917\n",
      "index 135 layer layer4.0.downsample.0 scheme (8, 2)bits Ltilde 0.069120\n",
      "index 136 layer layer4.0.downsample.0 scheme (8, 4)bits Ltilde 0.019811\n",
      "index 137 layer layer4.0.downsample.0 scheme (8, 8)bits Ltilde 0.002520\n",
      "index 138 layer layer4.1.conv1 scheme (8, 2)bits Ltilde 0.050847\n",
      "index 139 layer layer4.1.conv1 scheme (8, 4)bits Ltilde 0.013978\n",
      "index 140 layer layer4.1.conv1 scheme (8, 8)bits Ltilde 0.001773\n",
      "index 141 layer layer4.1.conv2 scheme (8, 2)bits Ltilde 0.312828\n",
      "index 142 layer layer4.1.conv2 scheme (8, 4)bits Ltilde 0.008358\n",
      "index 143 layer layer4.1.conv2 scheme (8, 8)bits Ltilde 0.000120\n",
      "index 144 layer layer4.1.conv3 scheme (8, 2)bits Ltilde 0.124703\n",
      "index 145 layer layer4.1.conv3 scheme (8, 4)bits Ltilde 0.007513\n",
      "index 146 layer layer4.1.conv3 scheme (8, 8)bits Ltilde 0.000185\n",
      "index 147 layer layer4.2.conv1 scheme (8, 2)bits Ltilde 1.573955\n",
      "index 148 layer layer4.2.conv1 scheme (8, 4)bits Ltilde 0.019228\n",
      "index 149 layer layer4.2.conv1 scheme (8, 8)bits Ltilde 0.001251\n",
      "index 150 layer layer4.2.conv2 scheme (8, 2)bits Ltilde 0.585869\n",
      "index 151 layer layer4.2.conv2 scheme (8, 4)bits Ltilde 0.002401\n",
      "index 152 layer layer4.2.conv2 scheme (8, 8)bits Ltilde 0.000090\n",
      "index 153 layer layer4.2.conv3 scheme (8, 2)bits Ltilde 0.479285\n",
      "index 154 layer layer4.2.conv3 scheme (8, 4)bits Ltilde 0.005710\n",
      "index 155 layer layer4.2.conv3 scheme (8, 8)bits Ltilde 0.000193\n"
     ]
    }
   ],
   "source": [
    "index2layerscheme = [None for i in range(hm['Ltilde'].shape[0])]\n",
    "\n",
    "for name in hm['layer_index']:\n",
    "    index = hm['layer_index'][name]\n",
    "    layer_name = name[:-10]\n",
    "    scheme = name[-10:]\n",
    "    a = hm['Ltilde']\n",
    "    print(f'index {index} layer {layer_name} scheme {scheme} Ltilde {a[index,index].item():.6f}')\n",
    "    \n",
    "    index2layerscheme[index] = (layer_name,scheme)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17bd25f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff7c54b81f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(hm['Ltilde'],cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78fde70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31508113787206454, 0.31508113787206454)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics\n",
    "#print(f'mean:{(hm['Ltilde']).mean()} mean abs {{(hm['Ltilde'].abs()).mean()}}')\n",
    "hm['Ltilde'].mean(),np.abs(hm['Ltilde']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "beb3fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached_grad is left hand side of equation 10 in draft\n",
    "# hm['Ltilde'] is loaded from pickle file (gradient caching phase)\n",
    "L = hm['Ltilde'].shape[0]\n",
    "cached_grad = np.zeros_like(hm['Ltilde'])\n",
    "for i in range(L):\n",
    "    for j in range(L):\n",
    "        layer_i,scheme_i = index2layerscheme[i]\n",
    "        layer_j,scheme_j = index2layerscheme[j]\n",
    "        if layer_i == layer_j:\n",
    "            if scheme_i == scheme_j:\n",
    "                cached_grad[i,j] = cached_grad[j,i] = 2 * hm['Ltilde'][i,j]\n",
    "            else:\n",
    "                #cached_grad[i,j] = cached_grad[j,i] = 4 * hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "                cached_grad[i,j] = cached_grad[j,i] = 0\n",
    "        else:\n",
    "            cached_grad[i,j] = cached_grad[j,i] = hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "        '''\n",
    "        print(index2layerscheme[i])\n",
    "        print(index2layerscheme[j])\n",
    "        '''\n",
    "        '''\n",
    "        if i == j:\n",
    "            cached_grad[i,j] = 0.5 * hm['Ltilde'][i,j]\n",
    "        else:\n",
    "            cached_grad[i,j] = 0.25 * (hm['Ltilde'][i,j]-hm['Ltilde'][i,i]-hm['Ltilde'][j,j])\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e34a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff7c5452fa0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cached_grad[cached_grad<0]=0\n",
    "plt.imshow(cached_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71d6487d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 156)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0736936c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a982e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge pyscipopt=3.5.0\n",
    "#!pip install cvxpy-base\n",
    "#!pip install -U pymoo\n",
    "#!pip install gurobipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bfca8",
   "metadata": {},
   "source": [
    "### Hook to record input and output shapes of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88a839b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer_hook(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(layer_hook, self).__init__()\n",
    "        self.in_shape = None\n",
    "        self.out_shape = None\n",
    "\n",
    "    def hook(self, module, inp, outp):\n",
    "        self.in_shape = inp[0].size()\n",
    "        self.out_shape = outp.size()\n",
    "    \n",
    "\n",
    "hooks = {}\n",
    "\n",
    "for layer in hm['layer_index']:\n",
    "    m = getModuleByName(model,layer[:-10])\n",
    "    hook = layer_hook()\n",
    "    hooks[layer[:-10]] = (hook,m.register_forward_hook(hook.hook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1bc42d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in hooks:\n",
    "#     hooks[layer][1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f56512fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for img,label in train:\n",
    "        model(img.cuda())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76e26a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_bitops(layer_name,a_bits,w_bits):\n",
    "    \n",
    "    m = getModuleByName(model,layer_name)\n",
    "    \n",
    "    if isinstance(m,torch.nn.Conv2d):\n",
    "        _,cin,_,_ = hooks[layer_name][0].in_shape\n",
    "        _,cout,hout,wout = hooks[layer_name][0].out_shape\n",
    "        \n",
    "#         print('in',hooks[layer_name][0].in_shape)\n",
    "#         print('out',hooks[layer_name][0].out_shape)\n",
    "        \n",
    "        n_muls = cin * m.weight.size()[2] * m.weight.size()[3] * cout * hout * wout\n",
    "        n_accs = (cin * m.weight.size()[2] * m.weight.size()[3] - 1) * cout * hout * wout\n",
    "        \n",
    "        bitops_per_mul = 2 * a_bits * w_bits\n",
    "        bitops_per_acc = (a_bits + w_bits) + np.ceil(np.log2(cin * m.weight.size()[2] * m.weight.size()[3]))\n",
    "        \n",
    "#         print(f'n_muls {n_muls} ops_per_mul {bitops_per_mul} totl {n_muls*bitops_per_mul}')\n",
    "#         print(f'n_accs {n_accs} ops_per_acc {bitops_per_acc} totl {n_accs*bitops_per_acc}')\n",
    "#         print()\n",
    "        \n",
    "        return n_muls * bitops_per_mul + n_accs * bitops_per_acc\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e0cbe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('layer1.0.conv1', '(8, 2)bits'),\n",
       " ('layer1.0.conv1', '(8, 4)bits'),\n",
       " ('layer1.0.conv1', '(8, 8)bits'),\n",
       " ('layer1.0.conv2', '(8, 2)bits'),\n",
       " ('layer1.0.conv2', '(8, 4)bits'),\n",
       " ('layer1.0.conv2', '(8, 8)bits'),\n",
       " ('layer1.0.conv3', '(8, 2)bits'),\n",
       " ('layer1.0.conv3', '(8, 4)bits'),\n",
       " ('layer1.0.conv3', '(8, 8)bits'),\n",
       " ('layer1.0.downsample.0', '(8, 2)bits'),\n",
       " ('layer1.0.downsample.0', '(8, 4)bits'),\n",
       " ('layer1.0.downsample.0', '(8, 8)bits'),\n",
       " ('layer1.1.conv1', '(8, 2)bits'),\n",
       " ('layer1.1.conv1', '(8, 4)bits'),\n",
       " ('layer1.1.conv1', '(8, 8)bits'),\n",
       " ('layer1.1.conv2', '(8, 2)bits'),\n",
       " ('layer1.1.conv2', '(8, 4)bits'),\n",
       " ('layer1.1.conv2', '(8, 8)bits'),\n",
       " ('layer1.1.conv3', '(8, 2)bits'),\n",
       " ('layer1.1.conv3', '(8, 4)bits'),\n",
       " ('layer1.1.conv3', '(8, 8)bits'),\n",
       " ('layer1.2.conv1', '(8, 2)bits'),\n",
       " ('layer1.2.conv1', '(8, 4)bits'),\n",
       " ('layer1.2.conv1', '(8, 8)bits'),\n",
       " ('layer1.2.conv2', '(8, 2)bits'),\n",
       " ('layer1.2.conv2', '(8, 4)bits'),\n",
       " ('layer1.2.conv2', '(8, 8)bits'),\n",
       " ('layer1.2.conv3', '(8, 2)bits'),\n",
       " ('layer1.2.conv3', '(8, 4)bits'),\n",
       " ('layer1.2.conv3', '(8, 8)bits'),\n",
       " ('layer2.0.conv1', '(8, 2)bits'),\n",
       " ('layer2.0.conv1', '(8, 4)bits'),\n",
       " ('layer2.0.conv1', '(8, 8)bits'),\n",
       " ('layer2.0.conv2', '(8, 2)bits'),\n",
       " ('layer2.0.conv2', '(8, 4)bits'),\n",
       " ('layer2.0.conv2', '(8, 8)bits'),\n",
       " ('layer2.0.conv3', '(8, 2)bits'),\n",
       " ('layer2.0.conv3', '(8, 4)bits'),\n",
       " ('layer2.0.conv3', '(8, 8)bits'),\n",
       " ('layer2.0.downsample.0', '(8, 2)bits'),\n",
       " ('layer2.0.downsample.0', '(8, 4)bits'),\n",
       " ('layer2.0.downsample.0', '(8, 8)bits'),\n",
       " ('layer2.1.conv1', '(8, 2)bits'),\n",
       " ('layer2.1.conv1', '(8, 4)bits'),\n",
       " ('layer2.1.conv1', '(8, 8)bits'),\n",
       " ('layer2.1.conv2', '(8, 2)bits'),\n",
       " ('layer2.1.conv2', '(8, 4)bits'),\n",
       " ('layer2.1.conv2', '(8, 8)bits'),\n",
       " ('layer2.1.conv3', '(8, 2)bits'),\n",
       " ('layer2.1.conv3', '(8, 4)bits'),\n",
       " ('layer2.1.conv3', '(8, 8)bits'),\n",
       " ('layer2.2.conv1', '(8, 2)bits'),\n",
       " ('layer2.2.conv1', '(8, 4)bits'),\n",
       " ('layer2.2.conv1', '(8, 8)bits'),\n",
       " ('layer2.2.conv2', '(8, 2)bits'),\n",
       " ('layer2.2.conv2', '(8, 4)bits'),\n",
       " ('layer2.2.conv2', '(8, 8)bits'),\n",
       " ('layer2.2.conv3', '(8, 2)bits'),\n",
       " ('layer2.2.conv3', '(8, 4)bits'),\n",
       " ('layer2.2.conv3', '(8, 8)bits'),\n",
       " ('layer2.3.conv1', '(8, 2)bits'),\n",
       " ('layer2.3.conv1', '(8, 4)bits'),\n",
       " ('layer2.3.conv1', '(8, 8)bits'),\n",
       " ('layer2.3.conv2', '(8, 2)bits'),\n",
       " ('layer2.3.conv2', '(8, 4)bits'),\n",
       " ('layer2.3.conv2', '(8, 8)bits'),\n",
       " ('layer2.3.conv3', '(8, 2)bits'),\n",
       " ('layer2.3.conv3', '(8, 4)bits'),\n",
       " ('layer2.3.conv3', '(8, 8)bits'),\n",
       " ('layer3.0.conv1', '(8, 2)bits'),\n",
       " ('layer3.0.conv1', '(8, 4)bits'),\n",
       " ('layer3.0.conv1', '(8, 8)bits'),\n",
       " ('layer3.0.conv2', '(8, 2)bits'),\n",
       " ('layer3.0.conv2', '(8, 4)bits'),\n",
       " ('layer3.0.conv2', '(8, 8)bits'),\n",
       " ('layer3.0.conv3', '(8, 2)bits'),\n",
       " ('layer3.0.conv3', '(8, 4)bits'),\n",
       " ('layer3.0.conv3', '(8, 8)bits'),\n",
       " ('layer3.0.downsample.0', '(8, 2)bits'),\n",
       " ('layer3.0.downsample.0', '(8, 4)bits'),\n",
       " ('layer3.0.downsample.0', '(8, 8)bits'),\n",
       " ('layer3.1.conv1', '(8, 2)bits'),\n",
       " ('layer3.1.conv1', '(8, 4)bits'),\n",
       " ('layer3.1.conv1', '(8, 8)bits'),\n",
       " ('layer3.1.conv2', '(8, 2)bits'),\n",
       " ('layer3.1.conv2', '(8, 4)bits'),\n",
       " ('layer3.1.conv2', '(8, 8)bits'),\n",
       " ('layer3.1.conv3', '(8, 2)bits'),\n",
       " ('layer3.1.conv3', '(8, 4)bits'),\n",
       " ('layer3.1.conv3', '(8, 8)bits'),\n",
       " ('layer3.2.conv1', '(8, 2)bits'),\n",
       " ('layer3.2.conv1', '(8, 4)bits'),\n",
       " ('layer3.2.conv1', '(8, 8)bits'),\n",
       " ('layer3.2.conv2', '(8, 2)bits'),\n",
       " ('layer3.2.conv2', '(8, 4)bits'),\n",
       " ('layer3.2.conv2', '(8, 8)bits'),\n",
       " ('layer3.2.conv3', '(8, 2)bits'),\n",
       " ('layer3.2.conv3', '(8, 4)bits'),\n",
       " ('layer3.2.conv3', '(8, 8)bits'),\n",
       " ('layer3.3.conv1', '(8, 2)bits'),\n",
       " ('layer3.3.conv1', '(8, 4)bits'),\n",
       " ('layer3.3.conv1', '(8, 8)bits'),\n",
       " ('layer3.3.conv2', '(8, 2)bits'),\n",
       " ('layer3.3.conv2', '(8, 4)bits'),\n",
       " ('layer3.3.conv2', '(8, 8)bits'),\n",
       " ('layer3.3.conv3', '(8, 2)bits'),\n",
       " ('layer3.3.conv3', '(8, 4)bits'),\n",
       " ('layer3.3.conv3', '(8, 8)bits'),\n",
       " ('layer3.4.conv1', '(8, 2)bits'),\n",
       " ('layer3.4.conv1', '(8, 4)bits'),\n",
       " ('layer3.4.conv1', '(8, 8)bits'),\n",
       " ('layer3.4.conv2', '(8, 2)bits'),\n",
       " ('layer3.4.conv2', '(8, 4)bits'),\n",
       " ('layer3.4.conv2', '(8, 8)bits'),\n",
       " ('layer3.4.conv3', '(8, 2)bits'),\n",
       " ('layer3.4.conv3', '(8, 4)bits'),\n",
       " ('layer3.4.conv3', '(8, 8)bits'),\n",
       " ('layer3.5.conv1', '(8, 2)bits'),\n",
       " ('layer3.5.conv1', '(8, 4)bits'),\n",
       " ('layer3.5.conv1', '(8, 8)bits'),\n",
       " ('layer3.5.conv2', '(8, 2)bits'),\n",
       " ('layer3.5.conv2', '(8, 4)bits'),\n",
       " ('layer3.5.conv2', '(8, 8)bits'),\n",
       " ('layer3.5.conv3', '(8, 2)bits'),\n",
       " ('layer3.5.conv3', '(8, 4)bits'),\n",
       " ('layer3.5.conv3', '(8, 8)bits'),\n",
       " ('layer4.0.conv1', '(8, 2)bits'),\n",
       " ('layer4.0.conv1', '(8, 4)bits'),\n",
       " ('layer4.0.conv1', '(8, 8)bits'),\n",
       " ('layer4.0.conv2', '(8, 2)bits'),\n",
       " ('layer4.0.conv2', '(8, 4)bits'),\n",
       " ('layer4.0.conv2', '(8, 8)bits'),\n",
       " ('layer4.0.conv3', '(8, 2)bits'),\n",
       " ('layer4.0.conv3', '(8, 4)bits'),\n",
       " ('layer4.0.conv3', '(8, 8)bits'),\n",
       " ('layer4.0.downsample.0', '(8, 2)bits'),\n",
       " ('layer4.0.downsample.0', '(8, 4)bits'),\n",
       " ('layer4.0.downsample.0', '(8, 8)bits'),\n",
       " ('layer4.1.conv1', '(8, 2)bits'),\n",
       " ('layer4.1.conv1', '(8, 4)bits'),\n",
       " ('layer4.1.conv1', '(8, 8)bits'),\n",
       " ('layer4.1.conv2', '(8, 2)bits'),\n",
       " ('layer4.1.conv2', '(8, 4)bits'),\n",
       " ('layer4.1.conv2', '(8, 8)bits'),\n",
       " ('layer4.1.conv3', '(8, 2)bits'),\n",
       " ('layer4.1.conv3', '(8, 4)bits'),\n",
       " ('layer4.1.conv3', '(8, 8)bits'),\n",
       " ('layer4.2.conv1', '(8, 2)bits'),\n",
       " ('layer4.2.conv1', '(8, 4)bits'),\n",
       " ('layer4.2.conv1', '(8, 8)bits'),\n",
       " ('layer4.2.conv2', '(8, 2)bits'),\n",
       " ('layer4.2.conv2', '(8, 4)bits'),\n",
       " ('layer4.2.conv2', '(8, 8)bits'),\n",
       " ('layer4.2.conv3', '(8, 2)bits'),\n",
       " ('layer4.2.conv3', '(8, 4)bits'),\n",
       " ('layer4.2.conv3', '(8, 8)bits')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2layerscheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db18b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = np.array([0 for i in range(L)])\n",
    "for l in hm['layer_index']:\n",
    "    index = hm['layer_index'][l]\n",
    "    layer_name, scheme = index2layerscheme[index]\n",
    "    scheme = eval(scheme[:-4])\n",
    "    layer_size[index] = torch.numel(getModuleByName(model,layer_name).weight) * int(scheme[1])\n",
    "\n",
    "layer_bitops = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4555d2",
   "metadata": {},
   "source": [
    "### Calculate sizes and numbers of bitoperations for layers under different quantization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5886f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = np.array([0 for i in range(L)])\n",
    "layer_bitops = np.array([0 for i in range(L)])\n",
    "for l in hm['layer_index']:\n",
    "    index = hm['layer_index'][l]\n",
    "    layer_name, scheme = index2layerscheme[index]\n",
    "    a_bits,w_bits = eval(scheme[:-4])\n",
    "    #print(layer_name,a_bits,w_bits)\n",
    "    layer_size[index] = torch.numel(getModuleByName(model,layer_name).weight) * int(w_bits)\n",
    "    layer_bitops[index] = get_layer_bitops(layer_name,a_bits,w_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79495d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_size # list[layer_index] = size of layer with layer_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "30e7a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_bitops # list[layer_index] = bitops of layer with layer_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97818b5",
   "metadata": {},
   "source": [
    "## Modify the quantization options for layers\n",
    "modify the aw_scheme to list of (a_bits,w_bits) so that CLADO will only consider to choose from these options.\n",
    "the corresponding cached_grad, layer_size, layer_bitops will also exclude quantization options that are not considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c17fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad_full = deepcopy(cached_grad)\n",
    "index2layerscheme_full = deepcopy(index2layerscheme)\n",
    "layer_size_full = deepcopy(layer_size)\n",
    "layer_bitops_full = deepcopy(layer_bitops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3de435fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPQ_scheme = (2,4,8)\n",
    "aw_scheme = []\n",
    "for a_bits in MPQ_scheme:\n",
    "    for w_bits in MPQ_scheme:\n",
    "        aw_scheme.append((a_bits,w_bits))\n",
    "\n",
    "#aw_scheme = [(4,8),(8,8),(8,4),(4,4)]\n",
    "aw_scheme = [(4,4),(4,8),(8,4),(8,8)]\n",
    "aw_scheme = [(8,2),(8,4),(8,8)]\n",
    "del_index = []\n",
    "for index in range(len(index2layerscheme_full)):\n",
    "    if eval(index2layerscheme_full[index][1][:-4]) not in aw_scheme:\n",
    "        del_index.append(index)\n",
    "        print(f'delete {index}: {index2layerscheme_full[index][1]}')\n",
    "\n",
    "cached_grad = np.delete(cached_grad_full,[del_index],axis=0)\n",
    "cached_grad = np.delete(cached_grad,[del_index],axis=1)\n",
    "index2layerscheme = np.delete(index2layerscheme_full,[del_index],axis=0)\n",
    "layer_size = np.delete(layer_size_full,[del_index],axis=0)\n",
    "layer_bitops = np.delete(layer_bitops_full,[del_index],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "156eb5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 2), (8, 4), (8, 8)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aw_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c7d9760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 156)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4bcd5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random variable v\n",
    "# use recitfied sigmoid h(v) to represent alpha\n",
    "# freg is 1-(1-2h(v))**beta, annealing beta to \n",
    "\n",
    "if not isinstance(cached_grad,torch.Tensor):\n",
    "    cached_grad = torch.Tensor(cached_grad)\n",
    "\n",
    "layer_size_tensor = torch.Tensor(layer_size)\n",
    "layer_bitops_tensor = torch.Tensor(layer_bitops)\n",
    "\n",
    "def lossfunc(v,beta,lambda1,lambda2,printInfo=False,naive=False,b=None):\n",
    "    \n",
    "    # alpha here is continuous\n",
    "    alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(aw_scheme))).reshape(-1,) # force equality constraint in eq.11\n",
    "    \n",
    "    if not naive:\n",
    "        outer_alpha = torch.outer(alpha,alpha)\n",
    "        netloss = torch.sum(outer_alpha * cached_grad)\n",
    "    else:\n",
    "        netloss = torch.sum(torch.diagonal(cached_grad) * alpha)\n",
    "        \n",
    "    model_size = torch.sum(layer_size_tensor * alpha)/8/1024/1024 # model size in MB\n",
    "    model_bitops = torch.sum(layer_bitops_tensor * alpha)/10**9\n",
    "            \n",
    "    regloss = torch.sum(1-(torch.abs(1-2*alpha))**beta)\n",
    "    regloss *= lambda1\n",
    "\n",
    "    if b is None:\n",
    "        closs = lambda2 * model_bitops\n",
    "    else:\n",
    "        closs = lambda2 * torch.clamp(model_bitops-b,0)\n",
    "    \n",
    "    totloss = netloss + regloss + closs\n",
    "    \n",
    "    if printInfo:\n",
    "        print(f'netloss {netloss.item():.4f} regloss {regloss.item():.4f}(beta={beta:.4f}) closs{closs.item():.4f}(bitops: {model_bitops.item():.2f}G constraint:{b})')\n",
    "        print(f'model size: {model_size.item():.4f}MB')\n",
    "        print('alpha:\\n',alpha)\n",
    "        \n",
    "    return totloss    \n",
    "    \n",
    "# for CVXPY\n",
    "# The problem is\n",
    "# minimize alpha Cached_grad alpha\n",
    "# subject to \n",
    "# alpha * layer_size <= size_constraint\n",
    "# alpha * layer_bitops <= bitops_constraint\n",
    "# alpha in the same layer summed up to 1\n",
    "# alpha is integer\n",
    "# 0 <= alpha <=1\n",
    "\n",
    "\n",
    "def CLADO_solver(cached_grad,size_bound,bitops_bound,options_per_layer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04760381",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = cached_grad.size()[0]\n",
    "def optimize(n_iteration,lr,beta,lambda1,lambda2,b=None,naive=False,hardInit=False):\n",
    "    \n",
    "    \n",
    "    #v = torch.nn.Parameter(torch.randn(L))\n",
    "    v = torch.nn.Parameter(torch.zeros(L))\n",
    "    if hardInit:\n",
    "        v = torch.nn.Parameter(torch.zeros(L))\n",
    "        with torch.no_grad():\n",
    "            for i in range(L):\n",
    "                if i % len(aw_scheme) == len(aw_scheme)-1:\n",
    "                    v[i].data += 1.\n",
    "                    \n",
    "    optim = torch.optim.Adam([v,],lr=lr)\n",
    "    bs = np.linspace(beta[0],beta[1],n_iteration)\n",
    "    \n",
    "    for i in range(n_iteration):\n",
    "        if i==0 or (i+1) % 1000 == 0:\n",
    "            printInfo = True\n",
    "            print(f'Iter {i+1}')\n",
    "        else:\n",
    "            printInfo = False\n",
    "            \n",
    "        optim.zero_grad()\n",
    "        loss = lossfunc(v,bs[i],lambda1,lambda2,printInfo=printInfo,b=b,naive=naive)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    return v\n",
    "\n",
    "def evaluate_decision(v,printInfo=False,test=test):\n",
    "    global mqb_mix_model\n",
    "    v = v.detach()\n",
    "    # alpha = torch.nn.Softmax(dim=1)(v.reshape(-1,len(MPQ_scheme)))\n",
    "    offset = torch.ones(int(L/len(aw_scheme)),dtype=int) * len(aw_scheme)\n",
    "    offset = offset.cumsum(dim=-1) - len(aw_scheme)\n",
    "    select = v.reshape(-1,len(aw_scheme)).argmax(dim=1) + offset\n",
    "    \n",
    "    modelsize = (layer_size[select]).sum()/8/1024/1024\n",
    "    bitops = (layer_bitops[select]).sum()/10**9\n",
    "    \n",
    "    decisions = {}\n",
    "    for scheme_id in select.numpy():\n",
    "        layer,scheme = index2layerscheme[scheme_id]\n",
    "        decisions[layer] = eval(scheme[:-4])\n",
    "    \n",
    "    print(\"evaluate_decision\\n\",decisions)\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # perturb layers\n",
    "        perturb(decisions)\n",
    "            \n",
    "        # do evaluation\n",
    "        res = evaluate(test,mqb_mix_model)\n",
    "        \n",
    "        # recover layers\n",
    "        mqb_mix_model = deepcopy(mqb_fp_model)\n",
    "    return res,modelsize,bitops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a23a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "\n",
    "def MIQCP_optimize(cached_grad,layer_bitops,layer_size,\n",
    "                   schemes_per_layer=3,\n",
    "                   bitops_bound=np.inf,size_bound=np.inf,\n",
    "                   naive=False):\n",
    "    \n",
    "    if cached_grad.__class__ == torch.Tensor:\n",
    "        cached_grad = cached_grad.cpu().numpy()\n",
    "    \n",
    "    x = cp.Variable(cached_grad.shape[0], boolean=True)\n",
    "    schemes_per_layer = schemes_per_layer\n",
    "    assert cached_grad.shape[0]%schemes_per_layer == 0, 'cached_gradient shape[0] does not divde schemes per layer'\n",
    "    num_layers = cached_grad.shape[0]//schemes_per_layer\n",
    "    \n",
    "    if not naive:\n",
    "        # convexation of cached_grad\n",
    "        es,us = np.linalg.eig(cached_grad)\n",
    "        es[es<0] = 0\n",
    "        C = us@np.diag(es)@us.T\n",
    "        C = (C+C.T)/2\n",
    "        C = cp.atoms.affine.wraps.psd_wrap(C)\n",
    "        objective = cp.Minimize(cp.quad_form(x,C))\n",
    "    else:\n",
    "        objective = cp.Minimize(np.diagonal(cached_grad)@x)\n",
    "\n",
    "    equality_constraint_matrix = []\n",
    "    for i in range(num_layers):\n",
    "        col = np.zeros(cached_grad.shape[0])\n",
    "        col[i*schemes_per_layer:(i+1)*schemes_per_layer] = 1\n",
    "        equality_constraint_matrix.append(col)\n",
    "\n",
    "    equality_constraint_matrix = np.array(equality_constraint_matrix)\n",
    "\n",
    "    constraints = [equality_constraint_matrix@x == np.ones((num_layers,)),\n",
    "                   layer_bitops@x/10**9<=bitops_bound,\n",
    "                   layer_size@x/8/1024/1024<=size_bound]\n",
    "\n",
    "    prob = cp.Problem(objective,constraints)\n",
    "    prob.solve(verbose=True)\n",
    "    \n",
    "    # Print result.\n",
    "    print(\"\\nThe optimal value is\", prob.value)\n",
    "    print(\"A solution x is\")\n",
    "    print(x.value)\n",
    "    #print(f\"bitops: {x.value@layer_bitops}\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b4939",
   "metadata": {},
   "source": [
    "## Sanity Check: no constraint optimization\n",
    "Without constraint, optimization should return (ideally) an 8-bit model, or performance close to 8-bit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa2f91e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1\n",
      "netloss 29.3711 regloss 0.0000(beta=20.0000) closs0.0000(bitops: 467.77G constraint:None)\n",
      "model size: 16.4358MB\n",
      "alpha:\n",
      " tensor([0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 1000\n",
      "netloss 1.6764 regloss 0.0000(beta=16.4029) closs0.0000(bitops: 540.43G constraint:None)\n",
      "model size: 19.6218MB\n",
      "alpha:\n",
      " tensor([0.0419, 0.2338, 0.7243, 0.0470, 0.0274, 0.9255, 0.0470, 0.1230, 0.8300,\n",
      "        0.0479, 0.0701, 0.8820, 0.0430, 0.2327, 0.7243, 0.0450, 0.1533, 0.8018,\n",
      "        0.0438, 0.2330, 0.7232, 0.0441, 0.3484, 0.6076, 0.0443, 0.2704, 0.6853,\n",
      "        0.0780, 0.8188, 0.1032, 0.0435, 0.2309, 0.7256, 0.0437, 0.2461, 0.7102,\n",
      "        0.0441, 0.1541, 0.8018, 0.0449, 0.1472, 0.8079, 0.0451, 0.1511, 0.8037,\n",
      "        0.0449, 0.1353, 0.8198, 0.0448, 0.1330, 0.8221, 0.0436, 0.1956, 0.7608,\n",
      "        0.0433, 0.2089, 0.7478, 0.0451, 0.1454, 0.8095, 0.0441, 0.2547, 0.7012,\n",
      "        0.0456, 0.2366, 0.7179, 0.0427, 0.1965, 0.7608, 0.0428, 0.1837, 0.7735,\n",
      "        0.0420, 0.2151, 0.7429, 0.0430, 0.2188, 0.7382, 0.0442, 0.1486, 0.8072,\n",
      "        0.0458, 0.2189, 0.7353, 0.0428, 0.2401, 0.7171, 0.0459, 0.0381, 0.9160,\n",
      "        0.0445, 0.2213, 0.7342, 0.0438, 0.2128, 0.7433, 0.0428, 0.2230, 0.7341,\n",
      "        0.0437, 0.2550, 0.7014, 0.0429, 0.2260, 0.7312, 0.0450, 0.1458, 0.8092,\n",
      "        0.0439, 0.3230, 0.6331, 0.0470, 0.1091, 0.8439, 0.0434, 0.2302, 0.7264,\n",
      "        0.0448, 0.1816, 0.7737, 0.0459, 0.1474, 0.8068, 0.0431, 0.1810, 0.7759,\n",
      "        0.0425, 0.1921, 0.7654, 0.0435, 0.1197, 0.8368, 0.0429, 0.1276, 0.8295,\n",
      "        0.0445, 0.1462, 0.8094, 0.0476, 0.0422, 0.9102, 0.0480, 0.2533, 0.6987,\n",
      "        0.0467, 0.0994, 0.8540, 0.0421, 0.1939, 0.7639, 0.0408, 0.2344, 0.7248,\n",
      "        0.0426, 0.2068, 0.7506], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 2000\n",
      "netloss 0.5174 regloss 0.0000(beta=12.8022) closs0.0000(bitops: 560.25G constraint:None)\n",
      "model size: 20.5130MB\n",
      "alpha:\n",
      " tensor([0.0209, 0.1774, 0.8017, 0.0240, 0.0117, 0.9643, 0.0257, 0.0578, 0.9165,\n",
      "        0.0256, 0.0288, 0.9456, 0.0220, 0.1952, 0.7828, 0.0233, 0.0810, 0.8957,\n",
      "        0.0235, 0.2192, 0.7574, 0.0214, 0.5627, 0.4159, 0.0237, 0.3075, 0.6688,\n",
      "        0.0515, 0.9000, 0.0485, 0.0230, 0.1665, 0.8105, 0.0235, 0.2152, 0.7613,\n",
      "        0.0231, 0.0778, 0.8991, 0.0240, 0.0721, 0.9039, 0.0241, 0.0781, 0.8978,\n",
      "        0.0233, 0.0631, 0.9135, 0.0235, 0.0612, 0.9154, 0.0236, 0.1326, 0.8438,\n",
      "        0.0235, 0.1506, 0.8259, 0.0242, 0.0721, 0.9037, 0.0246, 0.2754, 0.7000,\n",
      "        0.0268, 0.2089, 0.7643, 0.0225, 0.1285, 0.8490, 0.0224, 0.1149, 0.8627,\n",
      "        0.0220, 0.1559, 0.8221, 0.0231, 0.1771, 0.7998, 0.0229, 0.0715, 0.9056,\n",
      "        0.0272, 0.1680, 0.8048, 0.0231, 0.2158, 0.7611, 0.0233, 0.0151, 0.9616,\n",
      "        0.0244, 0.1748, 0.8008, 0.0235, 0.1555, 0.8210, 0.0228, 0.1691, 0.8080,\n",
      "        0.0239, 0.2540, 0.7221, 0.0226, 0.1807, 0.7967, 0.0244, 0.0786, 0.8971,\n",
      "        0.0230, 0.4920, 0.4850, 0.0257, 0.0470, 0.9273, 0.0236, 0.1974, 0.7791,\n",
      "        0.0243, 0.0998, 0.8760, 0.0246, 0.0701, 0.9054, 0.0223, 0.1002, 0.8775,\n",
      "        0.0221, 0.1163, 0.8616, 0.0219, 0.0514, 0.9267, 0.0214, 0.0538, 0.9249,\n",
      "        0.0230, 0.0809, 0.8961, 0.0254, 0.0213, 0.9533, 0.0291, 0.2516, 0.7193,\n",
      "        0.0249, 0.0430, 0.9321, 0.0218, 0.1203, 0.8579, 0.0205, 0.1903, 0.7892,\n",
      "        0.0222, 0.1386, 0.8392], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 3000\n",
      "netloss 0.2398 regloss 0.0000(beta=9.2014) closs0.0000(bitops: 569.50G constraint:None)\n",
      "model size: 20.9516MB\n",
      "alpha:\n",
      " tensor([0.0126, 0.1430, 0.8445, 0.0152, 0.0067, 0.9781, 0.0172, 0.0349, 0.9479,\n",
      "        0.0169, 0.0165, 0.9666, 0.0131, 0.1483, 0.8386, 0.0144, 0.0503, 0.9353,\n",
      "        0.0151, 0.2307, 0.7542, 0.0113, 0.7427, 0.2461, 0.0149, 0.3609, 0.6242,\n",
      "        0.0454, 0.9178, 0.0368, 0.0144, 0.1078, 0.8778, 0.0150, 0.1646, 0.8203,\n",
      "        0.0148, 0.0459, 0.9394, 0.0157, 0.0416, 0.9426, 0.0157, 0.0474, 0.9370,\n",
      "        0.0147, 0.0358, 0.9495, 0.0150, 0.0349, 0.9501, 0.0156, 0.0957, 0.8888,\n",
      "        0.0155, 0.1089, 0.8755, 0.0159, 0.0427, 0.9414, 0.0168, 0.3336, 0.6496,\n",
      "        0.0196, 0.1808, 0.7996, 0.0146, 0.0899, 0.8955, 0.0143, 0.0805, 0.9051,\n",
      "        0.0140, 0.1123, 0.8737, 0.0153, 0.1510, 0.8338, 0.0145, 0.0402, 0.9453,\n",
      "        0.0204, 0.1263, 0.8533, 0.0154, 0.1884, 0.7962, 0.0149, 0.0085, 0.9765,\n",
      "        0.0161, 0.1375, 0.8464, 0.0151, 0.1102, 0.8747, 0.0147, 0.1219, 0.8634,\n",
      "        0.0160, 0.2513, 0.7327, 0.0144, 0.1392, 0.8464, 0.0163, 0.0546, 0.9290,\n",
      "        0.0137, 0.6553, 0.3311, 0.0175, 0.0268, 0.9557, 0.0157, 0.1720, 0.8123,\n",
      "        0.0158, 0.0563, 0.9279, 0.0158, 0.0385, 0.9458, 0.0139, 0.0582, 0.9279,\n",
      "        0.0138, 0.0707, 0.9155, 0.0136, 0.0286, 0.9578, 0.0131, 0.0285, 0.9584,\n",
      "        0.0146, 0.0574, 0.9280, 0.0171, 0.0139, 0.9690, 0.0216, 0.2413, 0.7370,\n",
      "        0.0165, 0.0250, 0.9585, 0.0138, 0.0755, 0.9107, 0.0124, 0.1412, 0.8463,\n",
      "        0.0140, 0.0887, 0.8974], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 4000\n",
      "netloss 0.1366 regloss 0.0000(beta=5.6007) closs0.0000(bitops: 574.32G constraint:None)\n",
      "model size: 21.2167MB\n",
      "alpha:\n",
      " tensor([0.0082, 0.1304, 0.8614, 0.0104, 0.0043, 0.9853, 0.0127, 0.0241, 0.9632,\n",
      "        0.0123, 0.0107, 0.9770, 0.0081, 0.0990, 0.8929, 0.0096, 0.0351, 0.9553,\n",
      "        0.0102, 0.3024, 0.6874, 0.0065, 0.8360, 0.1576, 0.0098, 0.4454, 0.5448,\n",
      "        0.0436, 0.9206, 0.0359, 0.0096, 0.0687, 0.9218, 0.0100, 0.1123, 0.8777,\n",
      "        0.0103, 0.0299, 0.9598, 0.0113, 0.0266, 0.9622, 0.0111, 0.0319, 0.9570,\n",
      "        0.0101, 0.0226, 0.9673, 0.0105, 0.0224, 0.9671, 0.0111, 0.0748, 0.9141,\n",
      "        0.0111, 0.0814, 0.9075, 0.0114, 0.0282, 0.9604, 0.0121, 0.4537, 0.5342,\n",
      "        0.0161, 0.1572, 0.8268, 0.0103, 0.0697, 0.9200, 0.0100, 0.0638, 0.9262,\n",
      "        0.0097, 0.0842, 0.9061, 0.0111, 0.1434, 0.8456, 0.0099, 0.0250, 0.9650,\n",
      "        0.0175, 0.0969, 0.8855, 0.0111, 0.1632, 0.8256, 0.0105, 0.0055, 0.9841,\n",
      "        0.0114, 0.1116, 0.8770, 0.0104, 0.0782, 0.9114, 0.0101, 0.0877, 0.9022,\n",
      "        0.0116, 0.2509, 0.7375, 0.0097, 0.1066, 0.8836, 0.0121, 0.0464, 0.9415,\n",
      "        0.0090, 0.7436, 0.2474, 0.0132, 0.0174, 0.9693, 0.0114, 0.1595, 0.8290,\n",
      "        0.0112, 0.0337, 0.9551, 0.0109, 0.0231, 0.9660, 0.0094, 0.0360, 0.9546,\n",
      "        0.0094, 0.0447, 0.9459, 0.0092, 0.0181, 0.9728, 0.0088, 0.0171, 0.9741,\n",
      "        0.0101, 0.0485, 0.9414, 0.0127, 0.0101, 0.9773, 0.0176, 0.2284, 0.7540,\n",
      "        0.0120, 0.0165, 0.9714, 0.0095, 0.0497, 0.9408, 0.0080, 0.0994, 0.8926,\n",
      "        0.0094, 0.0569, 0.9337], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 5000\n",
      "netloss 0.0874 regloss 0.0000(beta=2.0000) closs0.0000(bitops: 576.22G constraint:None)\n",
      "model size: 21.3824MB\n",
      "alpha:\n",
      " tensor([0.0055, 0.1295, 0.8650, 0.0073, 0.0029, 0.9897, 0.0099, 0.0181, 0.9719,\n",
      "        0.0094, 0.0074, 0.9832, 0.0050, 0.0571, 0.9379, 0.0065, 0.0266, 0.9669,\n",
      "        0.0066, 0.4740, 0.5194, 0.0040, 0.8828, 0.1132, 0.0062, 0.5723, 0.4215,\n",
      "        0.0384, 0.9137, 0.0479, 0.0065, 0.0434, 0.9501, 0.0067, 0.0699, 0.9234,\n",
      "        0.0075, 0.0205, 0.9720, 0.0085, 0.0178, 0.9737, 0.0081, 0.0228, 0.9691,\n",
      "        0.0071, 0.0150, 0.9778, 0.0077, 0.0152, 0.9771, 0.0083, 0.0637, 0.9280,\n",
      "        0.0082, 0.0631, 0.9287, 0.0085, 0.0197, 0.9717, 0.0085, 0.6011, 0.3904,\n",
      "        0.0144, 0.1397, 0.8459, 0.0077, 0.0606, 0.9317, 0.0072, 0.0578, 0.9350,\n",
      "        0.0070, 0.0670, 0.9260, 0.0084, 0.1687, 0.8229, 0.0071, 0.0164, 0.9766,\n",
      "        0.0175, 0.0775, 0.9049, 0.0083, 0.1418, 0.8498, 0.0076, 0.0037, 0.9886,\n",
      "        0.0084, 0.0943, 0.8974, 0.0072, 0.0556, 0.9372, 0.0071, 0.0638, 0.9290,\n",
      "        0.0087, 0.2559, 0.7354, 0.0068, 0.0812, 0.9120, 0.0096, 0.0496, 0.9408,\n",
      "        0.0065, 0.7774, 0.2161, 0.0106, 0.0121, 0.9773, 0.0087, 0.1622, 0.8291,\n",
      "        0.0083, 0.0209, 0.9708, 0.0078, 0.0145, 0.9777, 0.0066, 0.0231, 0.9703,\n",
      "        0.0066, 0.0292, 0.9642, 0.0064, 0.0121, 0.9815, 0.0062, 0.0109, 0.9830,\n",
      "        0.0073, 0.0479, 0.9448, 0.0098, 0.0076, 0.9826, 0.0154, 0.2160, 0.7687,\n",
      "        0.0091, 0.0117, 0.9792, 0.0068, 0.0337, 0.9594, 0.0052, 0.0673, 0.9275,\n",
      "        0.0065, 0.0367, 0.9568], grad_fn=<ReshapeAliasBackward0>)\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 8), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 4), 'layer1.2.conv2': (8, 4), 'layer1.2.conv3': (8, 4), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 8), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 8), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 8), 'layer2.2.conv2': (8, 8), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 4), 'layer2.3.conv2': (8, 8), 'layer2.3.conv3': (8, 8), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 8), 'layer3.0.conv3': (8, 8), 'layer3.0.downsample.0': (8, 8), 'layer3.1.conv1': (8, 8), 'layer3.1.conv2': (8, 8), 'layer3.1.conv3': (8, 8), 'layer3.2.conv1': (8, 8), 'layer3.2.conv2': (8, 8), 'layer3.2.conv3': (8, 8), 'layer3.3.conv1': (8, 8), 'layer3.3.conv2': (8, 8), 'layer3.3.conv3': (8, 8), 'layer3.4.conv1': (8, 4), 'layer3.4.conv2': (8, 8), 'layer3.4.conv3': (8, 8), 'layer3.5.conv1': (8, 8), 'layer3.5.conv2': (8, 8), 'layer3.5.conv3': (8, 8), 'layer4.0.conv1': (8, 8), 'layer4.0.conv2': (8, 8), 'layer4.0.conv3': (8, 8), 'layer4.0.downsample.0': (8, 8), 'layer4.1.conv1': (8, 8), 'layer4.1.conv2': (8, 8), 'layer4.1.conv3': (8, 8), 'layer4.2.conv1': (8, 8), 'layer4.2.conv2': (8, 8), 'layer4.2.conv3': (8, 8)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([75.3121], device='cuda:0'),\n",
       "  'top5': tensor([92.4401], device='cuda:0'),\n",
       "  'loss': tensor(0.9867, device='cuda:0'),\n",
       "  'time': 146.34833240509033},\n",
       " 22.169921875,\n",
       " 588.924517888)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true: 1e-2 --> 1e-4\n",
    "# False 1e-1 --> 1e-3\n",
    "v = optimize(n_iteration=5000,lr=2e-3,beta=[20,2],\n",
    "             lambda1=0,lambda2=0,\n",
    "             naive=False,hardInit=True)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9556fe5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:14:23 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:14:23 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:14:23 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:14:23 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:14:23 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:14:23 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:14:23 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:14:24 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 11 04:14:24 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 11 04:14:24 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:14:24 AM: Finished problem compilation (took 1.282e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:14:24 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Restricted license - for non-production use only - expires 2023-10-25\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0x548dc069\n",
      "Model has 12246 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [5e-07, 1e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 60.1761468\n",
      "Presolve removed 2 rows and 0 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 52 rows, 156 columns, 156 nonzeros\n",
      "Presolved model has 12246 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Found heuristic solution: objective 1.0319005\n",
      "\n",
      "Root relaxation: objective 1.458668e-01, 300 iterations, 0.02 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       0.1824637    0.14587  20.1%     -    0s\n",
      "     0     0    0.14587    0   51    0.18246    0.14587  20.1%     -    0s\n",
      "     0     0    0.15120    0   41    0.18246    0.15120  17.1%     -    0s\n",
      "     0     0    0.15137    0   39    0.18246    0.15137  17.0%     -    0s\n",
      "     0     0    0.15138    0   36    0.18246    0.15138  17.0%     -    0s\n",
      "     0     0    0.15138    0   36    0.18246    0.15138  17.0%     -    0s\n",
      "H    0     0                       0.1806889    0.15138  16.2%     -    0s\n",
      "     0     0    0.15765    0   20    0.18069    0.15765  12.7%     -    0s\n",
      "     0     0    0.16458    0   19    0.18069    0.16458  8.91%     -    0s\n",
      "     0     0    0.16458    0   19    0.18069    0.16458  8.91%     -    0s\n",
      "     0     0    0.16458    0   15    0.18069    0.16458  8.91%     -    0s\n",
      "     0     0    0.16458    0   14    0.18069    0.16458  8.91%     -    0s\n",
      "     0     0    0.16458    0   14    0.18069    0.16458  8.91%     -    0s\n",
      "     0     2    0.16458    0   14    0.18069    0.16458  8.91%     -    0s\n",
      "\n",
      "Explored 53 nodes (610 simplex iterations) in 0.18 seconds (0.07 work units)\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 5: 0.180689 0.182464 0.438757 ... 60.1761\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.806888649465e-01, best bound 1.806888649465e-01, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:14:24 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:14:24 AM: Optimal value: 1.807e-01\n",
      "(CVXPY) Oct 11 04:14:24 AM: Compilation took 1.282e-02 seconds\n",
      "(CVXPY) Oct 11 04:14:24 AM: Solver (including time spent in interface) took 2.221e-01 seconds\n",
      "\n",
      "The optimal value is 0.18068886494654635\n",
      "A solution x is\n",
      "[-0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0.  1.  0. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0.  0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0.  1.  0. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0.  1.  0. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 4), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 8), 'layer1.2.conv2': (8, 8), 'layer1.2.conv3': (8, 8), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 8), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 8), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 8), 'layer2.2.conv2': (8, 8), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 8), 'layer2.3.conv2': (8, 8), 'layer2.3.conv3': (8, 8), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 8), 'layer3.0.conv3': (8, 8), 'layer3.0.downsample.0': (8, 8), 'layer3.1.conv1': (8, 8), 'layer3.1.conv2': (8, 8), 'layer3.1.conv3': (8, 8), 'layer3.2.conv1': (8, 8), 'layer3.2.conv2': (8, 4), 'layer3.2.conv3': (8, 8), 'layer3.3.conv1': (8, 8), 'layer3.3.conv2': (8, 8), 'layer3.3.conv3': (8, 8), 'layer3.4.conv1': (8, 4), 'layer3.4.conv2': (8, 8), 'layer3.4.conv3': (8, 8), 'layer3.5.conv1': (8, 8), 'layer3.5.conv2': (8, 8), 'layer3.5.conv3': (8, 8), 'layer4.0.conv1': (8, 8), 'layer4.0.conv2': (8, 8), 'layer4.0.conv3': (8, 8), 'layer4.0.downsample.0': (8, 8), 'layer4.1.conv1': (8, 8), 'layer4.1.conv2': (8, 8), 'layer4.1.conv3': (8, 8), 'layer4.2.conv1': (8, 8), 'layer4.2.conv2': (8, 8), 'layer4.2.conv3': (8, 8)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([75.6201], device='cuda:0'),\n",
       "  'top5': tensor([92.6540], device='cuda:0'),\n",
       "  'loss': tensor(0.9750, device='cuda:0'),\n",
       "  'time': 150.42189288139343},\n",
       " 21.9453125,\n",
       " 595.908013568)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=np.inf,\n",
    "                   naive=False)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0217953a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:16:54 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:16:54 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:16:54 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:16:54 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:16:54 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:16:54 AM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:16:54 AM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Oct 11 04:16:54 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:16:54 AM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Oct 11 04:16:54 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:16:54 AM: Finished problem compilation (took 2.094e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:16:54 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0xb0aff787\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [6e-07, 3e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 12.5884488\n",
      "Presolve removed 54 rows and 156 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 4 available processors)\n",
      "\n",
      "Solution count 2: 0.0461851 12.5884 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.618513584137e-02, best bound 4.618513584137e-02, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:16:54 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:16:54 AM: Optimal value: 4.619e-02\n",
      "(CVXPY) Oct 11 04:16:54 AM: Compilation took 2.094e-02 seconds\n",
      "(CVXPY) Oct 11 04:16:54 AM: Solver (including time spent in interface) took 1.101e-02 seconds\n",
      "\n",
      "The optimal value is 0.04618513584136963\n",
      "A solution x is\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 4), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 8), 'layer1.2.conv2': (8, 8), 'layer1.2.conv3': (8, 8), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 8), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 8), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 8), 'layer2.2.conv2': (8, 8), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 8), 'layer2.3.conv2': (8, 8), 'layer2.3.conv3': (8, 8), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 8), 'layer3.0.conv3': (8, 8), 'layer3.0.downsample.0': (8, 8), 'layer3.1.conv1': (8, 8), 'layer3.1.conv2': (8, 8), 'layer3.1.conv3': (8, 8), 'layer3.2.conv1': (8, 8), 'layer3.2.conv2': (8, 8), 'layer3.2.conv3': (8, 8), 'layer3.3.conv1': (8, 8), 'layer3.3.conv2': (8, 8), 'layer3.3.conv3': (8, 8), 'layer3.4.conv1': (8, 8), 'layer3.4.conv2': (8, 8), 'layer3.4.conv3': (8, 8), 'layer3.5.conv1': (8, 8), 'layer3.5.conv2': (8, 8), 'layer3.5.conv3': (8, 8), 'layer4.0.conv1': (8, 8), 'layer4.0.conv2': (8, 8), 'layer4.0.conv3': (8, 8), 'layer4.0.downsample.0': (8, 8), 'layer4.1.conv1': (8, 8), 'layer4.1.conv2': (8, 8), 'layer4.1.conv3': (8, 8), 'layer4.2.conv1': (8, 8), 'layer4.2.conv2': (8, 8), 'layer4.2.conv3': (8, 8)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([75.8641], device='cuda:0'),\n",
       "  'top5': tensor([92.8202], device='cuda:0'),\n",
       "  'loss': tensor(0.9633, device='cuda:0'),\n",
       "  'time': 152.55449628829956},\n",
       " 22.3515625,\n",
       " 607.262641664)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=np.inf,\n",
    "                   naive=True)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a85daf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:19:27 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:19:27 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:19:27 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:19:27 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:19:27 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:19:27 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:19:27 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:19:27 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 11 04:19:27 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 11 04:19:27 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:19:27 AM: Finished problem compilation (took 1.393e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:19:27 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0x58838e60\n",
      "Model has 12246 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [5e-07, 1e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Found heuristic solution: objective 137.6377723\n",
      "Presolve removed 1 rows and 0 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 53 rows, 156 columns, 261 nonzeros\n",
      "Presolved model has 12246 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Found heuristic solution: objective 87.3485522\n",
      "\n",
      "Root relaxation: objective 3.214769e+00, 405 iterations, 0.02 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       6.0625735    3.21477  47.0%     -    0s\n",
      "     0     0    3.21477    0   22    6.06257    3.21477  47.0%     -    0s\n",
      "H    0     0                       5.6916790    3.21477  43.5%     -    0s\n",
      "H    0     0                       3.6096561    3.21477  10.9%     -    0s\n",
      "     0     0    3.27682    0   28    3.60966    3.27682  9.22%     -    0s\n",
      "     0     0    3.27682    0   14    3.60966    3.27682  9.22%     -    0s\n",
      "     0     0    3.42748    0   20    3.60966    3.42748  5.05%     -    0s\n",
      "     0     0    3.57574    0   20    3.60966    3.57574  0.94%     -    0s\n",
      "     0     0    3.58688    0   20    3.60966    3.58688  0.63%     -    0s\n",
      "     0     0    3.59482    0   22    3.60966    3.59482  0.41%     -    0s\n",
      "     0     0    3.60150    0   23    3.60966    3.60150  0.23%     -    0s\n",
      "     0     0    3.60247    0   21    3.60966    3.60247  0.20%     -    0s\n",
      "     0     0    3.60247    0   15    3.60966    3.60247  0.20%     -    0s\n",
      "     0     0    3.60247    0   15    3.60966    3.60247  0.20%     -    0s\n",
      "     0     0    3.60247    0    8    3.60966    3.60247  0.20%     -    0s\n",
      "     0     0    3.60247    0   10    3.60966    3.60247  0.20%     -    0s\n",
      "     0     0    3.60966    0   10    3.60966    3.60966  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 1\n",
      "  RLT: 1\n",
      "\n",
      "Explored 1 nodes (557 simplex iterations) in 0.20 seconds (0.05 work units)\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 7: 3.60966 4.56205 4.90321 ... 137.638\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.609656052555e+00, best bound 3.609656052555e+00, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:19:27 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:19:27 AM: Optimal value: 3.610e+00\n",
      "(CVXPY) Oct 11 04:19:27 AM: Compilation took 1.393e-02 seconds\n",
      "(CVXPY) Oct 11 04:19:27 AM: Solver (including time spent in interface) took 2.187e-01 seconds\n",
      "\n",
      "The optimal value is 3.6096560525554082\n",
      "A solution x is\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 8), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 4), 'layer1.2.conv2': (8, 4), 'layer1.2.conv3': (8, 4), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 4), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 4), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 4), 'layer2.2.conv2': (8, 4), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 4), 'layer2.3.conv2': (8, 4), 'layer2.3.conv3': (8, 4), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 4), 'layer3.0.conv3': (8, 4), 'layer3.0.downsample.0': (8, 4), 'layer3.1.conv1': (8, 4), 'layer3.1.conv2': (8, 4), 'layer3.1.conv3': (8, 4), 'layer3.2.conv1': (8, 4), 'layer3.2.conv2': (8, 4), 'layer3.2.conv3': (8, 4), 'layer3.3.conv1': (8, 4), 'layer3.3.conv2': (8, 4), 'layer3.3.conv3': (8, 4), 'layer3.4.conv1': (8, 4), 'layer3.4.conv2': (8, 4), 'layer3.4.conv3': (8, 4), 'layer3.5.conv1': (8, 4), 'layer3.5.conv2': (8, 4), 'layer3.5.conv3': (8, 4), 'layer4.0.conv1': (8, 4), 'layer4.0.conv2': (8, 4), 'layer4.0.conv3': (8, 4), 'layer4.0.downsample.0': (8, 2), 'layer4.1.conv1': (8, 2), 'layer4.1.conv2': (8, 2), 'layer4.1.conv3': (8, 2), 'layer4.2.conv1': (8, 4), 'layer4.2.conv2': (8, 4), 'layer4.2.conv3': (8, 4)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([59.9241], device='cuda:0'),\n",
       "  'top5': tensor([83.0421], device='cuda:0'),\n",
       "  'loss': tensor(1.7640, device='cuda:0'),\n",
       "  'time': 151.79503417015076},\n",
       " 9.990234375,\n",
       " 399.83385344)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=10,\n",
    "                   naive=False)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcdb0f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:21:59 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:21:59 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:21:59 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:21:59 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:21:59 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:21:59 AM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:21:59 AM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Oct 11 04:21:59 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:21:59 AM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Oct 11 04:21:59 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:21:59 AM: Finished problem compilation (took 9.002e-03 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:21:59 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0x86c12b47\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [6e-07, 3e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Found heuristic solution: objective 21.1316271\n",
      "Presolve removed 2 rows and 52 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 52 rows, 104 columns, 207 nonzeros\n",
      "Found heuristic solution: objective 4.7035114\n",
      "Variable types: 0 continuous, 104 integer (104 binary)\n",
      "Found heuristic solution: objective 2.7756770\n",
      "\n",
      "Root relaxation: objective 1.332470e+00, 12 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.33247    0    1    2.77568    1.33247  52.0%     -    0s\n",
      "H    0     0                       1.7719706    1.33247  24.8%     -    0s\n",
      "H    0     0                       1.4590306    1.33247  8.67%     -    0s\n",
      "H    0     0                       1.3620657    1.33247  2.17%     -    0s\n",
      "     0     0    1.34574    0    3    1.36207    1.34574  1.20%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "\n",
      "Explored 1 nodes (17 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 6: 1.36207 1.45903 1.77197 ... 21.1316\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.362065672874e+00, best bound 1.362065672874e+00, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:21:59 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:21:59 AM: Optimal value: 1.362e+00\n",
      "(CVXPY) Oct 11 04:21:59 AM: Compilation took 9.002e-03 seconds\n",
      "(CVXPY) Oct 11 04:21:59 AM: Solver (including time spent in interface) took 3.307e-02 seconds\n",
      "\n",
      "The optimal value is 1.3620656728744507\n",
      "A solution x is\n",
      "[-0. -0.  1.  0. -0.  1.  0. -0.  1.  0. -0.  1.  0.  1.  0.  0.  1. -0.\n",
      "  0. -0.  1.  0.  1.  0.  0.  1. -0.  0. -0.  1.  0. -0.  1.  0.  1. -0.\n",
      "  0. -0.  1.  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.\n",
      "  0.  1. -0.  0. -0.  1.  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.\n",
      "  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.\n",
      "  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.\n",
      "  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.\n",
      "  0.  1. -0.  1. -0. -0.  0.  1. -0.  1. -0. -0.  1. -0. -0.  0.  1. -0.\n",
      "  0.  1. -0.  0.  1. -0.  0.  1. -0.  0.  1. -0.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 4), 'layer1.1.conv2': (8, 4), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 4), 'layer1.2.conv2': (8, 4), 'layer1.2.conv3': (8, 8), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 4), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 4), 'layer2.1.conv1': (8, 4), 'layer2.1.conv2': (8, 4), 'layer2.1.conv3': (8, 4), 'layer2.2.conv1': (8, 4), 'layer2.2.conv2': (8, 4), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 4), 'layer2.3.conv2': (8, 4), 'layer2.3.conv3': (8, 4), 'layer3.0.conv1': (8, 4), 'layer3.0.conv2': (8, 4), 'layer3.0.conv3': (8, 4), 'layer3.0.downsample.0': (8, 4), 'layer3.1.conv1': (8, 4), 'layer3.1.conv2': (8, 4), 'layer3.1.conv3': (8, 4), 'layer3.2.conv1': (8, 4), 'layer3.2.conv2': (8, 4), 'layer3.2.conv3': (8, 4), 'layer3.3.conv1': (8, 4), 'layer3.3.conv2': (8, 4), 'layer3.3.conv3': (8, 4), 'layer3.4.conv1': (8, 4), 'layer3.4.conv2': (8, 4), 'layer3.4.conv3': (8, 4), 'layer3.5.conv1': (8, 4), 'layer3.5.conv2': (8, 4), 'layer3.5.conv3': (8, 4), 'layer4.0.conv1': (8, 4), 'layer4.0.conv2': (8, 2), 'layer4.0.conv3': (8, 4), 'layer4.0.downsample.0': (8, 2), 'layer4.1.conv1': (8, 2), 'layer4.1.conv2': (8, 4), 'layer4.1.conv3': (8, 4), 'layer4.2.conv1': (8, 4), 'layer4.2.conv2': (8, 4), 'layer4.2.conv3': (8, 4)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([45.3600], device='cuda:0'),\n",
       "  'top5': tensor([70.3721], device='cuda:0'),\n",
       "  'loss': tensor(2.7799, device='cuda:0'),\n",
       "  'time': 151.86090731620789},\n",
       " 9.99609375,\n",
       " 368.391765504)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=10,\n",
    "                   naive=True)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66dbcc5",
   "metadata": {},
   "source": [
    "## KL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2610781e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1\n",
      "netloss 29.2334 regloss 0.0000(beta=20.0000) closs0.0000(bitops: 467.77G constraint:None)\n",
      "model size: 16.4358MB\n",
      "alpha:\n",
      " tensor([0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761, 0.2119, 0.2119, 0.5761,\n",
      "        0.2119, 0.2119, 0.5761], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 1000\n",
      "netloss 1.7087 regloss 0.0000(beta=16.4029) closs0.0000(bitops: 543.13G constraint:None)\n",
      "model size: 19.6530MB\n",
      "alpha:\n",
      " tensor([0.0438, 0.2017, 0.7546, 0.0476, 0.0297, 0.9226, 0.0464, 0.1395, 0.8141,\n",
      "        0.0484, 0.0495, 0.9021, 0.0435, 0.2779, 0.6786, 0.0453, 0.1692, 0.7855,\n",
      "        0.0447, 0.2220, 0.7333, 0.0446, 0.3056, 0.6498, 0.0451, 0.2675, 0.6874,\n",
      "        0.0487, 0.2461, 0.7051, 0.0435, 0.2317, 0.7248, 0.0443, 0.2453, 0.7105,\n",
      "        0.0440, 0.1630, 0.7930, 0.0444, 0.1472, 0.8085, 0.0451, 0.1314, 0.8236,\n",
      "        0.0452, 0.1253, 0.8296, 0.0448, 0.1330, 0.8221, 0.0438, 0.1832, 0.7730,\n",
      "        0.0429, 0.2119, 0.7452, 0.0447, 0.1423, 0.8130, 0.0440, 0.2185, 0.7374,\n",
      "        0.0447, 0.2302, 0.7251, 0.0425, 0.1739, 0.7835, 0.0430, 0.1817, 0.7753,\n",
      "        0.0421, 0.1874, 0.7704, 0.0425, 0.2391, 0.7183, 0.0438, 0.1703, 0.7859,\n",
      "        0.0453, 0.2251, 0.7296, 0.0427, 0.2392, 0.7181, 0.0458, 0.0430, 0.9112,\n",
      "        0.0443, 0.2180, 0.7377, 0.0438, 0.2097, 0.7465, 0.0434, 0.1682, 0.7884,\n",
      "        0.0430, 0.2304, 0.7267, 0.0432, 0.2044, 0.7525, 0.0442, 0.1089, 0.8469,\n",
      "        0.0438, 0.2653, 0.6909, 0.0460, 0.1338, 0.8203, 0.0431, 0.1850, 0.7719,\n",
      "        0.0432, 0.2079, 0.7488, 0.0448, 0.1959, 0.7594, 0.0434, 0.1951, 0.7615,\n",
      "        0.0423, 0.2230, 0.7348, 0.0436, 0.1311, 0.8253, 0.0425, 0.1580, 0.7995,\n",
      "        0.0453, 0.1126, 0.8421, 0.0478, 0.0432, 0.9090, 0.0475, 0.2632, 0.6893,\n",
      "        0.0471, 0.0645, 0.8883, 0.0419, 0.1927, 0.7654, 0.0408, 0.2257, 0.7336,\n",
      "        0.0425, 0.2078, 0.7497], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 2000\n",
      "netloss 0.5505 regloss 0.0000(beta=12.8022) closs0.0000(bitops: 565.37G constraint:None)\n",
      "model size: 20.5712MB\n",
      "alpha:\n",
      " tensor([0.0228, 0.1426, 0.8346, 0.0245, 0.0132, 0.9623, 0.0251, 0.0685, 0.9064,\n",
      "        0.0259, 0.0204, 0.9537, 0.0229, 0.3133, 0.6638, 0.0240, 0.0939, 0.8822,\n",
      "        0.0243, 0.1714, 0.8043, 0.0232, 0.4070, 0.5698, 0.0246, 0.2889, 0.6865,\n",
      "        0.0223, 0.1137, 0.8640, 0.0233, 0.1811, 0.7955, 0.0241, 0.2189, 0.7570,\n",
      "        0.0232, 0.0871, 0.8896, 0.0233, 0.0723, 0.9045, 0.0235, 0.0599, 0.9166,\n",
      "        0.0234, 0.0561, 0.9205, 0.0233, 0.0601, 0.9166, 0.0235, 0.1126, 0.8640,\n",
      "        0.0230, 0.1532, 0.8238, 0.0236, 0.0697, 0.9066, 0.0240, 0.1631, 0.8129,\n",
      "        0.0253, 0.1914, 0.7833, 0.0219, 0.0929, 0.8852, 0.0226, 0.1085, 0.8689,\n",
      "        0.0217, 0.1101, 0.8682, 0.0226, 0.2081, 0.7693, 0.0228, 0.0926, 0.8846,\n",
      "        0.0263, 0.1804, 0.7933, 0.0228, 0.2095, 0.7677, 0.0231, 0.0167, 0.9602,\n",
      "        0.0240, 0.1663, 0.8097, 0.0234, 0.1489, 0.8278, 0.0226, 0.0905, 0.8869,\n",
      "        0.0228, 0.1839, 0.7932, 0.0227, 0.1365, 0.8408, 0.0226, 0.0465, 0.9309,\n",
      "        0.0238, 0.2829, 0.6933, 0.0248, 0.0620, 0.9133, 0.0227, 0.1182, 0.8591,\n",
      "        0.0227, 0.1335, 0.8439, 0.0242, 0.1218, 0.8541, 0.0229, 0.1146, 0.8626,\n",
      "        0.0221, 0.1719, 0.8060, 0.0221, 0.0615, 0.9164, 0.0213, 0.0770, 0.9016,\n",
      "        0.0232, 0.0504, 0.9263, 0.0257, 0.0220, 0.9523, 0.0283, 0.2884, 0.6833,\n",
      "        0.0246, 0.0256, 0.9498, 0.0212, 0.1137, 0.8650, 0.0202, 0.1693, 0.8104,\n",
      "        0.0220, 0.1400, 0.8380], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 3000\n",
      "netloss 0.2672 regloss 0.0000(beta=9.2014) closs0.0000(bitops: 576.86G constraint:None)\n",
      "model size: 21.0231MB\n",
      "alpha:\n",
      " tensor([0.0143, 0.1153, 0.8704, 0.0157, 0.0078, 0.9765, 0.0165, 0.0408, 0.9428,\n",
      "        0.0173, 0.0119, 0.9708, 0.0145, 0.3234, 0.6621, 0.0151, 0.0570, 0.9279,\n",
      "        0.0157, 0.1258, 0.8584, 0.0140, 0.5079, 0.4780, 0.0160, 0.3009, 0.6831,\n",
      "        0.0108, 0.0424, 0.9468, 0.0151, 0.1307, 0.8542, 0.0157, 0.1770, 0.8073,\n",
      "        0.0150, 0.0532, 0.9318, 0.0149, 0.0418, 0.9433, 0.0149, 0.0337, 0.9514,\n",
      "        0.0149, 0.0315, 0.9536, 0.0148, 0.0334, 0.9518, 0.0152, 0.0735, 0.9113,\n",
      "        0.0150, 0.1083, 0.8768, 0.0152, 0.0410, 0.9438, 0.0158, 0.1166, 0.8677,\n",
      "        0.0173, 0.1528, 0.8299, 0.0138, 0.0548, 0.9314, 0.0145, 0.0706, 0.9149,\n",
      "        0.0135, 0.0675, 0.9190, 0.0146, 0.1711, 0.8143, 0.0143, 0.0548, 0.9309,\n",
      "        0.0190, 0.1390, 0.8421, 0.0149, 0.1727, 0.8125, 0.0146, 0.0093, 0.9761,\n",
      "        0.0156, 0.1242, 0.8602, 0.0150, 0.1024, 0.8826, 0.0143, 0.0538, 0.9320,\n",
      "        0.0147, 0.1388, 0.8465, 0.0143, 0.0894, 0.8963, 0.0144, 0.0268, 0.9588,\n",
      "        0.0158, 0.2912, 0.6930, 0.0163, 0.0350, 0.9487, 0.0146, 0.0828, 0.9027,\n",
      "        0.0141, 0.0803, 0.9056, 0.0154, 0.0741, 0.9104, 0.0145, 0.0673, 0.9182,\n",
      "        0.0140, 0.1275, 0.8584, 0.0137, 0.0365, 0.9498, 0.0130, 0.0425, 0.9444,\n",
      "        0.0147, 0.0300, 0.9553, 0.0174, 0.0145, 0.9681, 0.0203, 0.3157, 0.6640,\n",
      "        0.0160, 0.0143, 0.9697, 0.0129, 0.0673, 0.9198, 0.0120, 0.1151, 0.8730,\n",
      "        0.0136, 0.0899, 0.8964], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 4000\n",
      "netloss 0.1602 regloss 0.0000(beta=5.6007) closs0.0000(bitops: 584.10G constraint:None)\n",
      "model size: 21.2910MB\n",
      "alpha:\n",
      " tensor([0.0096, 0.1094, 0.8810, 0.0109, 0.0052, 0.9839, 0.0118, 0.0272, 0.9610,\n",
      "        0.0127, 0.0079, 0.9794, 0.0098, 0.2911, 0.6991, 0.0103, 0.0377, 0.9521,\n",
      "        0.0109, 0.0924, 0.8967, 0.0092, 0.5686, 0.4222, 0.0112, 0.2979, 0.6909,\n",
      "        0.0059, 0.0182, 0.9759, 0.0106, 0.0930, 0.8964, 0.0109, 0.1320, 0.8571,\n",
      "        0.0106, 0.0359, 0.9535, 0.0104, 0.0268, 0.9628, 0.0103, 0.0212, 0.9685,\n",
      "        0.0103, 0.0199, 0.9698, 0.0103, 0.0209, 0.9689, 0.0107, 0.0512, 0.9381,\n",
      "        0.0105, 0.0771, 0.9124, 0.0107, 0.0269, 0.9624, 0.0112, 0.0838, 0.9050,\n",
      "        0.0128, 0.1201, 0.8671, 0.0095, 0.0353, 0.9551, 0.0101, 0.0499, 0.9400,\n",
      "        0.0092, 0.0439, 0.9469, 0.0102, 0.1366, 0.8532, 0.0097, 0.0352, 0.9551,\n",
      "        0.0152, 0.1064, 0.8784, 0.0104, 0.1358, 0.8538, 0.0101, 0.0059, 0.9840,\n",
      "        0.0109, 0.0941, 0.8950, 0.0103, 0.0709, 0.9188, 0.0098, 0.0347, 0.9555,\n",
      "        0.0101, 0.1028, 0.8871, 0.0098, 0.0598, 0.9304, 0.0100, 0.0178, 0.9722,\n",
      "        0.0113, 0.2832, 0.7055, 0.0117, 0.0222, 0.9661, 0.0102, 0.0638, 0.9260,\n",
      "        0.0094, 0.0486, 0.9420, 0.0105, 0.0463, 0.9431, 0.0099, 0.0413, 0.9488,\n",
      "        0.0096, 0.0947, 0.8957, 0.0092, 0.0247, 0.9661, 0.0086, 0.0258, 0.9656,\n",
      "        0.0101, 0.0206, 0.9693, 0.0132, 0.0106, 0.9762, 0.0159, 0.3366, 0.6476,\n",
      "        0.0113, 0.0092, 0.9795, 0.0085, 0.0417, 0.9499, 0.0075, 0.0747, 0.9178,\n",
      "        0.0090, 0.0580, 0.9330], grad_fn=<ReshapeAliasBackward0>)\n",
      "Iter 5000\n",
      "netloss 0.1104 regloss 0.0000(beta=2.0000) closs0.0000(bitops: 589.44G constraint:None)\n",
      "model size: 21.4736MB\n",
      "alpha:\n",
      " tensor([0.0067, 0.1130, 0.8803, 0.0079, 0.0036, 0.9885, 0.0088, 0.0194, 0.9718,\n",
      "        0.0099, 0.0056, 0.9845, 0.0067, 0.2300, 0.7633, 0.0072, 0.0263, 0.9664,\n",
      "        0.0078, 0.0697, 0.9225, 0.0065, 0.5675, 0.4260, 0.0081, 0.2765, 0.7153,\n",
      "        0.0035, 0.0092, 0.9873, 0.0077, 0.0668, 0.9256, 0.0078, 0.0933, 0.8989,\n",
      "        0.0079, 0.0257, 0.9664, 0.0075, 0.0181, 0.9743, 0.0074, 0.0141, 0.9784,\n",
      "        0.0075, 0.0134, 0.9792, 0.0074, 0.0138, 0.9788, 0.0078, 0.0373, 0.9549,\n",
      "        0.0076, 0.0553, 0.9372, 0.0078, 0.0187, 0.9735, 0.0082, 0.0618, 0.9300,\n",
      "        0.0098, 0.0939, 0.8963, 0.0069, 0.0240, 0.9691, 0.0074, 0.0371, 0.9555,\n",
      "        0.0064, 0.0297, 0.9639, 0.0073, 0.1073, 0.8854, 0.0069, 0.0237, 0.9694,\n",
      "        0.0132, 0.0823, 0.9045, 0.0075, 0.1024, 0.8901, 0.0073, 0.0039, 0.9888,\n",
      "        0.0079, 0.0728, 0.9193, 0.0073, 0.0495, 0.9432, 0.0070, 0.0235, 0.9696,\n",
      "        0.0072, 0.0758, 0.9170, 0.0069, 0.0410, 0.9522, 0.0073, 0.0126, 0.9801,\n",
      "        0.0084, 0.2580, 0.7336, 0.0089, 0.0149, 0.9763, 0.0074, 0.0540, 0.9385,\n",
      "        0.0065, 0.0299, 0.9637, 0.0074, 0.0296, 0.9629, 0.0071, 0.0261, 0.9668,\n",
      "        0.0067, 0.0711, 0.9222, 0.0065, 0.0181, 0.9755, 0.0059, 0.0164, 0.9777,\n",
      "        0.0073, 0.0153, 0.9774, 0.0106, 0.0083, 0.9811, 0.0132, 0.3442, 0.6427,\n",
      "        0.0083, 0.0062, 0.9854, 0.0057, 0.0267, 0.9676, 0.0048, 0.0475, 0.9477,\n",
      "        0.0062, 0.0377, 0.9561], grad_fn=<ReshapeAliasBackward0>)\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 8), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 4), 'layer1.2.conv2': (8, 8), 'layer1.2.conv3': (8, 8), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 8), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 8), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 8), 'layer2.2.conv2': (8, 8), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 8), 'layer2.3.conv2': (8, 8), 'layer2.3.conv3': (8, 8), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 8), 'layer3.0.conv3': (8, 8), 'layer3.0.downsample.0': (8, 8), 'layer3.1.conv1': (8, 8), 'layer3.1.conv2': (8, 8), 'layer3.1.conv3': (8, 8), 'layer3.2.conv1': (8, 8), 'layer3.2.conv2': (8, 8), 'layer3.2.conv3': (8, 8), 'layer3.3.conv1': (8, 8), 'layer3.3.conv2': (8, 8), 'layer3.3.conv3': (8, 8), 'layer3.4.conv1': (8, 8), 'layer3.4.conv2': (8, 8), 'layer3.4.conv3': (8, 8), 'layer3.5.conv1': (8, 8), 'layer3.5.conv2': (8, 8), 'layer3.5.conv3': (8, 8), 'layer4.0.conv1': (8, 8), 'layer4.0.conv2': (8, 8), 'layer4.0.conv3': (8, 8), 'layer4.0.downsample.0': (8, 8), 'layer4.1.conv1': (8, 8), 'layer4.1.conv2': (8, 8), 'layer4.1.conv3': (8, 8), 'layer4.2.conv1': (8, 8), 'layer4.2.conv2': (8, 8), 'layer4.2.conv3': (8, 8)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([75.8740], device='cuda:0'),\n",
       "  'top5': tensor([92.7803], device='cuda:0'),\n",
       "  'loss': tensor(0.9629, device='cuda:0'),\n",
       "  'time': 147.7948613166809},\n",
       " 22.3515625,\n",
       " 607.262641664)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true: 1e-2 --> 1e-4\n",
    "# False 1e-1 --> 1e-3\n",
    "v = optimize(n_iteration=5000,lr=2e-3,beta=[20,2],\n",
    "             lambda1=0,lambda2=0,\n",
    "             naive=False,hardInit=True)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dbef5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "\n",
    "def MIQCP_optimize(cached_grad,layer_bitops,layer_size,\n",
    "                   schemes_per_layer=3,\n",
    "                   bitops_bound=np.inf,size_bound=np.inf,\n",
    "                   naive=False):\n",
    "    \n",
    "    if cached_grad.__class__ == torch.Tensor:\n",
    "        cached_grad = cached_grad.cpu().numpy()\n",
    "    \n",
    "    x = cp.Variable(cached_grad.shape[0], boolean=True)\n",
    "    schemes_per_layer = schemes_per_layer\n",
    "    assert cached_grad.shape[0]%schemes_per_layer == 0, 'cached_gradient shape[0] does not divde schemes per layer'\n",
    "    num_layers = cached_grad.shape[0]//schemes_per_layer\n",
    "    \n",
    "    if not naive:\n",
    "        # convexation of cached_grad\n",
    "        es,us = np.linalg.eig(cached_grad)\n",
    "        es[es<0] = 0\n",
    "        C = us@np.diag(es)@us.T\n",
    "        C = (C+C.T)/2\n",
    "        C = cp.atoms.affine.wraps.psd_wrap(C)\n",
    "        objective = cp.Minimize(cp.quad_form(x,C))\n",
    "    else:\n",
    "        objective = cp.Minimize(np.diagonal(cached_grad)@x)\n",
    "\n",
    "    equality_constraint_matrix = []\n",
    "    for i in range(num_layers):\n",
    "        col = np.zeros(cached_grad.shape[0])\n",
    "        col[i*schemes_per_layer:(i+1)*schemes_per_layer] = 1\n",
    "        equality_constraint_matrix.append(col)\n",
    "\n",
    "    equality_constraint_matrix = np.array(equality_constraint_matrix)\n",
    "\n",
    "    constraints = [equality_constraint_matrix@x == np.ones((num_layers,)),\n",
    "                   layer_bitops@x/10**9<=bitops_bound,\n",
    "                   layer_size@x/8/1024/1024<=size_bound]\n",
    "\n",
    "    prob = cp.Problem(objective,constraints)\n",
    "    prob.solve(verbose=True,solver='GUROBI',TimeLimit=30)\n",
    "    \n",
    "    # Print result.\n",
    "    print(\"\\nThe optimal value is\", prob.value)\n",
    "    print(\"A solution x is\")\n",
    "    print(x.value)\n",
    "    #print(f\"bitops: {x.value@layer_bitops}\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8d70554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:30:02 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:30:02 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:30:02 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:30:02 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:30:02 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:30:02 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:30:02 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:30:02 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 11 04:30:02 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 11 04:30:02 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:30:02 AM: Finished problem compilation (took 1.151e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:30:02 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Set parameter QCPDual to value 1\n",
      "Set parameter TimeLimit to value 30\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0x2c4ca1cd\n",
      "Model has 12246 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [1e-07, 1e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 59.6757823\n",
      "Presolve removed 2 rows and 0 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 52 rows, 156 columns, 156 nonzeros\n",
      "Presolved model has 12246 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Found heuristic solution: objective 1.0413428\n",
      "\n",
      "Root relaxation: objective 8.011059e-02, 222 iterations, 0.01 seconds (0.01 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.08011    0   35    1.04134    0.08011  92.3%     -    0s\n",
      "H    0     0                       0.0990508    0.08011  19.1%     -    0s\n",
      "     0     0    0.08213    0   24    0.09905    0.08213  17.1%     -    0s\n",
      "     0     0    0.08219    0   20    0.09905    0.08219  17.0%     -    0s\n",
      "     0     0    0.08219    0   20    0.09905    0.08219  17.0%     -    0s\n",
      "     0     0    0.09173    0    7    0.09905    0.09173  7.39%     -    0s\n",
      "     0     0    0.09196    0    5    0.09905    0.09196  7.16%     -    0s\n",
      "     0     0    0.09196    0    5    0.09905    0.09196  7.16%     -    0s\n",
      "\n",
      "Explored 1 nodes (283 simplex iterations) in 0.13 seconds (0.04 work units)\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 4: 0.0990508 0.4419 1.04134 59.6758 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.905080498862e-02, best bound 9.905080498862e-02, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:30:03 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:30:03 AM: Optimal value: 9.905e-02\n",
      "(CVXPY) Oct 11 04:30:03 AM: Compilation took 1.151e-02 seconds\n",
      "(CVXPY) Oct 11 04:30:03 AM: Solver (including time spent in interface) took 1.469e-01 seconds\n",
      "\n",
      "The optimal value is 0.09905080498862162\n",
      "A solution x is\n",
      "[-0.  0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0.  0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0.  0.  1. -0. -0.  1. -0. -0.  1. -0.  0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0.  0.  1. -0. -0.  1. -0.  0.  1. -0. -0.  1. -0.  0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1.  0. -0.  1. -0.  0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0.  0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0.  0.  1.\n",
      " -0.  0.  1.  0. -0.  1. -0.  0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0.  0.  1. -0. -0.  1. -0. -0.  1.  0. -0.  1.  0.  0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 8), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 8), 'layer1.2.conv2': (8, 8), 'layer1.2.conv3': (8, 8), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 8), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 8), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 8), 'layer2.2.conv2': (8, 8), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 8), 'layer2.3.conv2': (8, 8), 'layer2.3.conv3': (8, 8), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 8), 'layer3.0.conv3': (8, 8), 'layer3.0.downsample.0': (8, 8), 'layer3.1.conv1': (8, 8), 'layer3.1.conv2': (8, 8), 'layer3.1.conv3': (8, 8), 'layer3.2.conv1': (8, 8), 'layer3.2.conv2': (8, 8), 'layer3.2.conv3': (8, 8), 'layer3.3.conv1': (8, 8), 'layer3.3.conv2': (8, 8), 'layer3.3.conv3': (8, 8), 'layer3.4.conv1': (8, 8), 'layer3.4.conv2': (8, 8), 'layer3.4.conv3': (8, 8), 'layer3.5.conv1': (8, 8), 'layer3.5.conv2': (8, 8), 'layer3.5.conv3': (8, 8), 'layer4.0.conv1': (8, 8), 'layer4.0.conv2': (8, 8), 'layer4.0.conv3': (8, 8), 'layer4.0.downsample.0': (8, 8), 'layer4.1.conv1': (8, 8), 'layer4.1.conv2': (8, 8), 'layer4.1.conv3': (8, 8), 'layer4.2.conv1': (8, 8), 'layer4.2.conv2': (8, 8), 'layer4.2.conv3': (8, 8)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([75.9260], device='cuda:0'),\n",
       "  'top5': tensor([92.8321], device='cuda:0'),\n",
       "  'loss': tensor(0.9622, device='cuda:0'),\n",
       "  'time': 151.4406497478485},\n",
       " 22.359375,\n",
       " 610.75569408)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=np.inf,\n",
    "                   naive=False)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a8c3c8f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:32:34 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:32:34 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:32:34 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:32:34 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:32:34 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:32:34 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:32:34 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:32:34 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 11 04:32:34 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 11 04:32:34 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:32:34 AM: Finished problem compilation (took 8.518e-03 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:32:34 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Set parameter QCPDual to value 1\n",
      "Set parameter TimeLimit to value 30\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0x8fc74734\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [7e-05, 4e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 13.0274061\n",
      "Presolve removed 54 rows and 156 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 4 available processors)\n",
      "\n",
      "Solution count 2: 0.0417487 13.0274 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.174870804854e-02, best bound 4.174870804854e-02, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:32:34 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:32:34 AM: Optimal value: 4.175e-02\n",
      "(CVXPY) Oct 11 04:32:34 AM: Compilation took 8.518e-03 seconds\n",
      "(CVXPY) Oct 11 04:32:34 AM: Solver (including time spent in interface) took 1.239e-02 seconds\n",
      "\n",
      "The optimal value is 0.04174870804854436\n",
      "A solution x is\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 8), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 8), 'layer1.2.conv2': (8, 8), 'layer1.2.conv3': (8, 8), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 8), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 8), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 8), 'layer2.2.conv2': (8, 8), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 8), 'layer2.3.conv2': (8, 8), 'layer2.3.conv3': (8, 8), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 8), 'layer3.0.conv3': (8, 8), 'layer3.0.downsample.0': (8, 8), 'layer3.1.conv1': (8, 8), 'layer3.1.conv2': (8, 8), 'layer3.1.conv3': (8, 8), 'layer3.2.conv1': (8, 8), 'layer3.2.conv2': (8, 8), 'layer3.2.conv3': (8, 8), 'layer3.3.conv1': (8, 8), 'layer3.3.conv2': (8, 8), 'layer3.3.conv3': (8, 8), 'layer3.4.conv1': (8, 8), 'layer3.4.conv2': (8, 8), 'layer3.4.conv3': (8, 8), 'layer3.5.conv1': (8, 8), 'layer3.5.conv2': (8, 8), 'layer3.5.conv3': (8, 8), 'layer4.0.conv1': (8, 8), 'layer4.0.conv2': (8, 8), 'layer4.0.conv3': (8, 8), 'layer4.0.downsample.0': (8, 8), 'layer4.1.conv1': (8, 8), 'layer4.1.conv2': (8, 8), 'layer4.1.conv3': (8, 8), 'layer4.2.conv1': (8, 8), 'layer4.2.conv2': (8, 8), 'layer4.2.conv3': (8, 8)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([75.9260], device='cuda:0'),\n",
       "  'top5': tensor([92.8321], device='cuda:0'),\n",
       "  'loss': tensor(0.9622, device='cuda:0'),\n",
       "  'time': 152.59963202476501},\n",
       " 22.359375,\n",
       " 610.75569408)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=np.inf,\n",
    "                   naive=True)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f6ca5fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:35:07 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:35:07 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:35:07 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:35:07 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:35:07 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:35:07 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:35:07 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:35:07 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 11 04:35:07 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 11 04:35:07 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:35:07 AM: Finished problem compilation (took 1.122e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:35:07 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Set parameter QCPDual to value 1\n",
      "Set parameter TimeLimit to value 30\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0xa95bf4a8\n",
      "Model has 12246 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [1e-07, 1e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Found heuristic solution: objective 134.4998423\n",
      "Presolve removed 1 rows and 0 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 53 rows, 156 columns, 261 nonzeros\n",
      "Presolved model has 12246 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Found heuristic solution: objective 84.2865453\n",
      "\n",
      "Root relaxation: objective 3.125495e+00, 308 iterations, 0.01 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                      21.4480809    3.12550  85.4%     -    0s\n",
      "H    0     0                      19.4963348    3.12550  84.0%     -    0s\n",
      "     0     0    3.12550    0   22   19.49633    3.12550  84.0%     -    0s\n",
      "H    0     0                       6.7674249    3.12550  53.8%     -    0s\n",
      "H    0     0                       4.7131371    3.12550  33.7%     -    0s\n",
      "H    0     0                       3.5753878    3.12550  12.6%     -    0s\n",
      "     0     0    3.17223    0   28    3.57539    3.17223  11.3%     -    0s\n",
      "     0     0    3.17223    0   16    3.57539    3.17223  11.3%     -    0s\n",
      "     0     0    3.17524    0   24    3.57539    3.17524  11.2%     -    0s\n",
      "     0     0    3.36074    0   24    3.57539    3.36074  6.00%     -    0s\n",
      "     0     0    3.36315    0   24    3.57539    3.36315  5.94%     -    0s\n",
      "     0     0    3.36315    0   23    3.57539    3.36315  5.94%     -    0s\n",
      "     0     0    3.36315    0   23    3.57539    3.36315  5.94%     -    0s\n",
      "     0     2    3.36315    0   23    3.57539    3.36315  5.94%     -    0s\n",
      "H    6     5                       3.5660108    3.47891  2.44%   9.0    0s\n",
      "\n",
      "Cutting planes:\n",
      "  MIR: 1\n",
      "  StrongCG: 1\n",
      "  GUB cover: 1\n",
      "\n",
      "Explored 66 nodes (669 simplex iterations) in 0.15 seconds (0.06 work units)\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 9: 3.56601 3.57539 3.57716 ... 134.5\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.566010799621e+00, best bound 3.566010799621e+00, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:35:07 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:35:07 AM: Optimal value: 3.566e+00\n",
      "(CVXPY) Oct 11 04:35:07 AM: Compilation took 1.122e-02 seconds\n",
      "(CVXPY) Oct 11 04:35:07 AM: Solver (including time spent in interface) took 1.647e-01 seconds\n",
      "\n",
      "The optimal value is 3.566010799620898\n",
      "A solution x is\n",
      "[-0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1. -0.  0.  1. -0. -0.  1.\n",
      " -0.  0.  1. -0.  0.  1.  0.  1. -0. -0. -0.  1.  0. -0.  1.  0.  1.  0.\n",
      "  0.  0.  1.  0.  0.  1. -0. -0.  1.  0.  0.  1. -0. -0.  1. -0. -0.  1.\n",
      "  0.  0.  1.  0.  0.  1. -0.  1.  0.  0.  1.  0. -0. -0.  1.  0.  0.  1.\n",
      "  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0. -0. -0.  1.\n",
      " -0.  1. -0.  0.  1.  0. -0.  1.  0. -0.  1.  0. -0.  1. -0. -0.  1. -0.\n",
      " -0.  1.  0. -0.  1.  0. -0.  1.  0. -0.  1. -0. -0.  1. -0. -0.  1. -0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      " -0.  1.  0.  0.  1.  0. -0.  1.  0.  0.  1.  0.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 8), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 8), 'layer1.2.conv2': (8, 4), 'layer1.2.conv3': (8, 8), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 4), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 8), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 8), 'layer2.2.conv2': (8, 8), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 4), 'layer2.3.conv2': (8, 4), 'layer2.3.conv3': (8, 8), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 4), 'layer3.0.conv3': (8, 4), 'layer3.0.downsample.0': (8, 4), 'layer3.1.conv1': (8, 4), 'layer3.1.conv2': (8, 4), 'layer3.1.conv3': (8, 8), 'layer3.2.conv1': (8, 4), 'layer3.2.conv2': (8, 4), 'layer3.2.conv3': (8, 4), 'layer3.3.conv1': (8, 4), 'layer3.3.conv2': (8, 4), 'layer3.3.conv3': (8, 4), 'layer3.4.conv1': (8, 4), 'layer3.4.conv2': (8, 4), 'layer3.4.conv3': (8, 4), 'layer3.5.conv1': (8, 4), 'layer3.5.conv2': (8, 4), 'layer3.5.conv3': (8, 4), 'layer4.0.conv1': (8, 4), 'layer4.0.conv2': (8, 2), 'layer4.0.conv3': (8, 4), 'layer4.0.downsample.0': (8, 2), 'layer4.1.conv1': (8, 2), 'layer4.1.conv2': (8, 2), 'layer4.1.conv3': (8, 4), 'layer4.2.conv1': (8, 4), 'layer4.2.conv2': (8, 4), 'layer4.2.conv3': (8, 4)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([53.9580], device='cuda:0'),\n",
       "  'top5': tensor([78.4001], device='cuda:0'),\n",
       "  'loss': tensor(2.1375, device='cuda:0'),\n",
       "  'time': 152.35888171195984},\n",
       " 9.982421875,\n",
       " 426.466722304)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=10,\n",
    "                   naive=False)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d230b894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:37:40 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:37:40 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:37:40 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:37:40 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:37:40 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:37:40 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:37:40 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:37:40 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 11 04:37:40 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 11 04:37:40 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:37:40 AM: Finished problem compilation (took 9.400e-03 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:37:40 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Set parameter QCPDual to value 1\n",
      "Set parameter TimeLimit to value 30\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0x21e4d946\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [7e-05, 4e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Found heuristic solution: objective 22.0191943\n",
      "Presolve removed 1 rows and 51 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 53 rows, 105 columns, 210 nonzeros\n",
      "Variable types: 0 continuous, 105 integer (105 binary)\n",
      "Found heuristic solution: objective 4.4298451\n",
      "\n",
      "Root relaxation: objective 1.501224e+00, 11 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.50122    0    1    4.42985    1.50122  66.1%     -    0s\n",
      "H    0     0                       1.7999463    1.50122  16.6%     -    0s\n",
      "H    0     0                       1.5169591    1.50122  1.04%     -    0s\n",
      "     0     0    1.51298    0    2    1.51696    1.51298  0.26%     -    0s\n",
      "     0     0    1.51298    0    2    1.51696    1.51298  0.26%     -    0s\n",
      "H    0     1                       1.5164368    1.51298  0.23%     -    0s\n",
      "\n",
      "Explored 1 nodes (12 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 5: 1.51644 1.51696 1.79995 ... 22.0192\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.516436769780e+00, best bound 1.516436769780e+00, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:37:40 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:37:40 AM: Optimal value: 1.516e+00\n",
      "(CVXPY) Oct 11 04:37:40 AM: Compilation took 9.400e-03 seconds\n",
      "(CVXPY) Oct 11 04:37:40 AM: Solver (including time spent in interface) took 2.061e-02 seconds\n",
      "\n",
      "The optimal value is 1.5164367697798298\n",
      "A solution x is\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 8), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 4), 'layer1.2.conv2': (8, 4), 'layer1.2.conv3': (8, 8), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 4), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 4), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 4), 'layer2.2.conv1': (8, 4), 'layer2.2.conv2': (8, 4), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 4), 'layer2.3.conv2': (8, 4), 'layer2.3.conv3': (8, 8), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 4), 'layer3.0.conv3': (8, 4), 'layer3.0.downsample.0': (8, 4), 'layer3.1.conv1': (8, 4), 'layer3.1.conv2': (8, 4), 'layer3.1.conv3': (8, 4), 'layer3.2.conv1': (8, 4), 'layer3.2.conv2': (8, 4), 'layer3.2.conv3': (8, 4), 'layer3.3.conv1': (8, 4), 'layer3.3.conv2': (8, 4), 'layer3.3.conv3': (8, 4), 'layer3.4.conv1': (8, 4), 'layer3.4.conv2': (8, 4), 'layer3.4.conv3': (8, 4), 'layer3.5.conv1': (8, 4), 'layer3.5.conv2': (8, 4), 'layer3.5.conv3': (8, 4), 'layer4.0.conv1': (8, 4), 'layer4.0.conv2': (8, 2), 'layer4.0.conv3': (8, 4), 'layer4.0.downsample.0': (8, 2), 'layer4.1.conv1': (8, 2), 'layer4.1.conv2': (8, 4), 'layer4.1.conv3': (8, 2), 'layer4.2.conv1': (8, 4), 'layer4.2.conv2': (8, 4), 'layer4.2.conv3': (8, 4)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([53.1861], device='cuda:0'),\n",
       "  'top5': tensor([77.5321], device='cuda:0'),\n",
       "  'loss': tensor(2.4539, device='cuda:0'),\n",
       "  'time': 151.9811131954193},\n",
       " 9.998046875,\n",
       " 403.324497408)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=10,\n",
    "                   naive=True)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1124dc1",
   "metadata": {},
   "source": [
    "## no PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "196ac50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "\n",
    "def MIQCP_optimize(cached_grad,layer_bitops,layer_size,\n",
    "                   schemes_per_layer=3,\n",
    "                   bitops_bound=np.inf,size_bound=np.inf,\n",
    "                   naive=False):\n",
    "    \n",
    "    if cached_grad.__class__ == torch.Tensor:\n",
    "        cached_grad = cached_grad.cpu().numpy()\n",
    "    \n",
    "    x = cp.Variable(cached_grad.shape[0], boolean=True)\n",
    "    schemes_per_layer = schemes_per_layer\n",
    "    assert cached_grad.shape[0]%schemes_per_layer == 0, 'cached_gradient shape[0] does not divde schemes per layer'\n",
    "    num_layers = cached_grad.shape[0]//schemes_per_layer\n",
    "    \n",
    "    if not naive:\n",
    "        # convexation of cached_grad\n",
    "        es,us = np.linalg.eig(cached_grad)\n",
    "        #es[es<0] = 0\n",
    "        C = us@np.diag(es)@us.T\n",
    "        C = (C+C.T)/2\n",
    "        C = cp.atoms.affine.wraps.psd_wrap(C)\n",
    "        objective = cp.Minimize(cp.quad_form(x,C))\n",
    "    else:\n",
    "        objective = cp.Minimize(np.diagonal(cached_grad)@x)\n",
    "\n",
    "    equality_constraint_matrix = []\n",
    "    for i in range(num_layers):\n",
    "        col = np.zeros(cached_grad.shape[0])\n",
    "        col[i*schemes_per_layer:(i+1)*schemes_per_layer] = 1\n",
    "        equality_constraint_matrix.append(col)\n",
    "\n",
    "    equality_constraint_matrix = np.array(equality_constraint_matrix)\n",
    "\n",
    "    constraints = [equality_constraint_matrix@x == np.ones((num_layers,)),\n",
    "                   layer_bitops@x/10**9<=bitops_bound,\n",
    "                   layer_size@x/8/1024/1024<=size_bound]\n",
    "\n",
    "    prob = cp.Problem(objective,constraints)\n",
    "    prob.solve(verbose=True,solver='GUROBI',TimeLimit=30)\n",
    "    \n",
    "    # Print result.\n",
    "    print(\"\\nThe optimal value is\", prob.value)\n",
    "    print(\"A solution x is\")\n",
    "    print(x.value)\n",
    "    #print(f\"bitops: {x.value@layer_bitops}\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8cfc44ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:40:12 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:40:12 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:40:12 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:40:12 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:40:12 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:40:12 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:40:12 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:40:12 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 11 04:40:12 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 11 04:40:12 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:40:12 AM: Finished problem compilation (took 1.159e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:40:12 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Set parameter QCPDual to value 1\n",
      "Set parameter TimeLimit to value 30\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0xd22ed5ec\n",
      "Model has 12244 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [3e-12, 1e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 54.8954257\n",
      "Presolve removed 2 rows and 0 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 52 rows, 156 columns, 156 nonzeros\n",
      "Presolved model has 12244 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Found heuristic solution: objective 1.2864321\n",
      "\n",
      "Root relaxation: objective -1.220783e+01, 193 iterations, 0.01 seconds (0.01 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  -12.20783    0  134    1.28643  -12.20783  1049%     -    0s\n",
      "H    0     0                      -1.8488712  -12.20783   560%     -    0s\n",
      "H    0     0                      -2.0747804  -12.20783   488%     -    0s\n",
      "     0     0  -11.14214    0  134   -2.07478  -11.14214   437%     -    0s\n",
      "H    0     0                      -2.4057537  -11.14214   363%     -    0s\n",
      "     0     2  -11.14214    0  134   -2.40575  -11.14214   363%     -    0s\n",
      " 11566   957   -2.81691   37  119   -2.40575   -2.92345  21.5%   3.4    5s\n",
      "\n",
      "Explored 14636 nodes (48806 simplex iterations) in 5.80 seconds (9.95 work units)\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 5: -2.40575 -2.07478 -1.84887 ... 54.8954\n",
      "No other solutions better than -2.40575\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective -2.405753749586e+00, best bound -2.405753749586e+00, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:40:18 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:40:18 AM: Optimal value: -2.406e+00\n",
      "(CVXPY) Oct 11 04:40:18 AM: Compilation took 1.159e-02 seconds\n",
      "(CVXPY) Oct 11 04:40:18 AM: Solver (including time spent in interface) took 5.824e+00 seconds\n",
      "\n",
      "The optimal value is -2.4057537495863954\n",
      "A solution x is\n",
      "[-0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0.  1.  0. -0. -0.  1.\n",
      " -0. -0.  1.  1. -0. -0. -0.  1. -0.  1. -0. -0. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1.  1. -0. -0.  1. -0. -0. -0. -0.  1. -0.  1. -0.\n",
      "  1. -0. -0.  1. -0. -0. -0. -0.  1. -0. -0.  1. -0.  1. -0. -0.  1.  0.\n",
      " -0. -0.  1. -0.  1.  0. -0.  0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0.  1. -0. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.\n",
      " -0. -0.  1. -0. -0.  1. -0. -0.  1. -0. -0.  1.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 4), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 8), 'layer1.2.conv1': (8, 2), 'layer1.2.conv2': (8, 4), 'layer1.2.conv3': (8, 2), 'layer2.0.conv1': (8, 8), 'layer2.0.conv2': (8, 8), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 8), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 8), 'layer2.2.conv2': (8, 8), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 2), 'layer2.3.conv2': (8, 2), 'layer2.3.conv3': (8, 8), 'layer3.0.conv1': (8, 4), 'layer3.0.conv2': (8, 2), 'layer3.0.conv3': (8, 2), 'layer3.0.downsample.0': (8, 8), 'layer3.1.conv1': (8, 8), 'layer3.1.conv2': (8, 4), 'layer3.1.conv3': (8, 4), 'layer3.2.conv1': (8, 8), 'layer3.2.conv2': (8, 4), 'layer3.2.conv3': (8, 8), 'layer3.3.conv1': (8, 8), 'layer3.3.conv2': (8, 8), 'layer3.3.conv3': (8, 8), 'layer3.4.conv1': (8, 8), 'layer3.4.conv2': (8, 8), 'layer3.4.conv3': (8, 8), 'layer3.5.conv1': (8, 8), 'layer3.5.conv2': (8, 8), 'layer3.5.conv3': (8, 8), 'layer4.0.conv1': (8, 4), 'layer4.0.conv2': (8, 8), 'layer4.0.conv3': (8, 8), 'layer4.0.downsample.0': (8, 8), 'layer4.1.conv1': (8, 8), 'layer4.1.conv2': (8, 8), 'layer4.1.conv3': (8, 8), 'layer4.2.conv1': (8, 8), 'layer4.2.conv2': (8, 8), 'layer4.2.conv3': (8, 8)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([46.9140], device='cuda:0'),\n",
       "  'top5': tensor([71.1660], device='cuda:0'),\n",
       "  'loss': tensor(2.4794, device='cuda:0'),\n",
       "  'time': 152.14299297332764},\n",
       " 20.548828125,\n",
       " 521.675130368)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=np.inf,\n",
    "                   naive=False)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d279625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 11 04:42:50 AM: Your problem has 156 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 11 04:42:50 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 11 04:42:50 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 11 04:42:50 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:42:50 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Oct 11 04:42:50 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Oct 11 04:42:50 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 11 04:42:50 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 11 04:42:50 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 11 04:42:50 AM: Applying reduction GUROBI\n",
      "(CVXPY) Oct 11 04:42:50 AM: Finished problem compilation (took 1.247e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:42:50 AM: Invoking solver GUROBI  to obtain a solution.\n",
      "Set parameter QCPDual to value 1\n",
      "Set parameter TimeLimit to value 30\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 54 rows, 156 columns and 468 nonzeros\n",
      "Model fingerprint: 0xfaa54b1d\n",
      "Model has 12244 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+01]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [3e-12, 1e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 129.5950316\n",
      "Presolve removed 1 rows and 0 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 53 rows, 156 columns, 261 nonzeros\n",
      "Presolved model has 12244 quadratic objective terms\n",
      "Variable types: 0 continuous, 156 integer (156 binary)\n",
      "Found heuristic solution: objective 78.2108867\n",
      "\n",
      "Root relaxation: objective -7.787966e+00, 252 iterations, 0.03 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                      18.7866226   -7.78797   141%     -    0s\n",
      "     0     0   -7.78797    0  122   18.78662   -7.78797   141%     -    0s\n",
      "H    0     0                       3.3373603   -7.78797   333%     -    0s\n",
      "H    0     0                       2.1944348   -7.78797   455%     -    0s\n",
      "     0     0   -7.17908    0  122    2.19443   -7.17908   427%     -    0s\n",
      "     0     2   -7.17908    0  122    2.19443   -7.17908   427%     -    0s\n",
      "H   31    39                       2.1670609   -6.56902   403%   4.9    0s\n",
      " 18999  8544    1.07029   57   76    2.16706   -0.26362   112%   3.0    5s\n",
      " 46450 14993    1.68257   28   98    2.16706    0.73208  66.2%   2.9   10s\n",
      " 75147 16591    1.68244   53   70    2.16706    1.26788  41.5%   2.9   15s\n",
      " 104431 13473     cutoff   43         2.16706    1.66402  23.2%   2.9   20s\n",
      " 133152  8015    2.06010   82   16    2.16706    1.96296  9.42%   2.9   25s\n",
      "\n",
      "Explored 151293 nodes (450374 simplex iterations) in 27.46 seconds (38.41 work units)\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 6: 2.16706 2.19443 3.33736 ... 129.595\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.167060945921e+00, best bound 2.167060945921e+00, gap 0.0000%\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 11 04:43:17 AM: Problem status: optimal\n",
      "(CVXPY) Oct 11 04:43:17 AM: Optimal value: 2.167e+00\n",
      "(CVXPY) Oct 11 04:43:17 AM: Compilation took 1.247e-02 seconds\n",
      "(CVXPY) Oct 11 04:43:17 AM: Solver (including time spent in interface) took 2.747e+01 seconds\n",
      "\n",
      "The optimal value is 2.1670609459210723\n",
      "A solution x is\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "evaluate_decision\n",
      " {'layer1.0.conv1': (8, 8), 'layer1.0.conv2': (8, 8), 'layer1.0.conv3': (8, 8), 'layer1.0.downsample.0': (8, 8), 'layer1.1.conv1': (8, 4), 'layer1.1.conv2': (8, 8), 'layer1.1.conv3': (8, 4), 'layer1.2.conv1': (8, 4), 'layer1.2.conv2': (8, 4), 'layer1.2.conv3': (8, 8), 'layer2.0.conv1': (8, 4), 'layer2.0.conv2': (8, 4), 'layer2.0.conv3': (8, 8), 'layer2.0.downsample.0': (8, 8), 'layer2.1.conv1': (8, 8), 'layer2.1.conv2': (8, 8), 'layer2.1.conv3': (8, 8), 'layer2.2.conv1': (8, 4), 'layer2.2.conv2': (8, 4), 'layer2.2.conv3': (8, 8), 'layer2.3.conv1': (8, 4), 'layer2.3.conv2': (8, 4), 'layer2.3.conv3': (8, 4), 'layer3.0.conv1': (8, 8), 'layer3.0.conv2': (8, 4), 'layer3.0.conv3': (8, 4), 'layer3.0.downsample.0': (8, 4), 'layer3.1.conv1': (8, 4), 'layer3.1.conv2': (8, 4), 'layer3.1.conv3': (8, 4), 'layer3.2.conv1': (8, 4), 'layer3.2.conv2': (8, 4), 'layer3.2.conv3': (8, 4), 'layer3.3.conv1': (8, 4), 'layer3.3.conv2': (8, 4), 'layer3.3.conv3': (8, 4), 'layer3.4.conv1': (8, 4), 'layer3.4.conv2': (8, 4), 'layer3.4.conv3': (8, 4), 'layer3.5.conv1': (8, 4), 'layer3.5.conv2': (8, 4), 'layer3.5.conv3': (8, 4), 'layer4.0.conv1': (8, 4), 'layer4.0.conv2': (8, 4), 'layer4.0.conv3': (8, 4), 'layer4.0.downsample.0': (8, 2), 'layer4.1.conv1': (8, 2), 'layer4.1.conv2': (8, 2), 'layer4.1.conv3': (8, 2), 'layer4.2.conv1': (8, 4), 'layer4.2.conv2': (8, 4), 'layer4.2.conv3': (8, 4)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'top1': tensor([59.7740], device='cuda:0'),\n",
       "  'top5': tensor([82.9501], device='cuda:0'),\n",
       "  'loss': tensor(1.7629, device='cuda:0'),\n",
       "  'time': 150.95378303527832},\n",
       " 9.998046875,\n",
       " 392.848150016)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MIQCP_optimize(cached_grad=cached_grad,\n",
    "                   layer_bitops=layer_bitops,\n",
    "                   layer_size=layer_size,\n",
    "                   schemes_per_layer=len(aw_scheme),\n",
    "                   bitops_bound=np.inf,size_bound=10,\n",
    "                   naive=False)\n",
    "v = torch.Tensor(v.value)\n",
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f242b9d1",
   "metadata": {},
   "source": [
    "## Random MPQ (old code to generate random MPQ schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c568ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_size = []\n",
    "# random_acc = []\n",
    "# for i in range(500):\n",
    "#     v = torch.randn(L)\n",
    "#     res,size = evaluate_decision(v)\n",
    "#     random_size.append(size)\n",
    "#     random_acc.append(res['mean_acc'])\n",
    "\n",
    "# random_size,random_acc\n",
    "\n",
    "# with open('resnet56_random_baseline.pkl','wb') as f:\n",
    "#     pickle.dump({'size':random_size,'acc':random_acc},f)\n",
    "    \n",
    "\n",
    "# plt.hist(random_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d354c4",
   "metadata": {},
   "source": [
    "## Pareto-Frontier of CLADO vs Inter-Layer Dependency Unaware Optimization (Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df83f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iters = (5000,)\n",
    "#lambda1s = np.logspace(-5,-3,3)\n",
    "lambda1s = (0,1e-1,1)\n",
    "lambda2s = np.logspace(-3,0,100) # for 8 x (8,4)\n",
    "sample_size = 1\n",
    "results = {}\n",
    "for n_iter in n_iters:\n",
    "    for lambda1 in lambda1s:\n",
    "        for lambda2 in lambda2s:\n",
    "            feint_loss,feint_size,feint_bitops = [],[],[]\n",
    "            trial_name = f'{aw_scheme}bits_CLADO_lambda1{lambda1}_lambda2{lambda2}_{n_iter}iters'\n",
    "            print(trial_name)\n",
    "            for repeat in range(sample_size):\n",
    "                v = optimize(n_iteration=n_iter,lr=2e-3,beta=[20,2],lambda1=lambda1,lambda2=lambda2,naive=False)\n",
    "                perf,size,bitops = evaluate_decision(v)\n",
    "                feint_loss.append(perf)\n",
    "                feint_size.append(size)\n",
    "                feint_bitops.append(bitops)\n",
    "            results[trial_name] = {'size':feint_size,'perf':feint_loss,'bitops':feint_bitops}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48f9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iters = (5000,)\n",
    "lambda1s = np.logspace(-5,-3,3)\n",
    "lambda1s = (0,1e-1,1)\n",
    "lambda2s = np.logspace(-3,0,100) \n",
    "sample_size = 1\n",
    "\n",
    "for n_iter in n_iters:\n",
    "    for lambda1 in lambda1s:\n",
    "        for lambda2 in lambda2s:\n",
    "            naive_loss,naive_size,naive_bitops = [],[],[]\n",
    "            print('lambda2:',lambda2)\n",
    "            trial_name = f'{aw_scheme}bits_NAIVE_lambda1{lambda1}_lambda2{lambda2}_{n_iter}iters'\n",
    "            for repeat in range(sample_size):\n",
    "                v = optimize(n_iteration=n_iter,lr=2e-3,beta=[20,2],lambda1=lambda1,lambda2=lambda2,naive=True)\n",
    "                perf,size,bitops = evaluate_decision(v)\n",
    "                naive_loss.append(perf)\n",
    "                naive_size.append(size)\n",
    "                naive_bitops.append(bitops)\n",
    "            results[trial_name] = {'size':naive_size,'perf':naive_loss,'bitops':naive_bitops}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xx','wb') as f:\n",
    "    pickle.dump(results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c56c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('saved/general48c10resnet56results.pkl','rb') as f:\n",
    "#     c48 = pickle.load(f)\n",
    "# with open('saved/general248c10resnet56results.pkl','rb') as f:\n",
    "#     c248 = pickle.load(f)\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    c248 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc99274",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.plot(clado_size,clado_calib_acc,label='CALIB cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_calib_acc,label='CALIB cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "plt.xlim([12,22])\n",
    "plt.ylim([70,76])\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba2e16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.plot(clado_size,clado_calib_acc,label='CALIB cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_calib_acc,label='CALIB cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "plt.xlim([12,22])\n",
    "plt.ylim([70,76])\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d1b4cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50_sp.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.plot(clado_size,clado_calib_acc,label='CALIB cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_calib_acc,label='CALIB cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "plt.xlim([12,22])\n",
    "plt.ylim([70,76])\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedded71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad4k_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.plot(clado_size,clado_calib_acc,label='CALIB cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_calib_acc,label='CALIB cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "plt.xlim([12,22])\n",
    "plt.ylim([70,76])\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50_sp.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k SP) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k SP) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad4k_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(4k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(4k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.xlim([10,20])\n",
    "plt.ylim([52,76])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ceb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50_sp.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k SP) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k SP) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad4k_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(4k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(4k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.xlim([15,20])\n",
    "plt.ylim([74,76])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL_sp.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k SP) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k SP) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad4k_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(4k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(4k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.xlim([10,20])\n",
    "plt.ylim([52,76])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL_sp.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k SP) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k SP) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad4k_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(4k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(4k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.xlim([15,20])\n",
    "plt.ylim([74,76])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bae7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1kx1k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1kx1k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad1kx512_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1kx512) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1kx512) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad1kx512(2)_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1kx512(2)) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1kx512(2)) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim([10,20])\n",
    "plt.ylim([45,76])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc49dfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "#     res = pickle.load(f)\n",
    "\n",
    "# clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "# naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "# for item in res['clado_res']:\n",
    "#     test_perf,calib_perf,size,bitops,_ = item\n",
    "#     clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "#     clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "#     clado_size.append(size)\n",
    "#     clado_bitops.append(bitops)\n",
    "\n",
    "# for item in res['naive_res']:\n",
    "#     test_perf,calib_perf,size,bitops,_ = item\n",
    "#     naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "#     naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "#     naive_size.append(size)\n",
    "#     naive_bitops.append(bitops)\n",
    "\n",
    "# clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "# naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "# plt.plot(clado_size,clado_test_acc,label='TEST(1kx1k) cross-layer dependency aware',marker='v')\n",
    "# # plt.plot(naive_size,naive_test_acc,label='TEST(1kx1k) cross-layer dependency unaware',marker='^')\n",
    "# plt.legend()\n",
    "\n",
    "# with open('i1k_resnet50_CachedGrad1kx512_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "#     res = pickle.load(f)\n",
    "\n",
    "# clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "# naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "# for item in res['clado_res']:\n",
    "#     test_perf,calib_perf,size,bitops,_ = item\n",
    "#     clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "#     clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "#     clado_size.append(size)\n",
    "#     clado_bitops.append(bitops)\n",
    "\n",
    "# for item in res['naive_res']:\n",
    "#     test_perf,calib_perf,size,bitops,_ = item\n",
    "#     naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "#     naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "#     naive_size.append(size)\n",
    "#     naive_bitops.append(bitops)\n",
    "\n",
    "# clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "# naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "# plt.plot(clado_size,clado_test_acc,label='TEST(1kx512) cross-layer dependency aware',marker='v')\n",
    "# # plt.plot(naive_size,naive_test_acc,label='TEST(1kx512) cross-layer dependency unaware',marker='^')\n",
    "# plt.legend()\n",
    "\n",
    "# with open('i1k_resnet50_CachedGrad1kx512(2)_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "#     res = pickle.load(f)\n",
    "\n",
    "# clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "# naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "# for item in res['clado_res']:\n",
    "#     test_perf,calib_perf,size,bitops,_ = item\n",
    "#     clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "#     clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "#     clado_size.append(size)\n",
    "#     clado_bitops.append(bitops)\n",
    "\n",
    "# for item in res['naive_res']:\n",
    "#     test_perf,calib_perf,size,bitops,_ = item\n",
    "#     naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "#     naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "#     naive_size.append(size)\n",
    "#     naive_bitops.append(bitops)\n",
    "\n",
    "# clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "# naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "# plt.plot(clado_size,clado_test_acc,label='TEST(1kx512(2)) cross-layer dependency aware',marker='v')\n",
    "# # plt.plot(naive_size,naive_test_acc,label='TEST(1kx512(2)) cross-layer dependency unaware',marker='^')\n",
    "# plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad1kx256_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1kx256) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1kx256) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "plt.xlim([15,20])\n",
    "plt.ylim([74,76])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "## KL used \n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k KL) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k KL) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL_sp.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k SP KL) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k SP KL) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad4k_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(4k KL) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(4k KL) cross-layer dependency unaware',marker='^')\n",
    "# KL not used\n",
    "\n",
    "'''\n",
    "no KL results\n",
    "'''\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50_sp.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(1k SP) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(1k SP) cross-layer dependency unaware',marker='^')\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad4k_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(4k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(4k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim([10,20])\n",
    "plt.ylim([52,76])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (24,16)\n",
    "plt.savefig('all_big.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eebed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "with open('i1k_resnet50_CachedGrad1kx512_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST(4k) cross-layer dependency aware',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST(4k) cross-layer dependency unaware',marker='^')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim([10,20])\n",
    "plt.ylim([52,76])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (24,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f62662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "for kl in (True,False):\n",
    "    for op in ('1k','1ksp','4k'):\n",
    "        plt.clf()\n",
    "        a = '' if not op == '4k' else '4k'\n",
    "        fname = f'CachedGrad{a}_((8, 2), (8, 4), (8, 8))i1k_resnet50'\n",
    "        fname += 'KL' if kl else ''\n",
    "        fname += '_sp' if op == '1ksp' else ''\n",
    "        fname += '.pkl'\n",
    "        print(f'loading {fname}')\n",
    "        with open(fname,'rb') as f:\n",
    "            hm = pickle.load(f)\n",
    "        index2layerscheme = [None for i in range(hm['Ltilde'].shape[0])]\n",
    "\n",
    "        for name in hm['layer_index']:\n",
    "            index = hm['layer_index'][name]\n",
    "            layer_name = name[:-10]\n",
    "            scheme = name[-10:]\n",
    "            index2layerscheme[index] = (layer_name,scheme)\n",
    "        \n",
    "        #plt.imshow(hm['Ltilde'],cmap='hot')\n",
    "        fig = sns.heatmap(hm['Ltilde'], annot=True,  linewidths=.5)\n",
    "        fig = fig.get_figure()\n",
    "        fig.savefig(f\"{fname}_Ltilde.png\") \n",
    "        plt.clf()\n",
    "        L = hm['Ltilde'].shape[0]\n",
    "        cached_grad = np.zeros_like(hm['Ltilde'])\n",
    "        for i in range(L):\n",
    "            for j in range(L):\n",
    "                layer_i,scheme_i = index2layerscheme[i]\n",
    "                layer_j,scheme_j = index2layerscheme[j]\n",
    "                if layer_i == layer_j:\n",
    "                    if scheme_i == scheme_j:\n",
    "                        cached_grad[i,j] = cached_grad[j,i] = 2 * hm['Ltilde'][i,j]\n",
    "                    else:\n",
    "                        #cached_grad[i,j] = cached_grad[j,i] = 4 * hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "                        cached_grad[i,j] = cached_grad[j,i] = 0\n",
    "                else:\n",
    "                    cached_grad[i,j] = cached_grad[j,i] = hm['Ltilde'][i,j] - hm['Ltilde'][i,i] - hm['Ltilde'][j,j]\n",
    "        \n",
    "        #plt.imshow(cached_grad)\n",
    "        fig = sns.heatmap(cached_grad, annot=True,  linewidths=.5)\n",
    "        fig = fig.get_figure()\n",
    "        fig.savefig(f\"{fname}_cached_grad.png\") \n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f97bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50KL.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "plt.xlim([12,22])\n",
    "plt.ylim([70,76])\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware (KL)',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware (KL)',marker='^')\n",
    "\n",
    "with open('i1k_resnet50_CachedGrad_((8, 2), (8, 4), (8, 8))i1k_resnet50.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "\n",
    "clado_test_acc,clado_calib_acc,clado_size,clado_bitops = [],[],[],[]\n",
    "naive_test_acc,naive_calib_acc,naive_size,naive_bitops = [],[],[],[]\n",
    "\n",
    "for item in res['clado_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    clado_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    clado_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    clado_size.append(size)\n",
    "    clado_bitops.append(bitops)\n",
    "\n",
    "for item in res['naive_res']:\n",
    "    test_perf,calib_perf,size,bitops,_ = item\n",
    "    naive_test_acc.append(test_perf['top1'].cpu().numpy())\n",
    "    naive_calib_acc.append(calib_perf['top1'].cpu().numpy())\n",
    "    naive_size.append(size)\n",
    "    naive_bitops.append(bitops)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_size,clado_test_acc = getPF(clado_size,clado_test_acc)\n",
    "naive_size,naive_test_acc = getPF(naive_size,naive_test_acc)\n",
    "plt.xlim([12,22])\n",
    "plt.ylim([70,76])\n",
    "plt.plot(clado_size,clado_test_acc,label='TEST cross-layer dependency aware (loss)',marker='v')\n",
    "plt.plot(naive_size,naive_test_acc,label='TEST cross-layer dependency unaware (loss)',marker='^')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['clado_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "plt.rcParams['figure.figsize'] = (12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15010711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clado_size,clado_acc = [], []\n",
    "# naive_size,naive_acc = [], []\n",
    "# for trial in c48:\n",
    "#     size = c48[trial]['size']\n",
    "#     perf = c48[trial]['perf']\n",
    "#     perf = [x['mean_acc'] for x in perf]\n",
    "#     if 'NAIVE' in trial:\n",
    "#         naive_size,naive_acc = naive_size+size,naive_acc+perf\n",
    "#     if 'CLADO' in trial:\n",
    "#         clado_size,clado_acc = clado_size+size,clado_acc+perf \n",
    "#     #size = np.array(size)\n",
    "#     #perf = np.array(perf)\n",
    "#     #size,perf = getPF(size,perf)\n",
    "#     #plt.plot(size,perf,label=trial)\n",
    "# c48_naive_pf = getPF(np.array(naive_size),np.array(naive_acc))\n",
    "# c48_clado_pf = getPF(np.array(clado_size),np.array(clado_acc))\n",
    "# plt.plot(c48_naive_pf[0],c48_naive_pf[1],label='(4,8)bits naive MPQ')\n",
    "# plt.plot(c48_clado_pf[0],c48_clado_pf[1],label='(4,8)bits clado MPQ')\n",
    "\n",
    "clado_size,clado_acc = [], []\n",
    "naive_size,naive_acc = [], []\n",
    "for trial in c248:\n",
    "    size = c248[trial]['size']\n",
    "    perf = c248[trial]['perf']\n",
    "    perf = [x['mean_acc'] for x in perf]\n",
    "    if 'NAIVE' in trial:\n",
    "        naive_size,naive_acc = naive_size+size,naive_acc+perf\n",
    "    if 'CLADO' in trial:\n",
    "        clado_size,clado_acc = clado_size+size,clado_acc+perf \n",
    "    #size = np.array(size)\n",
    "    #perf = np.array(perf)\n",
    "    #size,perf = getPF(size,perf)\n",
    "    #plt.plot(size,perf,label=trial)\n",
    "c248_naive_pf = getPF(np.array(naive_size),np.array(naive_acc))\n",
    "c248_clado_pf = getPF(np.array(clado_size),np.array(clado_acc))\n",
    "plt.plot(c248_naive_pf[0],c248_naive_pf[1],label='(2,4,8)bits naive MPQ')\n",
    "plt.plot(c248_clado_pf[0],c248_clado_pf[1],label='(2,4,8)bits clado MPQ')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim([0.4,0.7])\n",
    "plt.ylim([0.88,0.95])\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "# plt.savefig('c10resnet56_w248.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40074e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "c248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f38ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "clado_bitops,clado_acc = [], []\n",
    "naive_bitops,naive_acc = [], []\n",
    "for trial in c248:\n",
    "    bitops = c248[trial]['bitops']\n",
    "    perf = c248[trial]['perf']\n",
    "    perf = [x['top1'].cpu() for x in perf]\n",
    "    if 'NAIVE' in trial:\n",
    "        naive_bitops,naive_acc = naive_bitops+bitops,naive_acc+perf\n",
    "    if 'CLADO' in trial:\n",
    "        clado_bitops,clado_acc = clado_bitops+bitops,clado_acc+perf \n",
    "    #size = np.array(size)\n",
    "    #perf = np.array(perf)\n",
    "    #size,perf = getPF(size,perf)\n",
    "    #plt.plot(size,perf,label=trial)\n",
    "c248_naive_pf = (np.array(naive_bitops),np.array(naive_acc))\n",
    "c248_clado_pf = (np.array(clado_bitops),np.array(clado_acc))\n",
    "plt.scatter(c248_naive_pf[0],c248_naive_pf[1],label='naive MPQ')\n",
    "plt.scatter(c248_clado_pf[0],c248_clado_pf[1],label='CLADO MPQ')\n",
    "plt.legend()\n",
    "\n",
    "# plt.xlim([0.4,0.7])\n",
    "# plt.ylim([0.88,0.95])\n",
    "plt.xlabel('Hardware Cost (Model bitops in Gops)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "#plt.savefig('c100resnet56_a48w48.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb97d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c248_naive_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10701d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "c248_clado_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "c248_naive_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12da08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c48_naive_size = np.array(c48['naive_size'])\n",
    "c48_naive_loss = c48['naive_loss']\n",
    "c48_feint_size = np.array(c48['feint_size'])\n",
    "c48_feint_loss = c48['feint_loss']\n",
    "\n",
    "c48_naive_acc = []\n",
    "for i in range(len(c48_naive_loss)):\n",
    "    c48_naive_acc.append(c48_naive_loss[i]['mean_acc'])\n",
    "\n",
    "c48_feint_acc = []\n",
    "for i in range(len(c48_feint_loss)):\n",
    "    c48_feint_acc.append(c48_feint_loss[i]['mean_acc'])\n",
    "\n",
    "c248_naive_size = np.array(c248['naive_size'])\n",
    "c248_naive_loss = c248['naive_loss']\n",
    "c248_feint_size = np.array(c248['feint_size'])\n",
    "c248_feint_loss = c248['feint_loss']\n",
    "\n",
    "c248_naive_acc = []\n",
    "for i in range(len(c248_naive_loss)):\n",
    "    c248_naive_acc.append(c248_naive_loss[i]['mean_acc'])\n",
    "\n",
    "c248_feint_acc = []\n",
    "for i in range(len(c248_feint_loss)):\n",
    "    c248_feint_acc.append(c248_feint_loss[i]['mean_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa465467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "\n",
    "c48_feint_size,c48_feint_acc = getPF(c48_feint_size,c48_feint_acc)\n",
    "\n",
    "c48_naive_size,c48_naive_acc = getPF(c48_naive_size,c48_naive_acc)\n",
    "\n",
    "c248_feint_size,c248_feint_acc = getPF(c248_feint_size,c248_feint_acc)\n",
    "\n",
    "c248_naive_size,c248_naive_acc = getPF(c248_naive_size,c248_naive_acc)\n",
    "\n",
    "plt.scatter(c48_naive_size,c48_naive_acc,color='lightcoral',alpha=0.5,label='c48 Inter-Layer Depedency Unaware Optimization')\n",
    "plt.scatter(c48_feint_size,c48_feint_acc,color='lightblue',alpha=0.5,label='c48 FeintLady Optimization')\n",
    "# plt.scatter(c248_naive_size,c248_naive_acc,color='red',alpha=0.5,label='c248 CLADO Used')\n",
    "# plt.scatter(c248_feint_size,c248_feint_acc,color='blue',alpha=0.5,label='c248 CLADO Not Used')\n",
    "\n",
    "plt.xlabel('Hardware cost')\n",
    "plt.ylabel('Performance')\n",
    "plt.legend()\n",
    "#plt.savefig('c100resnet56FeintEffecacy.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a211db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(naive_size,naive_acc,color='red',alpha=0.5,label='naive')\n",
    "# plt.scatter(naive_size,naive_acc,color='blue',alpha=0.5,label='feint')\n",
    "plt.xlabel('hardware cost')\n",
    "plt.ylabel('performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc8630",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8252488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fname = 'result_cifar100_shufflenetv2_x2_0_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_sfn20 = pickle.load(f)\n",
    "\n",
    "fname = 'result_cifar100_shufflenetv2_x1_5_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_sfn15 = pickle.load(f)\n",
    "    \n",
    "fname = 'result_cifar100_mobilenetv2_x1_4_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_mbn14 = pickle.load(f)\n",
    "\n",
    "fname = 'result_cifar100_mobilenetv2_x0_75_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_mbn075 = pickle.load(f)\n",
    "    \n",
    "\n",
    "fname = 'result_cifar100_resnet56_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_rsn56 = pickle.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in res_rsn56: print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPF_(xs,ys,mode='max',roundtoprecision=1):\n",
    "    pf = {}\n",
    "    for x,y in zip(xs,ys):\n",
    "        new_x = round(x,roundtoprecision)\n",
    "        if new_x in pf:\n",
    "            pf[new_x] = eval(mode)(pf[new_x],y)\n",
    "        else:\n",
    "            pf[new_x] = y\n",
    "    \n",
    "    pf_x,pf_y = [],[]\n",
    "    \n",
    "    for x in pf:\n",
    "        pf_x.append(x)\n",
    "        pf_y.append(pf[x])\n",
    "    \n",
    "    pf_x, pf_y = np.array(pf_x),np.array(pf_y)\n",
    "    \n",
    "    return pf_x,pf_y\n",
    "\n",
    "def getPF(xs,ys):\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    order = np.argsort(xs)\n",
    "    \n",
    "    xs = xs[order]\n",
    "    ys = ys[order]\n",
    "    \n",
    "    cur_max = -1\n",
    "    for i in range(ys.shape[0]):\n",
    "        if ys[i] > cur_max:\n",
    "            cur_max = ys[i]\n",
    "        ys[i] = cur_max\n",
    "    \n",
    "    return xs,ys\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de56442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_1_mbn075,y_1_mbn075 = getPF(res_mbn075['naive_size'],res_mbn075['naive_acc'])\n",
    "x_2_mbn075,y_2_mbn075 = getPF(res_mbn075['feint_size'],res_mbn075['feint_acc'])\n",
    "\n",
    "x_1_mbn14,y_1_mbn14 = getPF(res_mbn14['naive_size'],res_mbn14['naive_acc'])\n",
    "x_2_mbn14,y_2_mbn14 = getPF(res_mbn14['feint_size'],res_mbn14['feint_acc'])\n",
    "\n",
    "x_1_sfn20,y_1_sfn20 = getPF(res_sfn20['naive_size'],res_sfn20['naive_acc'])\n",
    "x_2_sfn20,y_2_sfn20 = getPF(res_sfn20['feint_size'],res_sfn20['feint_acc'])\n",
    "\n",
    "x_1_sfn15,y_1_sfn15 = getPF(res_sfn15['naive_size'],res_sfn15['naive_acc'])\n",
    "x_2_sfn15,y_2_sfn15 = getPF(res_sfn15['feint_size'],res_sfn15['feint_acc'])\n",
    "\n",
    "x_1_rsn56,y_1_rsn56 = getPF(res_rsn56['naive_size'],res_rsn56['naive_acc'])\n",
    "x_2_rsn56,y_2_rsn56 = getPF(res_rsn56['feint_size'],res_rsn56['feint_acc'])\n",
    "\n",
    "#x_random,y_random = getPF(random_size,random_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random baseline vs use/not use gradient on resnet56\n",
    "# plt.rcParams['figure.figsize'] = (12,8)\n",
    "fname = 'result_cifar10_resnet56_mode0_useaccFalse.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    res_rsn = pickle.load(f)\n",
    "fname = 'resnet56_random_baseline.pkl'\n",
    "with open(fname,'rb') as f:\n",
    "    rand_rsn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8529a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(res_rsn['feint_size'][:],res_rsn['feint_acc'][:],color='blue',\n",
    "            marker='o',s=20,alpha=0.5,label='Cross-layer Gradients Used')\n",
    "\n",
    "plt.scatter(res_rsn['naive_size'][:],res_rsn['naive_acc'][:],color='red',\n",
    "            marker='o',s=20,alpha=0.5,label='Cross-layer Gradients Ignored')\n",
    "\n",
    "plt.scatter(rand_rsn['size'],rand_rsn['acc'],color='black',marker='o',s=20,alpha=0.5,\n",
    "            label='Random Guess')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "plt.savefig('c10resnet.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105629d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "plt.plot(x_1_mbn14,y_1_mbn14,color='red',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='mobilenetv2_x1_4(N)')\n",
    "plt.plot(x_2_mbn14,y_2_mbn14,color='blue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='mobilenetv2_x1_4(A)')\n",
    "\n",
    "plt.plot(x_1_sfn20,y_1_sfn20,color='lightcoral',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='shufflenetv2_x2_0(N)')\n",
    "plt.plot(x_2_sfn20,y_2_sfn20,color='lightblue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='sufflenetv2_x2_0(A)')\n",
    "\n",
    "plt.plot(x_1_sfn15,y_1_sfn15,color='orangered',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='shufflenetv2_x1_5(N)')\n",
    "plt.plot(x_2_sfn15,y_2_sfn15,color='cyan',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='sufflenetv2_x1_5(A)')\n",
    "\n",
    "plt.plot(x_1_rsn56,y_1_rsn56,color='darkred',\n",
    "         #marker='^',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='resnet56(N)')\n",
    "plt.plot(x_2_rsn56,y_2_rsn56,color='darkblue',\n",
    "         #marker='v',markersize=3,alpha=0.5,\n",
    "         linewidth=1,label='resnet56(A)')\n",
    "\n",
    "\n",
    "# plt.scatter(x_1,y_1,color='red',marker='^',s=10,alpha=0.5)\n",
    "# plt.scatter(x_2,y_2,color='blue',marker='v',s=10,alpha=0.5)\n",
    "\n",
    "plt.ylim([0.68,0.76])\n",
    "plt.xlim([0.,4])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Hardware Cost (Model Size in MB)',fontsize=20)\n",
    "plt.ylabel('Performance (Accuracy)',fontsize=20)\n",
    "plt.legend()\n",
    "\n",
    "# plt.ylim([0.7,0.755])\n",
    "# plt.xlim([2.7,4.0])\n",
    "plt.savefig('c100pareto_3nets.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e6627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
