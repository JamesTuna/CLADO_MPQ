{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba86fdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zihao/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch,torchvision,os,time\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from utils.util import get_loader,evaluate\n",
    "from utils.layer import qConv2d,qLinear\n",
    "from utils.train import QAVAT_train\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models                           # for example model\n",
    "from mqbench.prepare_by_platform import prepare_by_platform   # add quant nodes for specific Backend\n",
    "from mqbench.prepare_by_platform import BackendType           # contain various Backend, like TensorRT, NNIE, etc.\n",
    "from mqbench.utils.state import enable_calibration            # turn on calibration algorithm, determine scale, zero_point, etc.\n",
    "from mqbench.utils.state import enable_quantization           # turn on actually quantization, like FP32 -> INT8\n",
    "from mqbench.utils.state import disable_all           # turn on actually quantization, like FP32 -> INT8\n",
    "from copy import deepcopy\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet56\", pretrained=True).cuda()\n",
    "# model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_mobilenetv2_x0_5\", pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53657ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train,test = get_loader('cifar10'.upper(),batch_size=128,test_batch_size=128)\n",
    "train.num_workers = 2\n",
    "test.num_workers = 2\n",
    "train.pin_in_memory = True\n",
    "test.pin_in_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f67af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration data used to calibrate PTQ and MPQ\n",
    "calib_data = []\n",
    "i = 0\n",
    "for img,label in train:\n",
    "    i += 1\n",
    "    calib_data.append((img,label))\n",
    "    if i == 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c71366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mqb_model = deepcopy(model)\n",
    "torch_fp_model = deepcopy(model)\n",
    "torch_quantized_model = deepcopy(model)\n",
    "torch_perturb_model = deepcopy(model)\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b007f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE calibration on model parameters\n",
    "backend = BackendType.Academic\n",
    "extra_config = {\n",
    "    'extra_qconfig_dict': {\n",
    "        'w_observer': 'MSEObserver',                              # custom weight observer\n",
    "        'a_observer': 'EMAMSEObserver',                              # custom activation observer\n",
    "        'w_fakequantize': 'FixedFakeQuantize',                    # custom weight fake quantize function\n",
    "        'a_fakequantize': 'FixedFakeQuantize',                    # custom activation fake quantize function\n",
    "        'w_qscheme': {\n",
    "            'bit': 4,                                             # custom bitwidth for weight,\n",
    "            'symmetry': True,                                    # custom whether quant is symmetric for weight,\n",
    "            'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for weight,\n",
    "            'pot_scale': False,                                   # custom whether scale is power of two for weight.\n",
    "        },\n",
    "        'a_qscheme': {\n",
    "            'bit': 8,                                             # custom bitwidth for activation,\n",
    "            'symmetry': False,                                    # custom whether quant is symmetric for activation,\n",
    "            'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for activation,\n",
    "            'pot_scale': False,                                   # custom whether scale is power of two for activation.\n",
    "        }\n",
    "    }                                                         # custom tracer behavior, checkout https://github.com/pytorch/pytorch/blob/efcbbb177eacdacda80b94ad4ce34b9ed6cf687a/torch/fx/_symbolic_trace.py#L836\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e67b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 4 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Set layer conv1 to 8 bit.\n",
      "[MQBENCH] INFO: Set layer fc to 8 bit.\n",
      "[MQBENCH] INFO: Set x post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_8_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_6_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_7_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_8_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set view post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant view_post_act_fake_quantizer\n"
     ]
    }
   ],
   "source": [
    "mqb_model = prepare_by_platform(mqb_model, backend,extra_config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fa42da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n"
     ]
    }
   ],
   "source": [
    "# calibration loop\n",
    "enable_calibration(mqb_model)\n",
    "for img,label in calib_data:\n",
    "    mqb_model(img.cuda())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d500a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 0.8779,\n",
       " 'qtl_acc': 0.8779,\n",
       " 'mean_loss': 0.5192676824104937,\n",
       " 'qtl_loss': 0.5192676824104937,\n",
       " 'test time': 2.8516080379486084,\n",
       " 'acc_list': array([0.8779]),\n",
       " 'loss_list': array([0.51926768])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation loop\n",
    "from mqbench.utils.state import disable_all\n",
    "enable_quantization(mqb_model)\n",
    "#disable_all(mqb_model)\n",
    "evaluate(test,mqb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993e770f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 0.9437,\n",
       " 'qtl_acc': 0.9437,\n",
       " 'mean_loss': 0.2539493507599529,\n",
       " 'qtl_loss': 0.2539493507599529,\n",
       " 'test time': 1.6719481945037842,\n",
       " 'acc_list': array([0.9437]),\n",
       " 'loss_list': array([0.25394935])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test,torch_fp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e0c6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getModuleByName(modelName,moduleName):\n",
    "    '''\n",
    "        replace module with name modelName.moduleName with newModule\n",
    "    '''\n",
    "    tokens = moduleName.split('.')\n",
    "    eval_str = modelName\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            eval_str += f'[{int(token)}]'\n",
    "        except:\n",
    "            eval_str += f'.{token}'\n",
    "            \n",
    "    return eval(eval_str)\n",
    "\n",
    "# pass quantized weight to torch_quantized_model\n",
    "for n,m in mqb_model.named_modules():\n",
    "    if isinstance(m,torch.nn.Linear) or isinstance(m,torch.nn.Conv2d):\n",
    "        # print('loading quantized weight for layer',n)\n",
    "        torch_module = getModuleByName('torch_quantized_model',n)\n",
    "        torch_module.weight.data = m.weight_fake_quant(m.weight).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c08c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 0.8784,\n",
       " 'qtl_acc': 0.8784,\n",
       " 'mean_loss': 0.5174519721465775,\n",
       " 'qtl_loss': 0.5174519721465775,\n",
       " 'test time': 1.749929666519165,\n",
       " 'acc_list': array([0.8784]),\n",
       " 'loss_list': array([0.51745197])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test,torch_quantized_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5773766",
   "metadata": {},
   "outputs": [],
   "source": [
    "mqb_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846ea48",
   "metadata": {},
   "source": [
    "## FeintLady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f9cd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# 1. record all modules we want to consider\n",
    "layers_to_quant = OrderedDict() # layer_name:[torch_fp_module,torch_q_module,torch_p_module]\n",
    "types_to_quant = (torch.nn.Conv2d,torch.nn.Linear)\n",
    "\n",
    "for n,m in torch_fp_model.named_modules():\n",
    "    if isinstance(m,types_to_quant):\n",
    "        layers_to_quant[n] = [m,]\n",
    "        \n",
    "for n,m in torch_quantized_model.named_modules():\n",
    "    if isinstance(m,types_to_quant):\n",
    "        layers_to_quant[n].append(m)\n",
    "\n",
    "for n,m in torch_perturb_model.named_modules():\n",
    "    if isinstance(m,types_to_quant):\n",
    "        layers_to_quant[n].append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c80e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate(calib_data,torch_fp_model)\n",
    "ref_metric = ('mean_loss',res['mean_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "772d2eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 1.0,\n",
       " 'qtl_acc': 1.0,\n",
       " 'mean_loss': 0.0006950303650228307,\n",
       " 'qtl_loss': 0.0006950303650228307,\n",
       " 'test time': 0.15936613082885742,\n",
       " 'acc_list': array([1.]),\n",
       " 'loss_list': array([0.00069503])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa6716b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_loss(perturb_names,ref_metric,eval_data,printInfo=False):\n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        for n in perturb_names:\n",
    "            layers_to_quant[n][2].weight.data = layers_to_quant[n][1].weight.data\n",
    "        # do evaluation\n",
    "        res = evaluate(eval_data,torch_perturb_model)\n",
    "        perturbed_loss = res[ref_metric[0]] - ref_metric[1]\n",
    "        \n",
    "        if printInfo:\n",
    "            print(res)\n",
    "        # recover layers\n",
    "        for n in perturb_names:\n",
    "            layers_to_quant[n][2].weight.data = layers_to_quant[n][0].weight.data\n",
    "    return perturbed_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47dd85f",
   "metadata": {},
   "source": [
    "## Build Cached Grad if not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f370df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "s_time = time.time()\n",
    "cached = {}\n",
    "for n in layers_to_quant:\n",
    "    for m in layers_to_quant:\n",
    "        if n == m:\n",
    "            print('perturb layer',n)\n",
    "            p = perturb_loss([n,],ref_metric,calib_data)\n",
    "            cached[(n,n)] = p\n",
    "        if (n,m) not in cached:\n",
    "            print('perturb layer',n,m)\n",
    "            p = perturb_loss([n,m],ref_metric,calib_data)\n",
    "            cached[(n,m)] = p\n",
    "            cached[(m,n)] = p   \n",
    "print(f'{time.time()-s_time:.2f} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239967a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index = {}\n",
    "cnt = 0\n",
    "for layer in layers_to_quant:\n",
    "    layer_index[layer] = cnt\n",
    "    cnt += 1\n",
    "L = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hm = np.zeros(shape=(L,L))\n",
    "for n in layers_to_quant:\n",
    "    for m in layers_to_quant:\n",
    "        hm[layer_index[n],layer_index[m]] = cached[(n,m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad = np.zeros_like(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99559c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('feintlady_c100resnet56_calib','wb') as f:\n",
    "    pickle.dump({'Ltilde':hm,'layer_index':layer_index},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_loss(['conv1',],ref_metric,eval_data=calib_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc001d",
   "metadata": {},
   "source": [
    "## Load Cached Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "498e1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('feintlady_resnet56_calib','rb') as f:\n",
    "    hm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17bd25f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d35c1d908>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(hm['Ltilde'],cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beb3fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = hm['Ltilde'].shape[0]\n",
    "cached_grad = np.zeros_like(hm['Ltilde'])\n",
    "for i in range(L):\n",
    "    for j in range(L):\n",
    "        if i == j:\n",
    "            cached_grad[i,j] = 0.5 * hm['Ltilde'][i,j]\n",
    "        else:\n",
    "            cached_grad[i,j] = 0.25 * (hm['Ltilde'][i,j]-hm['Ltilde'][i,i]-hm['Ltilde'][j,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccbde6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.11324436e-06,  8.01635906e-07,  3.74064257e-07, ...,\n",
       "         1.90833816e-07, -5.82549546e-08,  1.39370968e-08],\n",
       "       [ 8.01635906e-07, -3.38943937e-06,  3.68784094e-06, ...,\n",
       "        -1.63593722e-06, -1.32054993e-06, -8.19891284e-08],\n",
       "       [ 3.74064257e-07,  3.68784094e-06, -2.38365465e-06, ...,\n",
       "        -1.48320032e-06, -2.39680958e-07, -1.61733624e-07],\n",
       "       ...,\n",
       "       [ 1.90833816e-07, -1.63593722e-06, -1.48320032e-06, ...,\n",
       "         1.25698825e-04,  4.74548506e-06, -4.17436240e-07],\n",
       "       [-5.82549546e-08, -1.32054993e-06, -2.39680958e-07, ...,\n",
       "         4.74548506e-06,  6.75085539e-05, -4.71663952e-08],\n",
       "       [ 1.39370968e-08, -8.19891284e-08, -1.61733624e-07, ...,\n",
       "        -4.17436240e-07, -4.71663952e-08, -7.30753527e-07]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e34a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d35b6e358>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cached_grad[cached_grad<0]=0\n",
    "plt.imshow(cached_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4555d2",
   "metadata": {},
   "source": [
    "### Define a naive cost function: model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5886f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = np.array([0 for i in range(L)])\n",
    "for l in hm['layer_index']:\n",
    "    layer_size[hm['layer_index'][l]] = torch.numel(layers_to_quant[l][0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b50707a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size\n",
    "tot_size =  layer_size.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4bcd5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random variable v\n",
    "# use recitfied sigmoid h(v) to represent alpha\n",
    "# freg is 1-(1-2h(v))**beta, annealing beta to \n",
    "\n",
    "if not isinstance(cached_grad,torch.Tensor):\n",
    "    cached_grad = torch.Tensor(cached_grad)\n",
    "\n",
    "layer_size_tensor = torch.Tensor(layer_size)\n",
    "\n",
    "def lossfunc(v,beta,lambda1,lambda2,printInfo=False,naive=False,b=None):\n",
    "    alpha = (torch.sigmoid(v) * 1.2 - 0.1).clamp(0,1)\n",
    "    if not naive:\n",
    "        \n",
    "        outer_alpha = torch.outer(alpha,alpha)\n",
    "        netloss = torch.sum(outer_alpha * cached_grad)\n",
    "    else:\n",
    "        netloss = torch.sum(torch.diagonal(cached_grad) * alpha)\n",
    "            \n",
    "    regloss = torch.sum(1-(torch.abs(1-2*alpha))**beta)\n",
    "    regloss *= lambda1\n",
    "    \n",
    "    if b is None:\n",
    "        closs = -lambda2 * torch.sum(layer_size_tensor * alpha)\n",
    "    else:\n",
    "        closs = torch.sum(layer_size_tensor * alpha * 4) + torch.sum(layer_size_tensor * (1-alpha) * 8)\n",
    "        closs = torch.clamp(closs-b,0)\n",
    "        closs *= lambda2\n",
    "        \n",
    "    \n",
    "    totloss = netloss + regloss + closs\n",
    "    \n",
    "    if printInfo:\n",
    "        print(f'netloss {netloss.item():.4f} regloss {regloss.item():.4f}(beta={beta:.4f}) closs{closs.item():.4f}(constraint:{b})')\n",
    "        print('alpha:\\n',alpha)\n",
    "        \n",
    "    return totloss    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04760381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(n_iteration,lr,beta,lambda1,lambda2,b=None,naive=False):\n",
    "    \n",
    "    v = torch.nn.Parameter(torch.randn(L))\n",
    "    optim = torch.optim.Adam([v,],lr=lr)\n",
    "    bs = np.linspace(beta[0],beta[1],n_iteration)\n",
    "    \n",
    "    for i in range(n_iteration):\n",
    "        if i==0 or (i+1) % 1000 == 0:\n",
    "            printInfo = True\n",
    "            print(f'Iter {i+1}')\n",
    "        else:\n",
    "            printInfo = False\n",
    "            \n",
    "        optim.zero_grad()\n",
    "        loss = lossfunc(v,bs[i],lambda1,lambda2,printInfo=printInfo,b=b,naive=naive)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    return v\n",
    "\n",
    "def evaluate_decision(v,printInfo=False):\n",
    "    v = v.detach()\n",
    "    v[v>0] = 1\n",
    "    v[v<0] = 0\n",
    "    \n",
    "    decision = []\n",
    "    for layer in hm['layer_index']:\n",
    "        if v[hm['layer_index'][layer]] > 0:\n",
    "            decision.append(layer)\n",
    "    \n",
    "    \n",
    "    #ploss = perturb_loss(decision,ref_metric,eval_data=test,printInfo=printInfo)\n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        for n in decision:\n",
    "            layers_to_quant[n][2].weight.data = layers_to_quant[n][1].weight.data\n",
    "        # do evaluation\n",
    "        res = evaluate(test,torch_perturb_model)\n",
    "        # recover layers\n",
    "        for n in decision:\n",
    "            layers_to_quant[n][2].weight.data = layers_to_quant[n][0].weight.data\n",
    "    \n",
    "    orig_size = 0\n",
    "    reduced_size = 0\n",
    "    for i in range(L):\n",
    "        orig_size += layer_size[i] * 8\n",
    "        reduced_size += layer_size[i] * 8 if v[i] == 0 else layer_size[i] * 4\n",
    "    if printInfo:\n",
    "        print('result of quantizing the following layers')\n",
    "        print(decision)\n",
    "        print(res)\n",
    "        print(f'8-bit model size {orig_size/8/1024/1024:.2f} MB')\n",
    "        print(f'MP model size {reduced_size/8/1024/1024:.2f} MB') \n",
    "    \n",
    "    return res,reduced_size/8/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "04d858bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2ccad800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4087219.1999999997, 0.48723449707031247)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_size * 8 * r, tot_size /1024/1024 * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ef4783a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1\n",
      "netloss 0.0015 regloss 0.0559(beta=20.0000) closs0.0507(constraint:4087219.1999999997)\n",
      "alpha:\n",
      " tensor([0.6131, 0.1389, 0.3812, 0.3924, 0.1424, 0.6334, 0.5418, 0.1979, 0.2667,\n",
      "        0.8611, 0.3606, 1.0000, 0.4459, 0.1867, 0.5337, 0.6844, 0.2337, 0.3032,\n",
      "        0.8124, 0.8757, 0.4413, 0.6263, 0.3361, 0.5732, 0.4946, 0.3955, 0.2503,\n",
      "        0.0357, 0.9402, 0.8790, 0.3561, 0.6861, 0.4050, 0.2823, 0.2538, 0.4128,\n",
      "        0.6896, 0.8533, 0.4162, 0.0147, 0.1717, 0.2967, 0.3329, 0.6783, 0.3025,\n",
      "        0.8108, 0.2082, 0.9273, 0.7607, 0.8053, 0.9331, 0.0480, 0.6785, 0.4677,\n",
      "        0.1663, 0.4337, 0.8071, 0.6092], grad_fn=<ClampBackward1>)\n",
      "Iter 1000\n",
      "netloss 0.0021 regloss 0.0453(beta=16.4029) closs0.0143(constraint:4087219.1999999997)\n",
      "alpha:\n",
      " tensor([0.8616, 0.4185, 0.6764, 0.6804, 0.4213, 0.8624, 0.7959, 0.4857, 0.5631,\n",
      "        1.0000, 0.6540, 1.0000, 0.7249, 0.4687, 0.7909, 0.9184, 0.5260, 0.5971,\n",
      "        1.0000, 1.0000, 0.7248, 0.3189, 0.6324, 0.8183, 0.7621, 0.6846, 0.5467,\n",
      "        0.0000, 1.0000, 1.0000, 0.6504, 0.8954, 0.6926, 0.5806, 0.5503, 0.6991,\n",
      "        0.8982, 1.0000, 0.7026, 0.0000, 0.4419, 0.5951, 0.6295, 0.8860, 0.6007,\n",
      "        0.9808, 0.4997, 1.0000, 0.9406, 0.9757, 1.0000, 0.3147, 0.8861, 0.7429,\n",
      "        0.4483, 0.7158, 0.9778, 0.8535], grad_fn=<ClampBackward1>)\n",
      "Iter 2000\n",
      "netloss 0.0021 regloss 0.0318(beta=12.8022) closs0.0000(constraint:4087219.1999999997)\n",
      "alpha:\n",
      " tensor([1.0000, 0.5577, 0.7460, 0.7938, 0.5855, 1.0000, 1.0000, 0.5985, 0.7097,\n",
      "        1.0000, 0.7656, 1.0000, 0.8902, 0.5790, 1.0000, 1.0000, 0.6443, 0.6798,\n",
      "        1.0000, 1.0000, 0.7725, 0.0976, 0.7587, 1.0000, 0.8812, 0.7982, 0.6832,\n",
      "        0.0000, 1.0000, 1.0000, 0.7713, 1.0000, 0.8074, 0.7210, 0.6896, 0.8125,\n",
      "        1.0000, 1.0000, 0.7918, 0.0000, 0.4392, 0.7318, 0.7568, 1.0000, 0.7351,\n",
      "        1.0000, 0.6531, 1.0000, 1.0000, 1.0000, 1.0000, 0.4974, 1.0000, 0.8443,\n",
      "        0.6123, 0.8212, 1.0000, 1.0000], grad_fn=<ClampBackward1>)\n",
      "Iter 3000\n",
      "netloss 0.0016 regloss 0.0278(beta=9.2014) closs0.0000(constraint:4087219.1999999997)\n",
      "alpha:\n",
      " tensor([1.0000, 0.4686, 0.5807, 1.0000, 0.5634, 1.0000, 1.0000, 0.4692, 0.7273,\n",
      "        1.0000, 0.7620, 1.0000, 1.0000, 0.4559, 1.0000, 1.0000, 0.5498, 0.5228,\n",
      "        1.0000, 1.0000, 0.5661, 0.0000, 0.7599, 1.0000, 1.0000, 0.8213, 0.6550,\n",
      "        0.0000, 1.0000, 1.0000, 0.7736, 1.0000, 0.8583, 0.7241, 0.6700, 0.8749,\n",
      "        1.0000, 1.0000, 0.7274, 0.0000, 0.1663, 0.7329, 0.7547, 1.0000, 0.7331,\n",
      "        1.0000, 0.6444, 1.0000, 1.0000, 1.0000, 1.0000, 0.4926, 1.0000, 0.8660,\n",
      "        0.6089, 0.8251, 1.0000, 1.0000], grad_fn=<ClampBackward1>)\n",
      "Iter 4000\n",
      "netloss 0.0014 regloss 0.0193(beta=5.6007) closs0.0000(constraint:4087219.1999999997)\n",
      "alpha:\n",
      " tensor([1.0000, 0.3254, 0.3652, 1.0000, 0.5157, 1.0000, 1.0000, 0.2513, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.2772, 1.0000, 1.0000, 0.4024, 0.3078,\n",
      "        1.0000, 1.0000, 0.3187, 0.0000, 0.9330, 1.0000, 1.0000, 1.0000, 0.6142,\n",
      "        0.0000, 1.0000, 1.0000, 0.9757, 1.0000, 1.0000, 0.8053, 0.6421, 1.0000,\n",
      "        1.0000, 1.0000, 0.6184, 0.0000, 0.0000, 0.7500, 0.7735, 1.0000, 0.7437,\n",
      "        1.0000, 0.6306, 1.0000, 1.0000, 1.0000, 1.0000, 0.4858, 1.0000, 0.9962,\n",
      "        0.6031, 0.9111, 1.0000, 1.0000], grad_fn=<ClampBackward1>)\n",
      "Iter 5000\n",
      "netloss 0.0012 regloss 0.0064(beta=2.0000) closs0.0000(constraint:4087219.1999999997)\n",
      "alpha:\n",
      " tensor([1.0000, 0.0000, 0.0000, 1.0000, 0.2009, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0054, 0.0000,\n",
      "        1.0000, 1.0000, 0.0098, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.7830,\n",
      "        0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8828, 1.0000,\n",
      "        1.0000, 1.0000, 0.4587, 0.0000, 0.0000, 0.9195, 0.9432, 1.0000, 0.9085,\n",
      "        1.0000, 0.6770, 1.0000, 1.0000, 1.0000, 1.0000, 0.4693, 1.0000, 1.0000,\n",
      "        0.6424, 1.0000, 1.0000, 1.0000], grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "v = optimize(n_iteration=5000,lr=1e-3,beta=[20,2],lambda1=1e-3,lambda2=5e-8,naive=False,b=tot_size * 8 * r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cf97384a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_acc': 0.9323,\n",
       "  'qtl_acc': 0.9323,\n",
       "  'mean_loss': 0.31045264349896695,\n",
       "  'qtl_loss': 0.31045264349896695,\n",
       "  'test time': 1.6236681938171387,\n",
       "  'acc_list': array([0.9323]),\n",
       "  'loss_list': array([0.31045264])},\n",
       " 0.46767425537109375)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f91e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = optimize(n_iteration=10000,lr=2e-3,beta=[20,2],lambda1=0,lambda2=0,naive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36728f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_decision(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d354c4",
   "metadata": {},
   "source": [
    "## Pareto-Frontier of FeintLady vs Inter-Layer Dependency Unaware Optimization (Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48f9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fix lambda1 to 1e-3\n",
    "# search lambda2 from 1e-5 to 1e-10\n",
    "# each HP (lambda2) try 5 runs\n",
    "\n",
    "lambda2s = np.logspace(-5,-10,50) #lambda1=1e-3,n=5000,lr=1e-3,beta=[20,2] for resnet20 on cifar10\n",
    "lambda2s = np.logspace(-5,-10,50) #lambda1=1e-1,n=5000,lr=1e-3,beta=[20,2] for resnet20 on cifar100\n",
    "sample_size = 5\n",
    "naive_loss,naive_size = [],[]\n",
    "feint_loss,feint_size = [],[]\n",
    "\n",
    "for lambda2 in lambda2s:\n",
    "    print('lambda2:',lambda2)\n",
    "    for repeat in range(sample_size):\n",
    "        v = optimize(n_iteration=5000,lr=1e-3,beta=[20,2],lambda1=1e-1,lambda2=lambda2,naive=True)\n",
    "        perf,size = evaluate_decision(v)\n",
    "        naive_loss.append(perf)\n",
    "        naive_size.append(size)\n",
    "\n",
    "        v = optimize(n_iteration=5000,lr=1e-3,beta=[20,2],lambda1=1e-1,lambda2=lambda2,naive=False)\n",
    "        perf,size = evaluate_decision(v)\n",
    "        feint_loss.append(perf)\n",
    "        feint_size.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_size = np.array(naive_size)\n",
    "feint_size = np.array(feint_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12da08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_acc = [naive_loss[i]['mean_acc'] for i in range(len(naive_loss))]\n",
    "feint_acc = [feint_loss[i]['mean_acc'] for i in range(len(feint_loss))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('c100resnet56scatterplot.pkl','wb') as f:\n",
    "    pickle.dump({'naive_size':naive_size,'naive_acc':naive_acc,\n",
    "                 'feint_size':feint_size,'feint_acc':feint_acc},f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa465467",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(naive_size,naive_acc,color='red',alpha=0.5,label='Inter-Layer Depedency Unaware Optimization')\n",
    "plt.scatter(feint_size,feint_acc,color='blue',alpha=0.5,label='FeintLady Optimization')\n",
    "plt.xlabel('Hardware cost')\n",
    "plt.ylabel('Performance')\n",
    "plt.legend()\n",
    "# plt.imshow(X_std,cmap='hot')\n",
    "# plt.xlabel('layer index')\n",
    "# plt.ylabel('layer index')\n",
    "plt.savefig('c100resnet56FeintEffecacy.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a211db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(naive_size,naive_acc,color='red',alpha=0.5,label='naive')\n",
    "# plt.scatter(naive_size,naive_acc,color='blue',alpha=0.5,label='feint')\n",
    "plt.xlabel('hardware cost')\n",
    "plt.ylabel('performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8252488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
