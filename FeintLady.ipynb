{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba86fdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zihao/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch,torchvision,os,pyhessian,time\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pyhessian\n",
    "from utils.util import get_loader,evaluate\n",
    "from utils.layer import qConv2d,qLinear\n",
    "from utils.train import QAVAT_train\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53657ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train,test = get_loader('cifar10'.upper(),batch_size=256,test_batch_size=256)\n",
    "train.num_workers = 4\n",
    "test.num_workers = 4\n",
    "train.pin_in_memory = True\n",
    "test.pin_in_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c71366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models                           # for example model\n",
    "from mqbench.prepare_by_platform import prepare_by_platform   # add quant nodes for specific Backend\n",
    "from mqbench.prepare_by_platform import BackendType           # contain various Backend, like TensorRT, NNIE, etc.\n",
    "from mqbench.utils.state import enable_calibration            # turn on calibration algorithm, determine scale, zero_point, etc.\n",
    "from mqbench.utils.state import enable_quantization           # turn on actually quantization, like FP32 -> INT8\n",
    "from mqbench.convert_deploy import convert_deploy             # remove quant nodes for deploy\n",
    "from mqbench.advanced_ptq import ptq_reconstruction\n",
    "\n",
    "from copy import deepcopy\n",
    "model.eval()\n",
    "mqb_model = deepcopy(model)\n",
    "torch_fp_model = deepcopy(model)\n",
    "torch_quantized_model = deepcopy(model)\n",
    "torch_perturb_model = deepcopy(model)\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b007f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE calibration on model parameters\n",
    "backend = BackendType.Academic\n",
    "extra_config = {\n",
    "    'extra_qconfig_dict': {\n",
    "        'w_observer': 'MSEObserver',                              # custom weight observer\n",
    "        'a_observer': 'EMAMSEObserver',                              # custom activation observer\n",
    "        'w_fakequantize': 'FixedFakeQuantize',                    # custom weight fake quantize function\n",
    "        'a_fakequantize': 'FixedFakeQuantize',                    # custom activation fake quantize function\n",
    "        'w_qscheme': {\n",
    "            'bit': 4,                                             # custom bitwidth for weight,\n",
    "            'symmetry': True,                                    # custom whether quant is symmetric for weight,\n",
    "            'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for weight,\n",
    "            'pot_scale': False,                                   # custom whether scale is power of two for weight.\n",
    "        },\n",
    "        'a_qscheme': {\n",
    "            'bit': 8,                                             # custom bitwidth for activation,\n",
    "            'symmetry': False,                                    # custom whether quant is symmetric for activation,\n",
    "            'per_channel': False,                                  # custom whether quant is per-channel or per-tensor for activation,\n",
    "            'pot_scale': False,                                   # custom whether scale is power of two for activation.\n",
    "        }\n",
    "    }                                                         # custom tracer behavior, checkout https://github.com/pytorch/pytorch/blob/efcbbb177eacdacda80b94ad4ce34b9ed6cf687a/torch/fx/_symbolic_trace.py#L836\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e67b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 4 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Set layer conv1 to 8 bit.\n",
      "[MQBENCH] INFO: Set layer fc to 8 bit.\n",
      "[MQBENCH] INFO: Set x post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set view post act quantize to 8 bit.\n",
      "[MQBENCH] INFO: Insert act quant view_post_act_fake_quantizer\n"
     ]
    }
   ],
   "source": [
    "mqb_model = prepare_by_platform(mqb_model, backend,extra_config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11fa42da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n"
     ]
    }
   ],
   "source": [
    "# calibration loop\n",
    "enable_calibration(mqb_model)\n",
    "for i, batch in enumerate(train):\n",
    "    \n",
    "    mqb_model(batch[0].cuda())\n",
    "    \n",
    "    if i == 3: break # use the first 4 batches (1024 samples) to do calibration   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d500a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 0.8833,\n",
       " 'qtl_acc': 0.8833,\n",
       " 'mean_loss': 0.43942759484052657,\n",
       " 'qtl_loss': 0.43942759484052657,\n",
       " 'test time': 0.8666608333587646,\n",
       " 'acc_list': array([0.8833]),\n",
       " 'loss_list': array([0.43942759])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation loop\n",
    "from mqbench.utils.state import disable_all\n",
    "enable_quantization(mqb_model)\n",
    "# disable_all(mqb_model)\n",
    "evaluate(test,mqb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e0c6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading quantized weight for layer conv1\n",
      "loading quantized weight for layer fc\n",
      "loading quantized weight for layer layer1.0.conv1\n",
      "loading quantized weight for layer layer1.0.conv2\n",
      "loading quantized weight for layer layer1.1.conv1\n",
      "loading quantized weight for layer layer1.1.conv2\n",
      "loading quantized weight for layer layer1.2.conv1\n",
      "loading quantized weight for layer layer1.2.conv2\n",
      "loading quantized weight for layer layer2.0.conv1\n",
      "loading quantized weight for layer layer2.0.conv2\n",
      "loading quantized weight for layer layer2.0.downsample.0\n",
      "loading quantized weight for layer layer2.1.conv1\n",
      "loading quantized weight for layer layer2.1.conv2\n",
      "loading quantized weight for layer layer2.2.conv1\n",
      "loading quantized weight for layer layer2.2.conv2\n",
      "loading quantized weight for layer layer3.0.conv1\n",
      "loading quantized weight for layer layer3.0.conv2\n",
      "loading quantized weight for layer layer3.0.downsample.0\n",
      "loading quantized weight for layer layer3.1.conv1\n",
      "loading quantized weight for layer layer3.1.conv2\n",
      "loading quantized weight for layer layer3.2.conv1\n",
      "loading quantized weight for layer layer3.2.conv2\n"
     ]
    }
   ],
   "source": [
    "def getModuleByName(modelName,moduleName):\n",
    "    '''\n",
    "        replace module with name modelName.moduleName with newModule\n",
    "    '''\n",
    "    tokens = moduleName.split('.')\n",
    "    eval_str = modelName\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            eval_str += f'[{int(token)}]'\n",
    "        except:\n",
    "            eval_str += f'.{token}'\n",
    "            \n",
    "    return eval(eval_str)\n",
    "    \n",
    "for n,m in mqb_model.named_modules():\n",
    "    if isinstance(m,torch.nn.Linear) or isinstance(m,torch.nn.Conv2d):\n",
    "        print('loading quantized weight for layer',n)\n",
    "        torch_module = getModuleByName('torch_quantized_model',n)\n",
    "        torch_module.weight.data = m.weight_fake_quant(m.weight).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c08c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_acc': 0.926,\n",
       " 'qtl_acc': 0.926,\n",
       " 'mean_loss': 0.28646136410534384,\n",
       " 'qtl_loss': 0.28646136410534384,\n",
       " 'test time': 0.6562838554382324,\n",
       " 'acc_list': array([0.926]),\n",
       " 'loss_list': array([0.28646136])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test,torch_perturb_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33768cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mqb_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846ea48",
   "metadata": {},
   "source": [
    "## FeintLady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9cd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# 1. record all modules we want to consider\n",
    "layers_to_quant = OrderedDict() # layer_name:[torch_fp_module,torch_q_module,torch_p_module]\n",
    "types_to_quant = (torch.nn.Conv2d,torch.nn.Linear)\n",
    "\n",
    "for n,m in torch_fp_model.named_modules():\n",
    "    if isinstance(m,types_to_quant):\n",
    "        layers_to_quant[n] = [m,]\n",
    "        \n",
    "for n,m in torch_quantized_model.named_modules():\n",
    "    if isinstance(m,types_to_quant):\n",
    "        layers_to_quant[n].append(m)\n",
    "\n",
    "for n,m in torch_perturb_model.named_modules():\n",
    "    if isinstance(m,types_to_quant):\n",
    "        layers_to_quant[n].append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884ab144",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate(test,torch_perturb_model)\n",
    "ref_metric = ('mean_loss',res['mean_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a145393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_loss(perturb_names,ref_metric):\n",
    "    with torch.no_grad():\n",
    "        # perturb layers\n",
    "        for n in perturb_names:\n",
    "            layers_to_quant[n][2].weight.data = layers_to_quant[n][1].weight.data\n",
    "        # do evaluation\n",
    "        res = evaluate(test,torch_perturb_model)\n",
    "        perturbed_loss = res[ref_metric[0]] - ref_metric[1]\n",
    "#         print(res)\n",
    "        # recover layers\n",
    "        for n in perturb_names:\n",
    "            layers_to_quant[n][2].weight.data = layers_to_quant[n][0].weight.data\n",
    "    return perturbed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a66f11d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturb layer conv1\n",
      "perturb layer conv1 layer1.0.conv1\n",
      "perturb layer conv1 layer1.0.conv2\n",
      "perturb layer conv1 layer1.1.conv1\n",
      "perturb layer conv1 layer1.1.conv2\n",
      "perturb layer conv1 layer1.2.conv1\n",
      "perturb layer conv1 layer1.2.conv2\n",
      "perturb layer conv1 layer2.0.conv1\n",
      "perturb layer conv1 layer2.0.conv2\n",
      "perturb layer conv1 layer2.0.downsample.0\n",
      "perturb layer conv1 layer2.1.conv1\n",
      "perturb layer conv1 layer2.1.conv2\n",
      "perturb layer conv1 layer2.2.conv1\n",
      "perturb layer conv1 layer2.2.conv2\n",
      "perturb layer conv1 layer3.0.conv1\n",
      "perturb layer conv1 layer3.0.conv2\n",
      "perturb layer conv1 layer3.0.downsample.0\n",
      "perturb layer conv1 layer3.1.conv1\n",
      "perturb layer conv1 layer3.1.conv2\n",
      "perturb layer conv1 layer3.2.conv1\n",
      "perturb layer conv1 layer3.2.conv2\n",
      "perturb layer conv1 fc\n",
      "perturb layer layer1.0.conv1\n",
      "perturb layer layer1.0.conv1 layer1.0.conv2\n",
      "perturb layer layer1.0.conv1 layer1.1.conv1\n",
      "perturb layer layer1.0.conv1 layer1.1.conv2\n",
      "perturb layer layer1.0.conv1 layer1.2.conv1\n",
      "perturb layer layer1.0.conv1 layer1.2.conv2\n",
      "perturb layer layer1.0.conv1 layer2.0.conv1\n",
      "perturb layer layer1.0.conv1 layer2.0.conv2\n",
      "perturb layer layer1.0.conv1 layer2.0.downsample.0\n",
      "perturb layer layer1.0.conv1 layer2.1.conv1\n",
      "perturb layer layer1.0.conv1 layer2.1.conv2\n",
      "perturb layer layer1.0.conv1 layer2.2.conv1\n",
      "perturb layer layer1.0.conv1 layer2.2.conv2\n",
      "perturb layer layer1.0.conv1 layer3.0.conv1\n",
      "perturb layer layer1.0.conv1 layer3.0.conv2\n",
      "perturb layer layer1.0.conv1 layer3.0.downsample.0\n",
      "perturb layer layer1.0.conv1 layer3.1.conv1\n",
      "perturb layer layer1.0.conv1 layer3.1.conv2\n",
      "perturb layer layer1.0.conv1 layer3.2.conv1\n",
      "perturb layer layer1.0.conv1 layer3.2.conv2\n",
      "perturb layer layer1.0.conv1 fc\n",
      "perturb layer layer1.0.conv2\n",
      "perturb layer layer1.0.conv2 layer1.1.conv1\n",
      "perturb layer layer1.0.conv2 layer1.1.conv2\n",
      "perturb layer layer1.0.conv2 layer1.2.conv1\n",
      "perturb layer layer1.0.conv2 layer1.2.conv2\n",
      "perturb layer layer1.0.conv2 layer2.0.conv1\n",
      "perturb layer layer1.0.conv2 layer2.0.conv2\n",
      "perturb layer layer1.0.conv2 layer2.0.downsample.0\n",
      "perturb layer layer1.0.conv2 layer2.1.conv1\n",
      "perturb layer layer1.0.conv2 layer2.1.conv2\n",
      "perturb layer layer1.0.conv2 layer2.2.conv1\n",
      "perturb layer layer1.0.conv2 layer2.2.conv2\n",
      "perturb layer layer1.0.conv2 layer3.0.conv1\n",
      "perturb layer layer1.0.conv2 layer3.0.conv2\n",
      "perturb layer layer1.0.conv2 layer3.0.downsample.0\n",
      "perturb layer layer1.0.conv2 layer3.1.conv1\n",
      "perturb layer layer1.0.conv2 layer3.1.conv2\n",
      "perturb layer layer1.0.conv2 layer3.2.conv1\n",
      "perturb layer layer1.0.conv2 layer3.2.conv2\n",
      "perturb layer layer1.0.conv2 fc\n",
      "perturb layer layer1.1.conv1\n",
      "perturb layer layer1.1.conv1 layer1.1.conv2\n",
      "perturb layer layer1.1.conv1 layer1.2.conv1\n",
      "perturb layer layer1.1.conv1 layer1.2.conv2\n",
      "perturb layer layer1.1.conv1 layer2.0.conv1\n",
      "perturb layer layer1.1.conv1 layer2.0.conv2\n",
      "perturb layer layer1.1.conv1 layer2.0.downsample.0\n",
      "perturb layer layer1.1.conv1 layer2.1.conv1\n",
      "perturb layer layer1.1.conv1 layer2.1.conv2\n",
      "perturb layer layer1.1.conv1 layer2.2.conv1\n",
      "perturb layer layer1.1.conv1 layer2.2.conv2\n",
      "perturb layer layer1.1.conv1 layer3.0.conv1\n",
      "perturb layer layer1.1.conv1 layer3.0.conv2\n",
      "perturb layer layer1.1.conv1 layer3.0.downsample.0\n",
      "perturb layer layer1.1.conv1 layer3.1.conv1\n",
      "perturb layer layer1.1.conv1 layer3.1.conv2\n",
      "perturb layer layer1.1.conv1 layer3.2.conv1\n",
      "perturb layer layer1.1.conv1 layer3.2.conv2\n",
      "perturb layer layer1.1.conv1 fc\n",
      "perturb layer layer1.1.conv2\n",
      "perturb layer layer1.1.conv2 layer1.2.conv1\n",
      "perturb layer layer1.1.conv2 layer1.2.conv2\n",
      "perturb layer layer1.1.conv2 layer2.0.conv1\n",
      "perturb layer layer1.1.conv2 layer2.0.conv2\n",
      "perturb layer layer1.1.conv2 layer2.0.downsample.0\n",
      "perturb layer layer1.1.conv2 layer2.1.conv1\n",
      "perturb layer layer1.1.conv2 layer2.1.conv2\n",
      "perturb layer layer1.1.conv2 layer2.2.conv1\n",
      "perturb layer layer1.1.conv2 layer2.2.conv2\n",
      "perturb layer layer1.1.conv2 layer3.0.conv1\n",
      "perturb layer layer1.1.conv2 layer3.0.conv2\n",
      "perturb layer layer1.1.conv2 layer3.0.downsample.0\n",
      "perturb layer layer1.1.conv2 layer3.1.conv1\n",
      "perturb layer layer1.1.conv2 layer3.1.conv2\n",
      "perturb layer layer1.1.conv2 layer3.2.conv1\n",
      "perturb layer layer1.1.conv2 layer3.2.conv2\n",
      "perturb layer layer1.1.conv2 fc\n",
      "perturb layer layer1.2.conv1\n",
      "perturb layer layer1.2.conv1 layer1.2.conv2\n",
      "perturb layer layer1.2.conv1 layer2.0.conv1\n",
      "perturb layer layer1.2.conv1 layer2.0.conv2\n",
      "perturb layer layer1.2.conv1 layer2.0.downsample.0\n",
      "perturb layer layer1.2.conv1 layer2.1.conv1\n",
      "perturb layer layer1.2.conv1 layer2.1.conv2\n",
      "perturb layer layer1.2.conv1 layer2.2.conv1\n",
      "perturb layer layer1.2.conv1 layer2.2.conv2\n",
      "perturb layer layer1.2.conv1 layer3.0.conv1\n",
      "perturb layer layer1.2.conv1 layer3.0.conv2\n",
      "perturb layer layer1.2.conv1 layer3.0.downsample.0\n",
      "perturb layer layer1.2.conv1 layer3.1.conv1\n",
      "perturb layer layer1.2.conv1 layer3.1.conv2\n",
      "perturb layer layer1.2.conv1 layer3.2.conv1\n",
      "perturb layer layer1.2.conv1 layer3.2.conv2\n",
      "perturb layer layer1.2.conv1 fc\n",
      "perturb layer layer1.2.conv2\n",
      "perturb layer layer1.2.conv2 layer2.0.conv1\n",
      "perturb layer layer1.2.conv2 layer2.0.conv2\n",
      "perturb layer layer1.2.conv2 layer2.0.downsample.0\n",
      "perturb layer layer1.2.conv2 layer2.1.conv1\n",
      "perturb layer layer1.2.conv2 layer2.1.conv2\n",
      "perturb layer layer1.2.conv2 layer2.2.conv1\n",
      "perturb layer layer1.2.conv2 layer2.2.conv2\n",
      "perturb layer layer1.2.conv2 layer3.0.conv1\n",
      "perturb layer layer1.2.conv2 layer3.0.conv2\n",
      "perturb layer layer1.2.conv2 layer3.0.downsample.0\n",
      "perturb layer layer1.2.conv2 layer3.1.conv1\n",
      "perturb layer layer1.2.conv2 layer3.1.conv2\n",
      "perturb layer layer1.2.conv2 layer3.2.conv1\n",
      "perturb layer layer1.2.conv2 layer3.2.conv2\n",
      "perturb layer layer1.2.conv2 fc\n",
      "perturb layer layer2.0.conv1\n",
      "perturb layer layer2.0.conv1 layer2.0.conv2\n",
      "perturb layer layer2.0.conv1 layer2.0.downsample.0\n",
      "perturb layer layer2.0.conv1 layer2.1.conv1\n",
      "perturb layer layer2.0.conv1 layer2.1.conv2\n",
      "perturb layer layer2.0.conv1 layer2.2.conv1\n",
      "perturb layer layer2.0.conv1 layer2.2.conv2\n",
      "perturb layer layer2.0.conv1 layer3.0.conv1\n",
      "perturb layer layer2.0.conv1 layer3.0.conv2\n",
      "perturb layer layer2.0.conv1 layer3.0.downsample.0\n",
      "perturb layer layer2.0.conv1 layer3.1.conv1\n",
      "perturb layer layer2.0.conv1 layer3.1.conv2\n",
      "perturb layer layer2.0.conv1 layer3.2.conv1\n",
      "perturb layer layer2.0.conv1 layer3.2.conv2\n",
      "perturb layer layer2.0.conv1 fc\n",
      "perturb layer layer2.0.conv2\n",
      "perturb layer layer2.0.conv2 layer2.0.downsample.0\n",
      "perturb layer layer2.0.conv2 layer2.1.conv1\n",
      "perturb layer layer2.0.conv2 layer2.1.conv2\n",
      "perturb layer layer2.0.conv2 layer2.2.conv1\n",
      "perturb layer layer2.0.conv2 layer2.2.conv2\n",
      "perturb layer layer2.0.conv2 layer3.0.conv1\n",
      "perturb layer layer2.0.conv2 layer3.0.conv2\n",
      "perturb layer layer2.0.conv2 layer3.0.downsample.0\n",
      "perturb layer layer2.0.conv2 layer3.1.conv1\n",
      "perturb layer layer2.0.conv2 layer3.1.conv2\n",
      "perturb layer layer2.0.conv2 layer3.2.conv1\n",
      "perturb layer layer2.0.conv2 layer3.2.conv2\n",
      "perturb layer layer2.0.conv2 fc\n",
      "perturb layer layer2.0.downsample.0\n",
      "perturb layer layer2.0.downsample.0 layer2.1.conv1\n",
      "perturb layer layer2.0.downsample.0 layer2.1.conv2\n",
      "perturb layer layer2.0.downsample.0 layer2.2.conv1\n",
      "perturb layer layer2.0.downsample.0 layer2.2.conv2\n",
      "perturb layer layer2.0.downsample.0 layer3.0.conv1\n",
      "perturb layer layer2.0.downsample.0 layer3.0.conv2\n",
      "perturb layer layer2.0.downsample.0 layer3.0.downsample.0\n",
      "perturb layer layer2.0.downsample.0 layer3.1.conv1\n",
      "perturb layer layer2.0.downsample.0 layer3.1.conv2\n",
      "perturb layer layer2.0.downsample.0 layer3.2.conv1\n",
      "perturb layer layer2.0.downsample.0 layer3.2.conv2\n",
      "perturb layer layer2.0.downsample.0 fc\n",
      "perturb layer layer2.1.conv1\n",
      "perturb layer layer2.1.conv1 layer2.1.conv2\n",
      "perturb layer layer2.1.conv1 layer2.2.conv1\n",
      "perturb layer layer2.1.conv1 layer2.2.conv2\n",
      "perturb layer layer2.1.conv1 layer3.0.conv1\n",
      "perturb layer layer2.1.conv1 layer3.0.conv2\n",
      "perturb layer layer2.1.conv1 layer3.0.downsample.0\n",
      "perturb layer layer2.1.conv1 layer3.1.conv1\n",
      "perturb layer layer2.1.conv1 layer3.1.conv2\n",
      "perturb layer layer2.1.conv1 layer3.2.conv1\n",
      "perturb layer layer2.1.conv1 layer3.2.conv2\n",
      "perturb layer layer2.1.conv1 fc\n",
      "perturb layer layer2.1.conv2\n",
      "perturb layer layer2.1.conv2 layer2.2.conv1\n",
      "perturb layer layer2.1.conv2 layer2.2.conv2\n",
      "perturb layer layer2.1.conv2 layer3.0.conv1\n",
      "perturb layer layer2.1.conv2 layer3.0.conv2\n",
      "perturb layer layer2.1.conv2 layer3.0.downsample.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturb layer layer2.1.conv2 layer3.1.conv1\n",
      "perturb layer layer2.1.conv2 layer3.1.conv2\n",
      "perturb layer layer2.1.conv2 layer3.2.conv1\n",
      "perturb layer layer2.1.conv2 layer3.2.conv2\n",
      "perturb layer layer2.1.conv2 fc\n",
      "perturb layer layer2.2.conv1\n",
      "perturb layer layer2.2.conv1 layer2.2.conv2\n",
      "perturb layer layer2.2.conv1 layer3.0.conv1\n",
      "perturb layer layer2.2.conv1 layer3.0.conv2\n",
      "perturb layer layer2.2.conv1 layer3.0.downsample.0\n",
      "perturb layer layer2.2.conv1 layer3.1.conv1\n",
      "perturb layer layer2.2.conv1 layer3.1.conv2\n",
      "perturb layer layer2.2.conv1 layer3.2.conv1\n",
      "perturb layer layer2.2.conv1 layer3.2.conv2\n",
      "perturb layer layer2.2.conv1 fc\n",
      "perturb layer layer2.2.conv2\n",
      "perturb layer layer2.2.conv2 layer3.0.conv1\n",
      "perturb layer layer2.2.conv2 layer3.0.conv2\n",
      "perturb layer layer2.2.conv2 layer3.0.downsample.0\n",
      "perturb layer layer2.2.conv2 layer3.1.conv1\n",
      "perturb layer layer2.2.conv2 layer3.1.conv2\n",
      "perturb layer layer2.2.conv2 layer3.2.conv1\n",
      "perturb layer layer2.2.conv2 layer3.2.conv2\n",
      "perturb layer layer2.2.conv2 fc\n",
      "perturb layer layer3.0.conv1\n",
      "perturb layer layer3.0.conv1 layer3.0.conv2\n",
      "perturb layer layer3.0.conv1 layer3.0.downsample.0\n",
      "perturb layer layer3.0.conv1 layer3.1.conv1\n",
      "perturb layer layer3.0.conv1 layer3.1.conv2\n",
      "perturb layer layer3.0.conv1 layer3.2.conv1\n",
      "perturb layer layer3.0.conv1 layer3.2.conv2\n",
      "perturb layer layer3.0.conv1 fc\n",
      "perturb layer layer3.0.conv2\n",
      "perturb layer layer3.0.conv2 layer3.0.downsample.0\n",
      "perturb layer layer3.0.conv2 layer3.1.conv1\n",
      "perturb layer layer3.0.conv2 layer3.1.conv2\n",
      "perturb layer layer3.0.conv2 layer3.2.conv1\n",
      "perturb layer layer3.0.conv2 layer3.2.conv2\n",
      "perturb layer layer3.0.conv2 fc\n",
      "perturb layer layer3.0.downsample.0\n",
      "perturb layer layer3.0.downsample.0 layer3.1.conv1\n",
      "perturb layer layer3.0.downsample.0 layer3.1.conv2\n",
      "perturb layer layer3.0.downsample.0 layer3.2.conv1\n",
      "perturb layer layer3.0.downsample.0 layer3.2.conv2\n",
      "perturb layer layer3.0.downsample.0 fc\n",
      "perturb layer layer3.1.conv1\n",
      "perturb layer layer3.1.conv1 layer3.1.conv2\n",
      "perturb layer layer3.1.conv1 layer3.2.conv1\n",
      "perturb layer layer3.1.conv1 layer3.2.conv2\n",
      "perturb layer layer3.1.conv1 fc\n",
      "perturb layer layer3.1.conv2\n",
      "perturb layer layer3.1.conv2 layer3.2.conv1\n",
      "perturb layer layer3.1.conv2 layer3.2.conv2\n",
      "perturb layer layer3.1.conv2 fc\n",
      "perturb layer layer3.2.conv1\n",
      "perturb layer layer3.2.conv1 layer3.2.conv2\n",
      "perturb layer layer3.2.conv1 fc\n",
      "perturb layer layer3.2.conv2\n",
      "perturb layer layer3.2.conv2 fc\n",
      "perturb layer fc\n",
      "165.34 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s_time = time.time()\n",
    "cached = {}\n",
    "for n in layers_to_quant:\n",
    "    for m in layers_to_quant:\n",
    "        if n == m:\n",
    "            print('perturb layer',n)\n",
    "            p = perturb_loss([n,],ref_metric)\n",
    "            cached[(n,n)] = p\n",
    "        if (n,m) not in cached:\n",
    "            print('perturb layer',n,m)\n",
    "            p = perturb_loss([n,m],ref_metric)\n",
    "            cached[(n,m)] = p\n",
    "            cached[(m,n)] = p   \n",
    "print(f'{time.time()-s_time:.2f} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b8358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index = {}\n",
    "cnt = 0\n",
    "for layer in layers_to_quant:\n",
    "    layer_index[layer] = cnt\n",
    "    cnt += 1\n",
    "L = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32fcfaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hm = np.zeros(shape=(L,L))\n",
    "for n in layers_to_quant:\n",
    "    for m in layers_to_quant:\n",
    "        hm[layer_index[n],layer_index[m]] = cached[(n,m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e39fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_grad = np.zeros_like(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8c82c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(L):\n",
    "    for j in range(L):\n",
    "        if i == j:\n",
    "            cached_grad[i,j] = 0.5 * hm[i,j]\n",
    "        else:\n",
    "            cached_grad[i,j] = 0.5 * (hm[i,j] - hm[i,i] - hm[j,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67c2133f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.16934490e-05,  1.09550357e-04,  8.70123506e-05,\n",
       "         3.60045582e-05,  2.94178724e-05,  5.62150031e-05,\n",
       "         1.14321709e-05,  5.31995669e-05,  1.00730173e-04,\n",
       "        -1.15052424e-04, -5.61973080e-05, -2.28986144e-05,\n",
       "        -4.89939004e-05, -7.98352063e-05, -1.83467939e-04,\n",
       "        -8.35511833e-05, -1.54895708e-05, -5.28531149e-05,\n",
       "        -3.75006348e-06,  9.78056341e-06, -1.59651041e-05,\n",
       "        -6.42966479e-06],\n",
       "       [ 1.09550357e-04,  4.24776003e-03,  2.11605299e-03,\n",
       "         8.57040286e-05,  2.76977569e-04,  1.22486930e-03,\n",
       "         6.45171106e-04,  6.93453476e-05,  9.52508673e-04,\n",
       "        -1.23043340e-03, -3.70357744e-04, -1.61342323e-06,\n",
       "        -1.03405975e-03,  8.21219757e-05, -8.22045840e-04,\n",
       "        -5.20916656e-04, -3.37938778e-04,  1.64996982e-03,\n",
       "         5.48519194e-04,  4.76930290e-06, -1.64005905e-06,\n",
       "        -2.71238387e-06],\n",
       "       [ 8.70123506e-05,  2.11605299e-03,  5.51590435e-03,\n",
       "         1.45617537e-03,  1.94935873e-04,  1.03757270e-03,\n",
       "         1.60365812e-03,  1.32710841e-03,  2.31629238e-04,\n",
       "        -3.08083557e-04, -3.34854238e-04, -3.94269824e-05,\n",
       "        -4.28263843e-04,  2.70244665e-04, -1.22014973e-03,\n",
       "        -3.13362479e-04, -2.06332654e-04,  4.83503565e-04,\n",
       "        -2.43012235e-04, -7.90155306e-04,  1.80218741e-04,\n",
       "        -2.47128308e-05],\n",
       "       [ 3.60045582e-05,  8.57040286e-05,  1.45617537e-03,\n",
       "         8.20654258e-04, -2.05455348e-05, -3.16785648e-05,\n",
       "         2.10324489e-04, -5.67413680e-04,  4.56992164e-04,\n",
       "         1.89477764e-04,  3.18010524e-04, -1.85687654e-04,\n",
       "         3.14905681e-04,  1.60139613e-04, -3.54288146e-05,\n",
       "         7.35272840e-04,  1.43114664e-04, -5.42155281e-04,\n",
       "        -1.97028741e-05, -3.33044492e-04, -1.81429088e-05,\n",
       "        -2.87836418e-05],\n",
       "       [ 2.94178724e-05,  2.76977569e-04,  1.94935873e-04,\n",
       "        -2.05455348e-05, -5.55411726e-04,  3.30696627e-04,\n",
       "         1.64924935e-04, -4.92549688e-04,  7.92239606e-04,\n",
       "         7.74478912e-04,  2.14116834e-04,  3.30281630e-04,\n",
       "         2.56457180e-04,  3.12733464e-04,  8.69662501e-04,\n",
       "         1.01936366e-03,  4.22256067e-05,  3.95900942e-04,\n",
       "         4.09573689e-04, -1.83015130e-04,  8.63537192e-05,\n",
       "         4.25307080e-05],\n",
       "       [ 5.62150031e-05,  1.22486930e-03,  1.03757270e-03,\n",
       "        -3.16785648e-05,  3.30696627e-04, -3.06192786e-05,\n",
       "         1.12633761e-03,  1.34553518e-03, -4.32566553e-04,\n",
       "        -2.40720436e-04,  6.34800643e-05,  7.86341913e-04,\n",
       "        -1.92308091e-03, -9.58995707e-04, -6.27957471e-04,\n",
       "        -1.24724768e-03, -5.24869189e-04,  1.77748539e-03,\n",
       "        -1.52538531e-04,  6.92149438e-04,  1.50677189e-04,\n",
       "         8.74008983e-06],\n",
       "       [ 1.14321709e-05,  6.45171106e-04,  1.60365812e-03,\n",
       "         2.10324489e-04,  1.64924935e-04,  1.12633761e-03,\n",
       "         1.14211403e-03,  8.20084289e-04, -1.73474122e-03,\n",
       "         1.22504123e-04, -4.14247438e-04,  1.24448724e-04,\n",
       "        -1.17511116e-03, -6.38428517e-04, -8.20004381e-04,\n",
       "         2.07815319e-06, -1.20810792e-04,  3.13867070e-04,\n",
       "         3.19182314e-04,  5.00100292e-04,  1.50643103e-04,\n",
       "        -4.67095524e-05],\n",
       "       [ 5.31995669e-05,  6.93453476e-05,  1.32710841e-03,\n",
       "        -5.67413680e-04, -4.92549688e-04,  1.34553518e-03,\n",
       "         8.20084289e-04,  9.20157898e-03, -1.81178264e-03,\n",
       "        -2.28831507e-03, -1.51944719e-04,  1.39671788e-03,\n",
       "        -1.72820613e-03, -8.48380849e-05, -1.31040756e-03,\n",
       "        -1.87225491e-03, -1.39961317e-03,  4.28309049e-03,\n",
       "        -8.99399258e-04,  7.65483826e-04,  2.89619900e-04,\n",
       "         3.02070752e-05],\n",
       "       [ 1.00730173e-04,  9.52508673e-04,  2.31629238e-04,\n",
       "         4.56992164e-04,  7.92239606e-04, -4.32566553e-04,\n",
       "        -1.73474122e-03, -1.81178264e-03,  2.89463121e-03,\n",
       "         2.62765959e-04,  2.38050874e-03,  3.63671593e-04,\n",
       "         3.52031272e-03,  7.22477399e-04,  2.51271129e-03,\n",
       "         2.51281783e-03,  4.62939776e-04, -7.04127736e-04,\n",
       "         4.81990911e-04, -1.31327733e-03, -6.46009110e-04,\n",
       "         3.36542726e-06],\n",
       "       [-1.15052424e-04, -1.23043340e-03, -3.08083557e-04,\n",
       "         1.89477764e-04,  7.74478912e-04, -2.40720436e-04,\n",
       "         1.22504123e-04, -2.28831507e-03,  2.62765959e-04,\n",
       "         8.37235339e-04,  5.79477288e-04,  1.82042271e-04,\n",
       "         6.44018501e-04,  7.46961683e-05,  7.73596019e-04,\n",
       "         9.90165584e-04,  3.23838554e-04, -1.47112515e-03,\n",
       "         1.96939334e-04, -5.13954833e-04, -5.88614494e-05,\n",
       "        -1.49160624e-06],\n",
       "       [-5.61973080e-05, -3.70357744e-04, -3.34854238e-04,\n",
       "         3.18010524e-04,  2.14116834e-04,  6.34800643e-05,\n",
       "        -4.14247438e-04, -1.51944719e-04,  2.38050874e-03,\n",
       "         5.79477288e-04,  1.13561042e-03,  1.06125139e-04,\n",
       "         1.58454664e-03, -1.34174153e-04,  7.78683461e-04,\n",
       "         1.13246851e-03,  1.45336427e-04, -6.61463849e-04,\n",
       "         7.93647021e-05,  1.57084316e-05, -2.67543271e-04,\n",
       "        -4.08774242e-05],\n",
       "       [-2.28986144e-05, -1.61342323e-06, -3.94269824e-05,\n",
       "        -1.85687654e-04,  3.30281630e-04,  7.86341913e-04,\n",
       "         1.24448724e-04,  1.39671788e-03,  3.63671593e-04,\n",
       "         1.82042271e-04,  1.06125139e-04,  9.19270702e-04,\n",
       "        -7.71416351e-05,  1.61110237e-04,  9.84104350e-04,\n",
       "        -1.90768205e-04, -3.14518809e-04,  1.13748740e-03,\n",
       "         2.97873840e-04,  4.68585268e-04,  2.03644857e-05,\n",
       "         2.18397006e-05],\n",
       "       [-4.89939004e-05, -1.03405975e-03, -4.28263843e-04,\n",
       "         3.14905681e-04,  2.56457180e-04, -1.92308091e-03,\n",
       "        -1.17511116e-03, -1.72820613e-03,  3.52031272e-03,\n",
       "         6.44018501e-04,  1.58454664e-03, -7.71416351e-05,\n",
       "         3.01676486e-03,  1.22897457e-03,  9.98173282e-04,\n",
       "         1.85708962e-03,  6.75582886e-04, -1.79464389e-03,\n",
       "        -4.55989689e-04, -1.75008401e-03, -3.27225775e-04,\n",
       "        -1.14105642e-05],\n",
       "       [-7.98352063e-05,  8.21219757e-05,  2.70244665e-04,\n",
       "         1.60139613e-04,  3.12733464e-04, -9.58995707e-04,\n",
       "        -6.38428517e-04, -8.48380849e-05,  7.22477399e-04,\n",
       "         7.46961683e-05, -1.34174153e-04,  1.61110237e-04,\n",
       "         1.22897457e-03,  1.60429962e-03,  7.32128508e-04,\n",
       "         8.50991160e-04, -2.85129994e-05,  2.04319507e-04,\n",
       "         1.71399862e-04, -9.55566391e-04,  2.04589777e-04,\n",
       "         2.13932246e-05],\n",
       "       [-1.83467939e-04, -8.22045840e-04, -1.22014973e-03,\n",
       "        -3.54288146e-05,  8.69662501e-04, -6.27957471e-04,\n",
       "        -8.20004381e-04, -1.31040756e-03,  2.51271129e-03,\n",
       "         7.73596019e-04,  7.78683461e-04,  9.84104350e-04,\n",
       "         9.98173282e-04,  7.32128508e-04,  1.74608119e-03,\n",
       "         1.25793479e-03,  2.11806595e-04,  2.45693978e-03,\n",
       "         1.15237609e-03,  5.75185753e-04,  1.01447292e-04,\n",
       "         1.05980411e-04],\n",
       "       [-8.35511833e-05, -5.20916656e-04, -3.13362479e-04,\n",
       "         7.35272840e-04,  1.01936366e-03, -1.24724768e-03,\n",
       "         2.07815319e-06, -1.87225491e-03,  2.51281783e-03,\n",
       "         9.90165584e-04,  1.13246851e-03, -1.90768205e-04,\n",
       "         1.85708962e-03,  8.50991160e-04,  1.25793479e-03,\n",
       "         3.62810697e-03,  6.18250482e-04, -1.20403394e-03,\n",
       "         1.02446843e-03, -5.57783619e-04, -1.89397112e-04,\n",
       "        -2.31031328e-05],\n",
       "       [-1.54895708e-05, -3.37938778e-04, -2.06332654e-04,\n",
       "         1.43114664e-04,  4.22256067e-05, -5.24869189e-04,\n",
       "        -1.20810792e-04, -1.39961317e-03,  4.62939776e-04,\n",
       "         3.23838554e-04,  1.45336427e-04, -3.14518809e-04,\n",
       "         6.75582886e-04, -2.85129994e-05,  2.11806595e-04,\n",
       "         6.18250482e-04,  3.90915200e-05, -9.65348445e-04,\n",
       "        -4.75160778e-06, -1.75748952e-04, -2.28300877e-04,\n",
       "        -1.32670626e-05],\n",
       "       [-5.28531149e-05,  1.64996982e-03,  4.83503565e-04,\n",
       "        -5.42155281e-04,  3.95900942e-04,  1.77748539e-03,\n",
       "         3.13867070e-04,  4.28309049e-03, -7.04127736e-04,\n",
       "        -1.47112515e-03, -6.61463849e-04,  1.13748740e-03,\n",
       "        -1.79464389e-03,  2.04319507e-04,  2.45693978e-03,\n",
       "        -1.20403394e-03, -9.65348445e-04,  8.40002224e-03,\n",
       "         1.06840581e-03,  1.26054306e-03,  2.05523148e-04,\n",
       "         1.17347389e-04],\n",
       "       [-3.75006348e-06,  5.48519194e-04, -2.43012235e-04,\n",
       "        -1.97028741e-05,  4.09573689e-04, -1.52538531e-04,\n",
       "         3.19182314e-04, -8.99399258e-04,  4.81990911e-04,\n",
       "         1.96939334e-04,  7.93647021e-05,  2.97873840e-04,\n",
       "        -4.55989689e-04,  1.71399862e-04,  1.15237609e-03,\n",
       "         1.02446843e-03, -4.75160778e-06,  1.06840581e-03,\n",
       "        -4.30160761e-04,  9.19236615e-04,  1.20637752e-04,\n",
       "         8.91331583e-06],\n",
       "       [ 9.78056341e-06,  4.76930290e-06, -7.90155306e-04,\n",
       "        -3.33044492e-04, -1.83015130e-04,  6.92149438e-04,\n",
       "         5.00100292e-04,  7.65483826e-04, -1.31327733e-03,\n",
       "        -5.13954833e-04,  1.57084316e-05,  4.68585268e-04,\n",
       "        -1.75008401e-03, -9.55566391e-04,  5.75185753e-04,\n",
       "        -5.57783619e-04, -1.75748952e-04,  1.26054306e-03,\n",
       "         9.19236615e-04, -1.99022312e-03,  1.15023740e-04,\n",
       "         6.35981560e-06],\n",
       "       [-1.59651041e-05, -1.64005905e-06,  1.80218741e-04,\n",
       "        -1.81429088e-05,  8.63537192e-05,  1.50677189e-04,\n",
       "         1.50643103e-04,  2.89619900e-04, -6.46009110e-04,\n",
       "        -5.88614494e-05, -2.67543271e-04,  2.03644857e-05,\n",
       "        -3.27225775e-04,  2.04589777e-04,  1.01447292e-04,\n",
       "        -1.89397112e-04, -2.28300877e-04,  2.05523148e-04,\n",
       "         1.20637752e-04,  1.15023740e-04, -1.96912773e-03,\n",
       "         2.13764608e-05],\n",
       "       [-6.42966479e-06, -2.71238387e-06, -2.47128308e-05,\n",
       "        -2.87836418e-05,  4.25307080e-05,  8.74008983e-06,\n",
       "        -4.67095524e-05,  3.02070752e-05,  3.36542726e-06,\n",
       "        -1.49160624e-06, -4.08774242e-05,  2.18397006e-05,\n",
       "        -1.14105642e-05,  2.13932246e-05,  1.05980411e-04,\n",
       "        -2.31031328e-05, -1.32670626e-05,  1.17347389e-04,\n",
       "         8.91331583e-06,  6.35981560e-06,  2.13764608e-05,\n",
       "        -7.01434910e-05]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d62cab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cached_grad\n",
    "X[X<0] = 0\n",
    "X_std = (X - X.min()) / (X.max() - X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3d89e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_std,cmap='hot')\n",
    "plt.xlabel('layer index')\n",
    "plt.ylabel('layer index')\n",
    "plt.savefig('resnet20_feintgrad.pdf',transparent=True, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "608e8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('feintlady_resnet20','wb') as f:\n",
    "    pickle.dump({'Ltilde':hm,'layer_index':layer_index},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e094c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
