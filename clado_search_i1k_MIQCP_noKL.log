/homes/zdeng/.conda/envs/mltls/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Prepare 2bits model using MQBench
[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval
[MQBENCH] INFO: Weight Qconfig:
    FakeQuantize: FixedFakeQuantize Params: {}
    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 2 / Per channel: False / Pot scale: False / Extra kwargs: {}
[MQBENCH] INFO: Activation Qconfig:
    FakeQuantize: FixedFakeQuantize Params: {}
    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}
[MQBENCH] INFO: Replace module to qat module.
[MQBENCH] INFO: Set layer conv1 to 8 bit.
[MQBENCH] INFO: Set layer fc to 8 bit.
dbg node_to_quantize_output
 odict_keys([x, maxpool, layer1_0_relu, layer1_0_relu_1, layer1_0_relu_2, layer1_1_relu, layer1_1_relu_1, layer1_1_relu_2, layer1_2_relu, layer1_2_relu_1, layer1_2_relu_2, layer2_0_relu, layer2_0_relu_1, layer2_0_relu_2, layer2_1_relu, layer2_1_relu_1, layer2_1_relu_2, layer2_2_relu, layer2_2_relu_1, layer2_2_relu_2, layer2_3_relu, layer2_3_relu_1, layer2_3_relu_2, layer3_0_relu, layer3_0_relu_1, layer3_0_relu_2, layer3_1_relu, layer3_1_relu_1, layer3_1_relu_2, layer3_2_relu, layer3_2_relu_1, layer3_2_relu_2, layer3_3_relu, layer3_3_relu_1, layer3_3_relu_2, layer3_4_relu, layer3_4_relu_1, layer3_4_relu_2, layer3_5_relu, layer3_5_relu_1, layer3_5_relu_2, layer4_0_relu, layer4_0_relu_1, layer4_0_relu_2, layer4_1_relu, layer4_1_relu_1, layer4_1_relu_2, layer4_2_relu, layer4_2_relu_1, flatten])
[MQBENCH] INFO: Set x post act quantize to 8 bit.
[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant maxpool_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_2_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_2_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_3_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_2_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_3_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_4_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_5_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Set flatten post act quantize to 8 bit.
[MQBENCH] INFO: Insert act quant flatten_post_act_fake_quantizer
[MQBENCH] INFO: Enable observer and Disable quantize.
Prepare 4bits model using MQBench
[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval
[MQBENCH] INFO: Weight Qconfig:
    FakeQuantize: FixedFakeQuantize Params: {}
    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 4 / Per channel: False / Pot scale: False / Extra kwargs: {}
[MQBENCH] INFO: Activation Qconfig:
    FakeQuantize: FixedFakeQuantize Params: {}
    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}
[MQBENCH] INFO: Replace module to qat module.
[MQBENCH] INFO: Set layer conv1 to 8 bit.
[MQBENCH] INFO: Set layer fc to 8 bit.
dbg node_to_quantize_output
 odict_keys([x, maxpool, layer1_0_relu, layer1_0_relu_1, layer1_0_relu_2, layer1_1_relu, layer1_1_relu_1, layer1_1_relu_2, layer1_2_relu, layer1_2_relu_1, layer1_2_relu_2, layer2_0_relu, layer2_0_relu_1, layer2_0_relu_2, layer2_1_relu, layer2_1_relu_1, layer2_1_relu_2, layer2_2_relu, layer2_2_relu_1, layer2_2_relu_2, layer2_3_relu, layer2_3_relu_1, layer2_3_relu_2, layer3_0_relu, layer3_0_relu_1, layer3_0_relu_2, layer3_1_relu, layer3_1_relu_1, layer3_1_relu_2, layer3_2_relu, layer3_2_relu_1, layer3_2_relu_2, layer3_3_relu, layer3_3_relu_1, layer3_3_relu_2, layer3_4_relu, layer3_4_relu_1, layer3_4_relu_2, layer3_5_relu, layer3_5_relu_1, layer3_5_relu_2, layer4_0_relu, layer4_0_relu_1, layer4_0_relu_2, layer4_1_relu, layer4_1_relu_1, layer4_1_relu_2, layer4_2_relu, layer4_2_relu_1, flatten])
[MQBENCH] INFO: Set x post act quantize to 8 bit.
[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant maxpool_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_2_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_2_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_3_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_2_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_3_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_4_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_5_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Set flatten post act quantize to 8 bit.
[MQBENCH] INFO: Insert act quant flatten_post_act_fake_quantizer
[MQBENCH] INFO: Enable observer and Disable quantize.
Prepare 8bits model using MQBench
[MQBENCH] INFO: Quantize model Scheme: BackendType.Academic Mode: Eval
[MQBENCH] INFO: Weight Qconfig:
    FakeQuantize: FixedFakeQuantize Params: {}
    Oberver:      MSEObserver Params: Symmetric: True / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}
[MQBENCH] INFO: Activation Qconfig:
    FakeQuantize: FixedFakeQuantize Params: {}
    Oberver:      EMAMSEObserver Params: Symmetric: False / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}
[MQBENCH] INFO: Replace module to qat module.
[MQBENCH] INFO: Set layer conv1 to 8 bit.
[MQBENCH] INFO: Set layer fc to 8 bit.
dbg node_to_quantize_output
 odict_keys([x, maxpool, layer1_0_relu, layer1_0_relu_1, layer1_0_relu_2, layer1_1_relu, layer1_1_relu_1, layer1_1_relu_2, layer1_2_relu, layer1_2_relu_1, layer1_2_relu_2, layer2_0_relu, layer2_0_relu_1, layer2_0_relu_2, layer2_1_relu, layer2_1_relu_1, layer2_1_relu_2, layer2_2_relu, layer2_2_relu_1, layer2_2_relu_2, layer2_3_relu, layer2_3_relu_1, layer2_3_relu_2, layer3_0_relu, layer3_0_relu_1, layer3_0_relu_2, layer3_1_relu, layer3_1_relu_1, layer3_1_relu_2, layer3_2_relu, layer3_2_relu_1, layer3_2_relu_2, layer3_3_relu, layer3_3_relu_1, layer3_3_relu_2, layer3_4_relu, layer3_4_relu_1, layer3_4_relu_2, layer3_5_relu, layer3_5_relu_1, layer3_5_relu_2, layer4_0_relu, layer4_0_relu_1, layer4_0_relu_2, layer4_1_relu, layer4_1_relu_1, layer4_1_relu_2, layer4_2_relu, layer4_2_relu_1, flatten])
[MQBENCH] INFO: Set x post act quantize to 8 bit.
[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant maxpool_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer1_2_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_2_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_3_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_3_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer2_3_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_2_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_3_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_3_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_3_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_4_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_4_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_4_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_5_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_5_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer3_5_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_0_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_0_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_0_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_1_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_1_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_1_relu_2_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_2_relu_post_act_fake_quantizer
[MQBENCH] INFO: Insert act quant layer4_2_relu_1_post_act_fake_quantizer
[MQBENCH] INFO: Set flatten post act quantize to 8 bit.
[MQBENCH] INFO: Insert act quant flatten_post_act_fake_quantizer
[MQBENCH] INFO: Enable observer and Disable quantize.
[MQBENCH] INFO: Disable observer and Disable quantize.
[MQBENCH] INFO: Disable observer and Enable quantize.
evaluate mqb quantized model
